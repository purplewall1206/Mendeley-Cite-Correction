Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Sun2013,
abstract = {Buggy device drivers are a major threat to the reliability of their host operating system. There have been myriad attempts to protect the kernel, but most of them either required driver modifications or incur substantial performance overhead. This paper describes an isolated device driver execution system called SIDE (Streamlined Isolated Driver Execution), which focuses specifically on unmodified device drivers and strives to avoid changing the existing kernel code as much as possible. SIDE exploits virtual memory hardware to set up a device driver execution environment that is compatible with existing device drivers and yet is fully isolated from the kernel. SIDE is able to run an unmodified device driver for a Gigabit Ethernet NIC and the latency and throughput penalty is kept under 1% when augmented with a set of performance optimizations designed to reduce the number of protection domain crossings between an isolated device driver and the kernel. {\textcopyright} 2013 IEEE.},
author = {Sun, Yifeng and Chiueh, Tzi Cker},
doi = {10.1109/DSN.2013.6575348},
file = {:F\:/D2/06575348.pdf:pdf},
isbn = {9781467364713},
journal = {Proceedings of the International Conference on Dependable Systems and Networks},
keywords = {device driver isolation,fault tolerance},
publisher = {IEEE},
title = {{SIDE: Isolated and efficient execution of unmodified device drivers}},
year = {2013}
}
@article{Kwon2019,
abstract = {Code disclosure attacks are one of the major threats to a computer system, considering that code often contains security sensitive information, such as intellectual properties (e.g., secret algorithm), sensitive data (e.g., cryptographic keys) and the gadgets for launching code reuse attacks. To stymie this class of attacks, security researchers have devised a strong memory protection mechanism, called eXecute-Only-Memory (XOM), that defines special memory regions where instruction execution is permitted but data reads and writes are prohibited. Reflecting the value of XOM, many recent high-end processors have added support for XOM in their hardware. Unfortunately, however, low-end embedded processors have yet to provide hardware support for XOM. In this paper, we propose a novel technique, named uXOM, that realizes XOM in a way that is secure and highly optimized to work on Cortex-M, which is a prominent processor series used in low-end embedded devices. uXOM achieves its security and efficiency by using special architectural features in Cortex-M: unprivileged memory instructions and an MPU. We present several challenges in making XOM nonbypassable under strong attackers and introduce our code analysis and instrumentation to solve these challenges. Our evaluation reveals that uXOM successfully realizes XOM in Cortex-M processor with much better efficiency in terms of execution time, code size and energy consumption compared to a software-only XOM implementation for Cortex-M.},
author = {Kwon, Donghyun and Shin, Jangseop and Kim, Giyeol and Lee, Byoungyoung and Cho, Yeongpil and Paek, Yunheung},
file = {:F\:/D2/sec19-kwon_0.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {231--247},
title = {{UXOM: Efficient execute-only memory on arm cortex-M}},
year = {2019}
}
@article{Song2017,
abstract = {—The operation system kernel is the foundation of the whole system and is often the de facto trusted computing base for many higher level security mechanisms. Unfortunately, kernel vulnerabilities are not rare and are continuously being introduced with new kernel features. Once the kernel is compromised, attack-ers can bypass any access control checks, escalate their privileges, and hide the evidence of attacks. Many protection mechanisms have been proposed and deployed to prevent kernel exploits. However, a majority of these techniques only focus on preventing control-flow hijacking attacks; techniques that can mitigate non-control-data attacks either only apply to drivers/modules or im-pose too much overhead. The goal of our research is to develop a principled defense mechanism against memory-corruption-based privilege escalation attacks. Toward this end, we leverage data-flow integrity to enforce security invariants of the kernel access control system. In order for our protection mechanism to be practical, we develop two new techniques: one for automatically inferring data that are critical to the access control system without manual annotation, and the other for efficient DFI enforcement over the inference results. We have implemented a prototype of our technology for the ARM64 Linux kernel on an Android device. The evaluation results of our prototype implementation show that our technology can mitigate a majority of privilege escalation attacks, while imposing a moderate amount of performance overhead.},
author = {Song, Chengyu and Lee, Byoungyoung and Lu, Kangjie and Harris, William and Kim, Taesoo and Lee, Wenke},
doi = {10.14722/ndss.2016.23218},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2017 - Enforcing Kernel Security Invariants with Data Flow Integrity.pdf:pdf},
isbn = {189156241X},
number = {February},
pages = {21--24},
title = {{Enforcing Kernel Security Invariants with Data Flow Integrity}},
year = {2017}
}
@article{Srivastava2011,
abstract = {Recent malware instances execute completely in the kernel as drivers; they do not contain any user-level ma- licious processes. This design evades the system call monitoring used by many software security solutions, in- cluding malware analyzers and host-based intrusion de- tectors that track only user-level processes. To trace the behavior of kernel malware instances, we design and im- plement a hypervisor-based system called Gateway that monitors kernel APIs invoked by drivers. Gateway cre- ates a hardened, non-bypassable monitoring interface by isolating drivers in an address space separate from the kernel. To overcome the performance degradation introduced by switches between these separate address spaces, our design rewrites binary kernel and driver code at runtime and generates new code on demand to optimize the address space transition speed. Our exper- imental measurements show performance overheads of 10% or better, with many overheads less than 1%. Our security evaluation shows that Gateway is able to mon- itor all kernel APIs invoked by malicious drivers across its non-bypassable interface.},
author = {Srivastava, Abhinav and Giffin, Jonathon},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava, Giffin - Unknown - Efficient Monitoring of Untrusted Kernel-Mode Execution.pdf:pdf},
journal = {18th Annual Network & Distributed System Security Symposium},
pages = {18},
title = {{Efficient monitoring of untrusted kernel-mode execution}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.3041&rep=rep1&type=pdf},
year = {2011}
}
@article{Ben-Yehuda2019,
abstract = {In classical machine virtualization, a hypervisor runs multiple operating systems simultaneously, each on its own virtual machine. In nested virtualization, a hypervisor can run multiple other hypervisors with their associated virtual machines. As operating systems gain hypervisor functionality-Microsoft Windows 7 already runs Windows XP in a virtual machine-nested virtualization will become necessary in hypervisors that wish to host them. We present the design, implementation, analysis, and evaluation of high-performance nested virtualization on Intel x86-based systems. The Turtles project, which is part of the Linux/KVM hypervisor, runs multiple unmodified hypervisors (e.g., KVM and VMware) and operating systems (e.g., Linux and Windows). Despite the lack of architectural support for nested virtualization in the x86 architecture, it can achieve performance that is within 6-8% of single-level (non-nested) virtualization for common workloads, through multi-dimensional paging for MMU virtualization and multi-level device assignment for I/O virtualization.},
author = {Ben-Yehuda, Muli and Day, Michael D. and Dubitzky, Zvi and Factor, Michael and Har'El, Nadav and Gordon, Abel and Liguori, Anthony and Wasserman, Orit and Yassour, Ben Ami},
file = {:F\:/D2/Ben-Yehuda.pdf:pdf},
isbn = {9781931971799},
journal = {Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2010},
pages = {423--436},
title = {{The turtles project: Design and implementation of nested virtualization}},
year = {2019}
}
@article{Wiseman2008,
abstract = {The Linux kernel stack has a fixed size. There is no mechanism to prevent the kernel from overflowing the stack. Hackers can exploit this bug to put unwanted information in the memory of the operating system and gain control over the system. In order to prevent this problem, we introduce a dynamically sized kernel stack that can be integrated into the standard Linux kernel. The well-known paging mechanism is reused with some changes, in order to enable the kernel stack to grow. {\textcopyright}2008 IEEE.},
author = {Wiseman, Yair and Isaacson, Joel and Lubovsky, Eliad},
doi = {10.1109/IRI.2008.4583015},
file = {:F\:/D2/wiseman2008.pdf:pdf},
isbn = {9781424426607},
journal = {2008 IEEE International Conference on Information Reuse and Integration, IEEE IRI-2008},
pages = {116--121},
title = {{Eliminating the threat of kernel stack overflows}},
year = {2008}
}
@article{Vano-Garcia2020a,
abstract = {Cloud computing has completely changed our lives. This technology dramatically impacted on how we play, work and live. It has been widely adopted in many sectors mainly because it reduces the cost of performing tasks in a flexible, scalable and reliable way. To provide a secure cloud computing architecture, the highest possible level of protection must be applied. Unfortunately, the cloud computing paradigm introduces new scenarios where security protection techniques are weakened or disabled to obtain a better performance and resources exploitation. Kernel ASLR (KASLR) is a widely adopted protection technique present in all modern operating systems. KASLR is a very effective technique that thwarts unknown attacks but unfortunately its randomness have a significant impact on memory deduplication savings. Both techniques are very desired by the industry, the first one because of the high level of security that it provides and the latter to obtain better performance and resources exploitation. In this paper, we propose KASLR-MT, a new Linux kernel randomization approach compatible with memory deduplication. We identify why the most widely and effective technique used to mitigate attacks at kernel level, KASLR, fails to provide protection and shareability at the same time. We analyze the current Linux kernel randomization and how it affects to the shared memory of each kernel region. Then, based on the analysis, we propose KASLR-MT, the first effective and practical Kernel ASLR memory protection that maximizes the memory deduplication savings rate while providing a strong security. Our tests reveal that KASLR-MT is not intrusive, very scalable and provides strong protection without sacrificing the shareability.},
author = {Vano-Garcia, Fernando and Marco-Gisbert, Hector},
doi = {10.1016/j.jpdc.2019.11.008},
journal = {Journal of Parallel and Distributed Computing},
keywords = {Cloud,Memory deduplication,Operating systems,Security,Virtualization},
pages = {77--90},
title = {{KASLR-MT: Kernel Address Space Layout Randomization for Multi-Tenant cloud systems}},
url = {https://doi.org/10.1016/j.jpdc.2019.11.008},
volume = {137},
year = {2020}
}
@article{Lee2020,
abstract = {Trusted execution environments (TEEs) see rising use in devices from embedded sensors to cloud servers and encompass a range of cost, power constraints, and security threat model choices. On the other hand, each of the current vendor-specific TEEs makes a fixed set of trade-offs with little room for customization. We present Keystone-The first open-source framework for building customized TEEs. Keystone uses simple abstractions provided by the hardware such as memory isolation and a programmable layer underneath untrusted components (e.g., OS). We build reusable TEE core primitives from these abstractions while allowing platform-specific modifications and flexible feature choices. We showcase how Keystone-based TEEs run on unmodified RISC-V hardware and demonstrate the strengths of our design in terms of security, TCB size, execution of a range of benchmarks, applications, kernels, and deployment models.},
author = {Lee, Dayeol and Kohlbrenner, David and Shinde, Shweta and Asanovi{\'{c}}, Krste and Song, Dawn},
doi = {10.1145/3342195.3387532},
file = {:F\:/D2/Keystone.pdf:pdf},
isbn = {9781450368827},
journal = {Proceedings of the 15th European Conference on Computer Systems, EuroSys 2020},
keywords = {RISC-V,hardware enclave,hardware root of trust,memory isolation,open source,secure enclave,side-channel attack,trusted execution environment},
title = {{Keystone: An open framework for architecting trusted execution environments}},
year = {2020}
}
@article{Manes2018,
abstract = {Monolithic kernel is one of the prevalent configurations out of various kernel design models. While monolithic kernel excels in performance and management, they are unequipped for runtime system update; and this brings the need for kernel extension. Although kernel extensions are a convenient measure for system management, it is well established that they make the system prone to rootkit attacks and kernel exploitation as they share the single memory space with the rest of the kernel. To address this problem, various forms of isolation (e.g., making into a process), are so far proposed, yet their performance overhead is often too high or incompatible for a general purpose kernel. In this paper, we propose Domain Isolated Kernel (DIKernel), a new kernel architecture which securely isolates the untrusted kernel extensions with minimal performance overhead. DIKernel leverages hardware-based memory domain feature in ARM architecture; and prevents system manipulation attacks originated from kernel extensions, such as rootkits and exploits caused by buggy kernel extensions. We implemented DIKernel on top of Linux 4.13 kernel with 1500 LOC. Performance evaluation indicates that DIKernel imposes negligible overhead which is observed by cycle level microbenchmark.},
author = {Man{\`{e}}s, Valentin J.M. and Jang, Daehee and Ryu, Chanho and Kang, Brent Byunghoon},
doi = {10.1016/j.cose.2018.01.009},
file = {:F\:/papers/1-s2.0-S0167404818300282-main.pdf:pdf},
issn = {01674048},
journal = {Computers and Security},
keywords = {ARM,DACR,Extension,Kernel,Rootkit,Software vulnerability},
pages = {130--143},
publisher = {Elsevier Ltd},
title = {{Domain Isolated Kernel: A lightweight sandbox for untrusted kernel extensions}},
url = {https://doi.org/10.1016/j.cose.2018.01.009},
volume = {74},
year = {2018}
}
@techreport{Zhou,
abstract = {We present SafeDrive, a system for detecting and recovering from type safety violations in software extensions. SafeDrive has low overhead and requires minimal changes to existing source code. To achieve this result, SafeDrive uses a novel type system that provides fine-grained isolation for existing extensions written in C. In addition, SafeDrive tracks invariants using simple wrappers for the host system API and restores them when recovering from a violation. This approach achieves fine-grained memory error detection and recovery with few code changes and at a significantly lower performance cost than existing solutions based on hardware-enforced domains, such as Nooks [33], L4 [21], and Xen [13], or software-enforced domains, such as SFI [35]. The principles used in SafeDrive can be applied to any large system with loadable, error-prone extension modules. In this paper we describe our experience using SafeDrive for protection and recovery of a variety of Linux device drivers. In order to apply SafeDrive to these device drivers, we had to change less than 4% of the source code. SafeDrive recovered from all 44 crashes due to injected faults in a network card driver. In experiments with 6 different drivers, we observed increases in kernel CPU utilization of 4-23% with no noticeable degradation in end-to-end performance.},
author = {Zhou, Feng and Condit, Jeremy and Anderson, Zachary and Bagrak, Ilya and Ennals, Rob and Harren, Matthew and Necula, George and Brewer, Eric},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - Unknown - SafeDrive Safe and Recoverable Extensions Using Language-Based Techniques.pdf:pdf},
title = {{SafeDrive: Safe and Recoverable Extensions Using Language-Based Techniques}}
}
@book{Giger2012,
abstract = {Researchers proposed a wide range of approaches to build effective bug prediction models that take into account multiple aspects of the software development process. Such models achieved good prediction performance, guiding developers towards those parts of their system where a large share of bugs can be expected. However, most of those approaches predict bugs on file-level. This often leaves developers with a considerable amount of effort to examine all methods of a file until a bug is located. This particular problem is reinforced by the fact that large files are typically predicted as the most bug-prone. In this paper, we present bug prediction models at the level of individual methods rather than at file-level. This increases the granularity of the prediction and thus reduces manual inspection efforts for developers. The models are based on change metrics and source code metrics that are typically used in bug prediction. Our experiments-performed on 21 Java open-source (sub-)systems-show that our prediction models reach a precision and recall of 84% and 88%, respectively. Furthermore, the results indicate that change metrics significantly outperform source code metrics.},
author = {Giger, Emanuel and Ambros, Marco D ' and Pinzger, Martin and Nl, M Pinzger@tudelft and Gall, Harald C},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Giger et al. - 2012 - Method-Level Bug Prediction.pdf:pdf},
isbn = {9781450310567},
keywords = {D28 [Software Engineering]: Metrics-complexity mea,code metrics,fine-grained source code changes,process metrics,product metrics Keywords method-level bug predicti},
title = {{Method-Level Bug Prediction}},
url = {http://svn.apache.org/repos/asf/ant/core/trunk},
year = {2012}
}
@article{Canella2020,
abstract = {In this paper, we analyze the hardware-based Meltdown mitigations in recent Intel microarchitectures, revealing that illegally accessed data is only zeroed out. Hence, while non-present loads stall the CPU, illegal loads are still executed. We present EchoLoad, a novel technique to distinguish load stalls from transiently executed loads. EchoLoad allows detecting physically-backed addresses from unprivileged applications, breaking KASLR in 40's on the newest Meltdown- and MDS-resistant Cascade Lake microarchitecture. As EchoLoad only relies on memory loads, it runs in highly-restricted environments, e.g., SGX or JavaScript, making it the first JavaScript-based KASLR break. Based on EchoLoad, we demonstrate the first proof-of-concept Meltdown attack from JavaScript on systems that are still broadly not patched against Meltdown, i.e., 32-bit x86 OSs. We propose FLARE, a generic mitigation against known microarchitectural KASLR breaks with negligible overhead. By mapping unused kernel addresses to a reserved page and mirroring neighboring permission bits, we make used and unused kernel memory indistinguishable, i.e., a uniform behavior across the entire kernel address space, mitigating the root cause behind microarchitectural KASLR breaks. With incomplete hardware mitigations, we propose to deploy FLARE even on recent CPUs.},
author = {Canella, Claudio and Schwarz, Michael and Haubenwallner, Martin and Schwarzl, Martin and Gruss, Daniel},
doi = {10.1145/3320269.3384747},
file = {:F\:/D2/3320269.3384747.pdf:pdf},
isbn = {9781450367509},
journal = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2020},
keywords = {KASLR,countermeasure,meltdown,reverse engineering,side-channel attack,transient execution},
pages = {481--493},
title = {{KASLR: Break It, Fix It, Repeat}},
year = {2020}
}
@article{Proskurin2020,
abstract = {Attackers leverage memory corruption vulnerabil-ities to establish primitives for reading from or writing to the address space of a vulnerable process. These primitives form the foundation for code-reuse and data-oriented attacks. While various defenses against the former class of attacks have proven effective, mitigation of the latter remains an open problem. In this paper, we identify various shortcomings of the x86 architecture regarding memory isolation, and leverage virtual-ization to build an effective defense against data-oriented attacks. Our approach, called xMP, provides (in-guest) selective memory protection primitives that allow VMs to isolate sensitive data in user or kernel space in disjoint xMP domains. We interface the Xen altp2m subsystem with the Linux memory management system, lending VMs the flexibility to define custom policies. Contrary to conventional approaches, xMP takes advantage of virtualization extensions, but after initialization, it does not require any hypervisor intervention. To ensure the integrity of in-kernel management information and pointers to sensitive data within isolated domains, xMP protects pointers with HMACs bound to an immutable context, so that integrity validation succeeds only in the right context. We have applied xMP to protect the page tables and process credentials of the Linux kernel, as well as sensitive data in various user-space applications. Overall, our evaluation shows that xMP introduces minimal overhead for real-world workloads and applications, and offers effective protection against data-oriented attacks.},
author = {Proskurin, Sergej and Momeu, Marius and Ghavamnia, Seyedhamed and Kemerlis, Vasileios P. and Polychronakis, Michalis},
doi = {10.1109/sp40000.2020.00041},
file = {:F\:/D2/09152671.pdf:pdf},
pages = {563--577},
title = {{xMP: Selective Memory Protection for Kernel and User Space}},
year = {2020}
}
@article{Lee2018a,
abstract = {Intel memory protection keys (MPK) is a new hardware feature to support thread-local permission control on groups of pages without requiring modification of page tables. Unfortunately, its current hardware implementation and software supports suffer from security, scalability, and semantic-gap problems: (1) MPK is vulnerable to protection-key-use-afterfree and protection-key corruption; (2) MPK does not scale due to hardware limitations; and (3) MPK is not perfectly compatible with mprotect() because it does not support permission synchronization across threads. In this paper, we propose libmpk, a software abstraction for MPK. libmpk virtualizes protection keys to eliminate the protection-key-use-after-free and protection-key corruption problems while supporting a tremendous number of memory page groups. libmpk also prevents unauthorized writes to its metadata and supports inter-thread key synchronization. We apply libmpk to three real-world applications: OpenSSL, JavaScript JIT compiler, and Memcached for memory protection and isolation. An evaluation shows that libmpk introduces negligible performance overhead (<1%) compared with insecure versions, and improves their performance by 8.1× over secure equivalents using mprotect(). The source code of libmpk will be publicly available and maintained as an open source project.},
author = {Lee, Soyeon Park Sangho and Moon, Wen Xu Hyungon and Kim, Taesoo},
file = {:F\:/D2/atc19-park-soyeon.pdf:pdf},
isbn = {9781939133038},
journal = {arXiv},
title = {{libmpk: Software abstraction for intel memory protection keys}},
year = {2018}
}
@article{Raj2017,
author = {Raj, Abhilash},
file = {:F\:/D2/thesis.pdf:pdf},
pages = {1--84},
title = {{A Decade of Linux Kernel Vulnerabilities, their Mitigation and Open Problems}},
year = {2017}
}
@article{VanDerVeen2017,
abstract = {In 2007, Shacham published a seminal paper on Return-Oriented Programming (ROP), the first systematic formulation of code reuse. The paper has been highly influential, profoundly shaping the way we still think about code reuse today: an attacker analyzes the "ge-ometry" of victim binary code to locate gadgets and chains these to craft an exploit. This model has spurred much research, with a rapid progression of increasingly sophisticated code reuse attacks and defenses over time. After ten years, the common perception is that state-of-the-art code reuse defenses are effective in significantly raising the bar and making attacks exceedingly hard. In this paper, we challenge this perception and show that an attacker going beyond "geometry" (static analysis) and considering the "dynamics" (dynamic analysis) of a victim program can easily find function call gadgets even in the presence of state-of-the-art code-reuse defenses. To support our claims, we present Newton, a run-time gadget-discovery framework based on constraint-driven dynamic taint analysis. Newton can model a broad range of defenses by mapping their properties into simple, stackable, reusable constraints, and automatically generate gadgets that comply with these constraints. Using Newton, we systematically map and compare state-of-the-art defenses, demonstrating that even simple interactions with popular server programs are adequate for finding gadgets for all state-of-the-art code-reuse defenses. We conclude with an nginx case study, which shows that a Newton-enabled attacker can craft attacks which comply with the restrictions of advanced defenses, such as CPI and context-sensitive CFI.},
author = {{Van Der Veen}, Victor and Andriesse, Dennis and Stamatogiannakis, Manolis and Chen, Xi and Bos, Herbert and Giuffrida, Cristiano},
doi = {10.1145/3133956.3134026},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Der Veen et al. - 2017 - The Dynamics of Innocent Flesh on the Bone Code Reuse Ten Years Later.pdf:pdf},
isbn = {9781450349468},
title = {{The Dynamics of Innocent Flesh on the Bone: Code Reuse Ten Years Later}},
url = {https://doi.org/http://dx.doi.org/10.1145/3133956.3134026},
year = {2017}
}
@article{Goktas2020,
abstract = {To defeat ASLR or more advanced fine-grained and leakage-resistant code randomization schemes, modern software exploits rely on information disclosure to locate gadgets inside the victim's code. In the absence of such info-leak vulnerabilities, attackers can still hack blind and derandomize the address space by repeatedly probing the victim's memory while observing crash side effects, but doing so is only feasible for crash-resistant programs. However, high-value targets such as the Linux kernel are not crash-resistant. Moreover, the anomalously large number of crashes is often easily detectable. In this paper, we show that the Spectre era enables an attacker armed with a single memory corruption vulnerability to hack blind without triggering any crashes. Using speculative execution for crash suppression allows the elevation of basic memory write vulnerabilities into powerful speculative probing primitives that leak through microarchitectural side effects. Such primitives can repeatedly probe victim memory and break strong randomization schemes without crashes and bypass all deployed mitigations against Spectre-like attacks. The key idea behind speculative probing is to break Spectre mitigations using memory corruption and resurrect Spectre-style disclosure primitives to mount practical blind software exploits. To showcase speculative probing, we target the Linux kernel, a crash-sensitive victim that has so far been out of reach of blind attacks, mount end-to-end exploits that compromise the system with just-in-time code reuse and data-only attacks from a single memory write vulnerability, and bypass strong Spectre and strong randomization defenses. Our results show that it is crucial to consider synergies between different (Spectre vs. code reuse) threat models to fully comprehend the attack surface of modern systems.},
author = {G{\"{o}}ktas, Enes and Razavi, Kaveh and Portokalidis, Georgios and Bos, Herbert and Giuffrida, Cristiano},
doi = {10.1145/3372297.3417289},
file = {:F\:/D2/3372297.3417289.pdf:pdf},
isbn = {9781450370899},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {code-reuse attacks,speculative execution},
pages = {1871--1885},
title = {{Speculative Probing: Hacking Blind in the Spectre Era}},
year = {2020}
}
@article{Li2019,
abstract = {This paper presents MiniBox, the first two-way sandbox for x86 native code, that not only protects a benign OS from a misbehaving application, but also protects an application from a malicious OS. MiniBox can be applied in Platform-as-a-Service cloud computing to provide two-way protection between a customer's application and the cloud platform OS. We implement a MiniBox prototype running on recent x86 multi-core systems from Intel or AMD, and we port several applications to MiniBox. Evaluation results show that MiniBox is efficient and practical.},
author = {Li, Yanlin and McCune, Jonathan and Baker, Brandon and Newsome, James and Drewry, Will and Perrig, Adrian},
file = {:F\:/D2/atc14-paper-li_yanlin.pdf:pdf},
isbn = {9781931971102},
journal = {Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014},
pages = {409--420},
title = {{Minibox: A two-way sandbox for x86 native code}},
year = {2019}
}
@article{Gens2018,
abstract = {Operating system kernels are appealing attack targets: compromising the kernel usually allows attackers to bypass all deployed security mechanisms and take control over the entire system. Commodity kernels, like Linux, are written in low-level programming languages that offer only limited type and memory-safety guarantees, enabling adversaries to launch sophisticated run-time attacks against the kernel by exploiting memory-corruption vulnerabilities. Many defenses have been proposed to protect operating systems at run time, such as control-flow integrity (CFI). However, the goal of these run-time monitors is to prevent exploitation as a symptom of memory corruption, rather than eliminating the underlying root cause, i.e., bugs in the kernel code. While finding bugs can be automated, e.g., using static analysis, all existing approaches are limited to local, intra-procedural checks, and face severe scalability challenges due to the large kernel code base. Consequently, there currently exist no tools for conducting global static analysis of operating system kernels. In this paper, we present K-Miner, a new framework to efficiently analyze large, commodity operating system kernels like Linux. Our novel approach exploits the highly standardized interface structure of the kernel code to enable scalable pointer analysis and conduct global, context-sensitive analysis. Through our inter-procedural analysis we show that K-Miner systematically and reliably uncovers several different classes of memory-corruption vulnerabilities, such as dangling pointers, user-after-free, double-free, and double-lock vulnerabilities. We thoroughly evaluate our extensible analysis framework, which leverages the popular and widely used LLVM compiler suite, for the current Linux kernel and demonstrate its effectiveness by reporting several memory-corruption vulnerabilities.},
author = {Gens, David and Schmitt, Simon and Davi, Lucas and Sadeghi, Ahmad-Reza},
doi = {10.14722/ndss.2018.23326},
file = {:F\:/D2/ndss2018_05A-1_Gens_paper.pdf:pdf},
isbn = {1891562495},
number = {February},
title = {{K-Miner: Uncovering Memory Corruption in Linux}},
year = {2018}
}
@article{Zhang2019,
abstract = {Permission checks play an essential role in operating system security by providing access control to privileged functionali-ties. However, it is particularly challenging for kernel developers to correctly apply new permission checks and to scalably verify the soundness of existing checks due to the large code base and complexity of the kernel. In fact, Linux kernel contains millions of lines of code with hundreds of permission checks, and even worse its complexity is fast-growing. This paper presents PeX, a static Permission check error detector for LinuX, which takes as input a kernel source code and reports any missing, inconsistent, and redundant permission checks. PeX uses KIRIN (Kernel InteRface based Indirect call aNalysis), a novel, precise, and scalable indirect call analysis technique, leveraging the common programming paradigm used in kernel abstraction interfaces. Over the inter-procedural control flow graph built by KIRIN, PeX automatically identifies all permission checks and infers the mappings between permission checks and privileged functions. For each privileged function, PeX examines all possible paths to the function to check if necessary permission checks are correctly enforced before it is called. We evaluated PeX on the latest stable Linux kernel v4.18.5 for three types of permission checks: Discretionary Access Controls (DAC), Capabilities, and Linux Security Modules (LSM). PeX reported 36 new permission check errors, 14 of which have been confirmed by the kernel developers.},
author = {Zhang, Tong and Tech, Virginia and Shen, Wenbo and Azab, Ahmed M and Wang, Ruowen and Lee, Dongyoon and Jung, Changhee},
file = {:F\:/papers/Zhang et al. - 2019 - PeX A Permission Check Analysis Framework for Linux Kernel.pdf:pdf},
isbn = {9781939133069},
journal = {28th USENIX Security Symposium (2019)},
title = {{PeX: A Permission Check Analysis Framework for Linux Kernel}},
url = {https://www.usenix.org/conference/usenixsecurity19/presentation/zhang-tong},
year = {2019}
}
@article{Yavuz2019,
abstract = {Extensibility is an important design goal for software frameworks that are expected to evolve in a variety of dimensions. Callback mechanism is utilized extensively in large frameworks to achieve extensibility. However, callback mechanism introduces implicit control-flow dependencies that make program comprehension and analysis difficult. This paper presents an automated approach for detecting deep bugs/vulnerabilities that involve callbacks. Our approach consists of several stages to balance scalability and precision. Specifically, it uses a light-weight static analysis for extracting callback related interactions between the application modules and the framework modules. This information is used to extend the basic call graph of the application modules to incorporate implicit call chains due to callbacks. The second stage, summary mode, summarizes bug relevant data-flow facts for paths that start at callbacks. The third stage, summary-aware mode, uses the extended call graph to incorporate data-flow facts due to implicit paths that lead to the callbacks and detects deep bugs. We have implemented the presented model extraction and bug detection approach in a framework called MOXCAFE and applied it to Linux device drivers. Using our approach, we could detect several deep vulnerabilities.},
author = {Yavuz, Tuba},
doi = {10.1109/SecDev.2019.00018},
file = {:F\:/papers/08901555.pdf:pdf},
isbn = {9781538672891},
journal = {Proceedings - 2019 IEEE Secure Development, SecDev 2019},
keywords = {API misuse,Callbacks,Deep bugs,Model extraction,Static analysis},
pages = {62--75},
publisher = {IEEE},
title = {{Detecting callback related deep vulnerabilities in linux device drivers}},
year = {2019}
}
@article{Wang2020,
author = {Wang, Juan and shirong Hao and Hu, Hongxin and Zhao, Bo and Li, Hongda and Zhang, Wenhui and Xu, Jun and Liu, Peng and Ma, Jing},
doi = {10.1109/tcc.2020.2985045},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - S-Blocks Lightweight and Trusted Virtual Security Function with SGX.pdf:pdf},
journal = {IEEE Transactions on Cloud Computing},
number = {January 2019},
pages = {1--1},
title = {{S-Blocks: Lightweight and Trusted Virtual Security Function with SGX}},
year = {2020}
}
@article{Swift2002,
author = {Swift, Michael M. and Martin, Steven and Levy, Henry M. and Eggers, Susan J.},
doi = {10.1145/1133373.1133393},
file = {:F\:/D2/1133373.1133393.pdf:pdf},
journal = {Proceedings of the 10th Workshop on ACM SIGOPS European Workshop, EW 10},
number = {1},
pages = {102--107},
title = {{Nooks: An architecture for reliable device drivers}},
year = {2002}
}
@article{Cutler2018,
author = {Cutler, Cody and Kaashoek, M Frans and Morris, Robert T and Csail, M I T and Osdi, Implementation and Cutler, Cody and Kaashoek, M Frans and Morris, Robert T},
file = {:F\:/papers/osdi18-cutler.pdf:pdf},
isbn = {9781939133083},
title = {{The benefits and costs of writing a POSIX kernel in a high-level language This paper is included in the Proceedings of the}},
year = {2018}
}
@article{Wang2019,
abstract = {Information hiding (IH) is an important building block for many defenses against code reuse attacks, such as code-pointer integrity (CPI), control-flow integrity (CFI) and fine-grained code (re-)randomization, because of its effectiveness and performance. It employs randomization to probabilistically “hide” sensitive memory areas, called safe areas, from attackers and ensures their addresses are not leaked by any pointers directly. These defenses used safe areas to protect their critical data, such as jump targets and randomization secrets. However, recent works have shown that IH is vulnerable to various attacks. In this paper, we propose a new IH technique called SafeHidden. It continuously re-randomizes the locations of safe areas and thus prevents the attackers from probing and inferring the memory layout to find its location. A new thread-private memory mechanism is proposed to isolate the thread-local safe areas and prevent adversaries from reducing the randomization entropy. It also randomizes the safe areas after the TLB misses to prevent attackers from inferring the address of safe areas using cache side-channels. Existing IH-based defenses can utilize SafeHidden directly without any change. Our experiments show that SafeHidden not only prevents existing attacks effectively but also incurs low performance overhead.},
author = {Wang, Zhe and Wu, Chenggang and Zhang, Yinqian and Tang, Bowen and Yew, Pen Chung and Xie, Mengyao and Lai, Yuanming and Kang, Yan and Cheng, Yueqiang and Shi, Zhiping},
file = {:F\:/D2/sec19-wang-zhe.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1239--1256},
title = {{Safehidden: An efficient and secure information hiding technique using re-randomization}},
year = {2019}
}
@article{Bosman2014,
abstract = {Signal handling has been an integral part of UNIX systems since the earliest implementation in the 1970s. Nowadays, we find signals in all common flavors of UNIX systems, including BSD, Linux, Solaris, Android, and Mac OS. While each flavor handles signals in slightly different ways, the implementations are very similar. In this paper, we show that signal handling can be used as an attack method in exploits and backdoors. The problem has been a part of UNIX from the beginning, and now that advanced security measures like ASLR, DEP and stack cookies have made simple exploitation much harder, our technique is among the lowest hanging fruit available to an attacker. Specifically, we describe Sigreturn Oriented Programming (SROP), a novel technique for exploits and backdoors in UNIX-like systems. Like return-oriented programming (ROP), sigreturn oriented programming constructs what is known as a 'weird machine' that can be programmed by attackers to change the behavior of a process. To program the machine, attackers set up fake signal frames and initiate returns from signals that the kernel never really delivered. This is possible, because UNIX stores signal frames on the process' stack. Sigreturn oriented programming is interesting for attackers, OS developers and academics. For attackers, the technique is very versatile, with pre-conditions that are different from those of existing exploitation techniques like ROP. Moreover, unlike ROP, sigreturn oriented programming programs are portable. For OS developers, the technique presents a problem that has been present in one of the two main operating system families from its inception, while the fixes (which we also present) are non-trivial. From a more academic viewpoint, it is also interesting because we show that sigreturn oriented programming is Turing complete. We demonstrate the usefulness of the technique in three applications. First, we describe the exploitation of a vulnerable web server on different Linux distributions. Second, we build a very stealthy proof-of-concept backdoor. Third, we use SROP to bypass Apple's code signing and security vetting process by building an app that can execute arbitrary system calls. Finally, we discuss mitigation techniques.},
author = {Bosman, Erik and Bos, Herbert},
doi = {10.1109/SP.2014.23},
file = {:F\:/papers/Bosman, Bos - 2014 - Framing signals - A return to portable shellcode.pdf:pdf},
isbn = {9781479946860},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Operatings system security,backdoors,exploits},
pages = {243--258},
title = {{Framing signals - A return to portable shellcode}},
year = {2014}
}
@article{Tian2019a,
abstract = {Modern computer peripherals are diverse in their capabilities and functionality, ranging from keyboards and printers to smartphones and external GPUs. In recent years, peripherals increasingly connect over a small number of standardized communication protocols, including USB, Bluetooth, and NFC. The host operating system is responsible for managing these devices; however, malicious peripherals can request additional functionality from the OS resulting in system compromise, or can craft data packets to exploit vulnerabilities within OS software stacks. Defenses against malicious peripherals to date only partially cover the peripheral attack surface and are limited to specific protocols (e.g., USB). In this paper, we propose Linux (e)BPF Modules (LBM), a general security framework that provides a unified API for enforcing protection against malicious peripherals within the Linux kernel. LBM leverages the eBPF packet filtering mechanism for performance and extensibility and we provide a high-level language to facilitate the development of powerful filtering functionality. We demonstrate how LBM can provide host protection against malicious USB, Bluetooth, and NFC devices; we also instantiate and unify existing defenses under the LBM framework. Our evaluation shows that the overhead introduced by LBM is within 1 $\mu$s per packet in most cases, application and system overhead is negligible, and LBM outperforms other state-of-the-art solutions. To our knowledge, LBM is the first security framework designed to provide comprehensive protection against malicious peripherals within the Linux kernel.},
author = {Tian, Dave Jing and Hernandez, Grant and Choi, Joseph I. and Frost, Vanessa and Johnson, Peter C. and Butler, Kevin R.B.},
doi = {10.1109/SP.2019.00041},
file = {:F\:/D2/08835285.pdf:pdf},
isbn = {9781538666609},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Bluetooth,EBPF,Linux-Kernel,Peripheral,USB},
pages = {967--984},
publisher = {IEEE},
title = {{LBM: A security framework for peripherals within the linux kernel}},
volume = {2019-May},
year = {2019}
}
@article{Wu2019,
abstract = {Automatic exploit generation is a challenging problem. A challenging part of the task is to connect an identified exploitable state (exploit primitive) to triggering execution of code-reuse (e.g., ROP) payload. A control-flow hijacking primitive is one of the most common capabilities for exploitation. However, due to the challenges of widely deployed exploit mitigations, pitfalls along an exploit path, and ill-suited primitives, it is difficult to even manually craft an exploit with a control-flow hijacking primitive for an off-the-shelf modern Linux kernel. We propose KEPLER to facilitate exploit generation by automatically generating a “single-shot” exploitation chain. KEPLER accepts as input a control-flow hijacking primitive and bootstraps any kernel ROP payload by symbolically stitching an exploitation chain taking advantage of prevalent kernel coding style and corresponding gadgets. Comparisons with previous automatic exploit generation techniques and previous kernel exploit techniques show KEPLER effectively facilitates evaluation of control-flow hijacking primitives in the Linux kernel.},
author = {Wu, Wei and Chen, Yueqi and Xing, Xinyu and Zou, Wei},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - Kepler Facilitating control-flow hijacking primitive evaluation for linux kernel vulnerabilities.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1187--1204},
title = {{Kepler: Facilitating control-flow hijacking primitive evaluation for linux kernel vulnerabilities}},
year = {2019}
}
@article{Nelson2019,
abstract = {This paper presents Serval, a framework for developing automated verifiers for systems software. Serval provides an extensible infrastructure for creating verifiers by lifting interpreters under symbolic evaluation, and a systematic approach to identifying and repairing verification performance bottlenecks using symbolic profiling and optimizations. Using Serval, we build automated verifiers for the RISC-V, x86-32, LLVM, and BPF instruction sets. We report our experience of retrofitting CertiKOS and Komodo, two systems previously verified using Coq and Dafny, respectively, for automated verification using Serval, and discuss trade-offs of different verification methodologies. In addition, we apply Serval to the Keystone security monitor and the BPF compilers in the Linux kernel, and uncover 18 new bugs through verification, all confirmed and fixed by developers.},
author = {Nelson, Luke and Bornholt, James and Gu, Ronghui and Baumann, Andrew and Torlak, Emina and Wang, Xi},
doi = {10.1145/3341301.3359641},
file = {:F\:/D2/Serval_Scaling_Symbolic_Evaluation_for_Automated_Verification_of_Systems_code_SOSP2019_BEST.pdf:pdf},
isbn = {9781450368735},
journal = {SOSP 2019 - Proceedings of the 27th ACM Symposium on Operating Systems Principles},
pages = {225--242},
title = {{Scaling symbolic evaluation for automated verification of systems code with serval}},
year = {2019}
}
@article{Shinagawa2009,
author = {Shinagawa, Takahiro},
file = {:F\:/D2/1508293.1508311.pdf:pdf},
isbn = {9781605583754},
keywords = {hypervisors,parapass-through,puting base,shadow dma descriptor,trusted com-,virtual machine monitors},
pages = {121--130},
title = {{BitVisor : A Thin Hypervisor for Enforcing I / O Device Security}},
year = {2009}
}
@article{Das2019,
abstract = {Hardware Performance Counters (HPCs) have been available in processors for more than a decade. These counters can be used to monitor and measure events that occur at the CPU level. Modern processors provide hundreds of hardware events that can be monitored, and with each new processor architecture more are added. Yet, there has been little in the way of systematic studies on how performance counters can best be utilized to accurately monitor events in real-world settings. Especially when it comes to the use of HPCs for security applications, measurement imprecisions or incorrect assumptions regarding the measured values can undermine the offered protection. To shed light on this issue, we embarked on a year-long effort to (i) study the best practices for obtaining accurate measurement of events using performance counters, (ii) understand the challenges and pitfalls of using HPCs in various settings, and (iii) explore ways to obtain consistent and accurate measurements across different settings and architectures. Additionally, we then empirically evaluated the way HPCs have been used throughout a wide variety of papers. Not wanting to stop there, we explored whether these widely used techniques are in fact obtaining performance counter data correctly. As part of that assessment, we (iv) extended the seminal work of Weaver and McKee from almost 10 years ago on non-determinism in HPCs, and applied our findings to 56 papers across various application domains. In that follow-up study, we found the acceptance of HPCs in security applications is in stark contrast to other application areas - especially in the last five years. Given that, we studied an additional representative set of 41 works from the security literature that rely on HPCs, to better elucidate how the intricacies we discovered can impact the soundness and correctness of their approaches and conclusions. Toward that goal, we (i) empirically evaluated how failure to accommodate for various subtleties in the use of HPCs can undermine the effectiveness of security applications, specifically in the case of exploit prevention and malware detection. Lastly, we showed how (ii) an adversary can manipulate HPCs to bypass certain security defenses.},
author = {Das, Sanjeev and Werner, Jan and Antonakakis, Manos and Polychronakis, Michalis and Monrose, Fabian},
doi = {10.1109/SP.2019.00021},
file = {:F\:/D2/08835366.pdf:pdf},
isbn = {9781538666609},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Exploit-Defense,Hardware-Performance-Counters,Malware-Detection,Non-determinism},
pages = {20--38},
publisher = {IEEE},
title = {{SoK: The challenges, pitfalls, and perils of using hardware performance counters for security}},
volume = {2019-May},
year = {2019}
}
@article{Xiong2011,
abstract = {Kernel extensions are widely used by attackers to com- promise the operating system kernel. With the presence of various untrusted extensions, it remains a challenging prob- lem to comprehensively preserve the integrity of OS kernels in a practical and generic way. In this paper, we present HUKO, a hypervisor-based integrity protection system de- signed to protect commodity OS kernels from untrusted ex- tensions. In HUKO system, untrusted kernel extensions can safely run to provide desired functionalities. The behaviors of untrusted extensions, however, are confined by manda- tory access control policies, which significantly limit the attackers ability to compromise the integrity of the ker- nel. To guarantee multi-aspect protection and enforcement, HUKOleverages hardware assisted paging to transparently isolate untrusted extensions from the OS kernel. Moreover, HUKO overcomes the challenge of mediation overhead by introducing a novel design named subject-aware protection state transition to eliminate unnecessary privilege transi- tions caused by mediating allowed accesses. Our approach is practical because it requires little change for either OS kernel or extensions, and it can inherently support multiple commodity operating systems and legacy extensions. We have implemented a prototype of HUKO based on the open source Xen hypervisor. The evaluation results show that HUKO can comprehensively protect the integrity for both Linux and Windows kernel from various kinds of malicious extensions with an acceptable performance cost.},
author = {Xiong, Xi and Tian, Donghai and Liu, Peng},
file = {:F\:/papers/Xiong, Tian, Liu - 2011 - Practical Protection of Kernel Integrity for Commodity OS from Untrusted Extensions.pdf:pdf},
journal = {Ndss},
title = {{Practical Protection of Kernel Integrity for Commodity OS from Untrusted Extensions.}},
year = {2011}
}
@article{Cheng2018,
abstract = {Binary packing, encoding binary code prior to execution and decoding them at run time, is the most common obfuscation adopted by malware authors to camouflage malicious code. Especially, most packers recover the original code by going through a set of “written-then-executed” layers, which renders determining the end of the unpacking increasingly difficult. Many generic binary unpacking approaches have been proposed to extract packed binaries without the prior knowledge of packers. However, the high runtime overhead and lack of anti-analysis resistance have severely limited their adoptions. Over the past two decades, packed malware is always a veritable challenge to anti-malware landscape. This paper revisits the long-standing binary unpacking problem from a new angle: packers consistently obfuscate the standard use of API calls. Our in-depth study on an enormous variety of Windows malware packers at present leads to a common property: malware's Import Address Table (IAT), which acts as a lookup table for dynamically linked API calls, is typically erased by packers for further obfuscation; and then unpacking routine, like a custom dynamic loader, will reconstruct IAT before original code resumes execution. During a packed malware execution, if an API is invoked through looking up a rebuilt IAT, it indicates that the original payload has been restored. This insight motivates us to design an efficient unpacking approach, called BinUnpack. Compared to the previous methods that suffer from multiple “written-then-executed” unpacking layers, BinUnpack is free from tedious memory access monitoring, and therefore it introduces very small runtime overhead. To defeat a variety of ever-evolving evasion tricks, we design BinUnpack's API monitor module via a novel kernel-level DLL hijacking technique. We have evaluated BinUnpack's efficacy extensively with more than 238K packed malware and multiple Windows utilities. BinUnpack's success rate is significantly better than that of existing tools with several orders of magnitude performance boost. Our study demonstrates that BinUnpack can be applied to speeding up large-scale malware analysis.},
author = {Cheng, Binlin and Ming, Jiang and Fu, Jianming and Peng, Guojun and Chen, Ting and Zhang, Xiaosong and Marion, Jean Yves},
doi = {10.1145/3243734.3243771},
file = {:F\:/papers/Cheng et al. - 2018 - Towards paving the way for large-scale Windows malware analysis Generic binary unpacking with orders-of-magnitude.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Windows Malware Analysis, Generic Binary Unpacking},
pages = {395--411},
title = {{Towards paving the way for large-scale Windows malware analysis: Generic binary unpacking with orders-of-magnitude performance boost}},
year = {2018}
}
@book{Frassetto,
abstract = {Memory-corruption attacks have been subject to extensive research in the latest decades. Researchers demonstrated sophisticated attack techniques, such as (just-in-time/blind) return-oriented programming and counterfeit object-oriented programming, which enable the attacker to execute arbitrary code and data-oriented attacks that are commonly used for privilege escalation. At the same time, the research community proposed a number of effective defense techniques. In particular, control-flow integrity (CFI), code-pointer integrity (CPI), and fine-grained code randomization are effective mitigation techniques against code-reuse attacks. All of these techniques require strong memory isolation. For example, CFI's shadow stack, CPI's safe-region, and the random-ization secret must be protected from adversaries able to perform arbitrary read-write accesses. In this paper we propose IMIX, a lightweight, in-process memory isolation extension for the Intel-based x86 CPUs. Our solution extends the x86 ISA with a new memory-access permission to mark memory pages as security sensitive. These memory pages can then only be accessed with a newly introduced instruction. Unlike previous work, IMIX is not tailored towards a specific defense (technique) but can be leveraged as a primitive to protect the data of a wide variety of memory-corruption defenses. We provide a proof of concept of IMIX using Intel's Simulation and Analysis Engine. We extend Clang/LLVM to include our new instruction, and enhance CPI by protecting CPI's safe region using IMIX.},
author = {Frassetto, Tommaso and Jauernig, Patrick and Liebchen, Christopher and Sadeghi, Ahmad-Reza},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frassetto et al. - Unknown - IMIX In-Process Memory Isolation EXtension(2).pdf:pdf},
isbn = {978-1-939133-04-5},
title = {{ IMIX: In-Process Memory Isolation EXtension}},
url = {https://www.usenix.org/conference/usenixsecurity18/presentation/frassetto}
}
@techreport{Negi,
abstract = {In this work we use Machine Learning (ML) techniques to learn the CPU time-slice utilization behavior of known programs in a Linux system. Learning is done by an analysis of certain static and dynamic attributes of the processes while they are being run. Our objective was to discover the most important static and dynamic attributes of the processes that can help best in prediction of CPU burst times which minimize the process TaT (Turn-around-Time). In our experimentation we modify the Linux Kernel scheduler (version 2.4.20-8) to allow scheduling with customized time slices. The "Waikato Environment for Knowledge Analysis" (Weka), an open source machine-learning tool is used to find the most suitable ML method to characterize our programs. We experimentally find that the C4.5 Decision Tree algorithm most effectively solved the problem. We find that predictive scheduling could reduce TaT in the range of 1.4% to 5.8%. This was due to a reduction in the number of context switches needed to complete the process execution. We find our result interesting in the context that generally operating systems presently never make use of a program's previous execution history in their scheduling behavior.},
author = {Negi, Atul and Member, Senior and Kumar, Kishore P},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Negi, Member, Kumar - Unknown - Applying Machine Learning Techniques to improve Linux Process Scheduling.pdf:pdf},
keywords = {Index Terms-Machine learning,Process Scheduling,turn-around-time},
title = {{Applying Machine Learning Techniques to improve Linux Process Scheduling}}
}
@book{Sun,
abstract = {Lightweight virtualization (i.e., containers) offers a virtual host environment for applications without the need for a separate kernel, enabling better resource utilization and improved efficiency. However, the shared kernel also prevents containers from taking advantage of security features that are available to traditional VMs and hosts. Containers cannot apply local policies to govern integrity measurement, code execution, mandatory access control, etc. to prevent application-specific security problems. Changes have been proposed to make kernel security mechanisms available to containers, but such changes are often adhoc and expose the challenges of trusting containers to make security decisions without compromising host system or other containers. In this paper, we propose security namespaces, a kernel abstraction that enables containers to have an autonomous control over their security. The security namespace relaxes the global and mandatory assumption of kernel security frameworks, thus enabling containers to independently define security policies and apply them to a limited scope of processes. To preserve security, we propose a routing mechanism that can dynamically dispatch an operation to a set of containers whose security might be affected by the operation, therefore ensuring the security decision made by one container cannot compromise the host or other containers. We demonstrate security namespace by developing namespaces for integrity measurement and mandatory access control in the Linux kernel for use by Docker containers. Results show that security names-paces can effectively mitigate security problems within containers (e.g., malicious code execution) with less than 0.7% additional latency to system call and almost identical application throughput. As a result, security names-paces enable containers to obtain autonomous control over their security without compromising the security of other containers or the host system.},
author = {Sun, Yuqiong and Zohar, Mimi and Pendarakis, Dimitrios and Gu, Zhongshu and Safford, David and Jaeger, Trent},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - Unknown - Security Namespace Making Linux Security Frameworks Available to Containers Security Namespace Making Linux Se(2).pdf:pdf},
isbn = {978-1-939133-04-5},
title = {{Security Namespace: Making Linux Security Frameworks Available to Containers Security Namespace : Making Linux Security Frameworks Available to Containers}},
url = {www.usenix.org/conference/usenixsecurity18/presentation/sun}
}
@article{Ghavamnia2020,
abstract = {Attack surface reduction through the removal of unnecessary application features and code is a promising technique for improving security without incurring any additional overhead. Recent software debloating techniques consider an application's entire lifetime when extracting its code requirements, and reduce the attack surface accordingly. In this paper, we present temporal specialization, a novel approach for limiting the set of system calls available to a process depending on its phase of execution. Our approach is tailored to server applications, which exhibit distinct initialization and serving phases with different system call requirements. We present novel static analysis techniques for improving the precision of extracting the application's call graph for each execution phase, which is then used to pinpoint the system calls used in each phase. We show that requirements change throughout the lifetime of servers, and many dangerous system calls (such as execve) can be disabled after the completion of the initialization phase. We have implemented a prototype of temporal specialization on top of the LLVM compiler, and evaluated its effectiveness with six popular server applications. Our results show that it disables 51% more security-critical system calls compared to existing library specialization approaches, while offering the additional benefit of neutralizing 13 more Linux kernel vulnerabilities that could lead to privilege escalation.},
author = {Ghavamnia, Seyedhamed and Palit, Tapti and Mishra, Shachee and Polychronakis, Michalis},
file = {:F\:/D2/sec20-ghavamnia.pdf:pdf},
isbn = {9781939133175},
journal = {Proceedings of the 29th USENIX Security Symposium},
pages = {1749--1766},
title = {{Temporal system call specialization for attack surface reduction}},
year = {2020}
}
@article{Wang2018a,
abstract = {Automatic exploit generation is an open challenge. Existing solutions usually explore in depth the crashing paths, i.e., paths taken by proof-of-concept (PoC) inputs triggering vulnerabilities, and generate exploits when exploitable states are found along the paths. However, exploitable states do not always exist in crashing paths. Moreover, existing solutions heavily rely on symbolic execution and are not scalable in path exploration and exploit generation. In addition, few solutions could exploit heap-based vulnerabilities. In this paper, we propose a new solution Revery to search for exploitable states in paths diverging from crashing paths, and generate control-flow hijacking exploits for heap-based vulnerabilities. It adopts three novel techniques: (1) a layout-contributor digraph to characterize a vulnerability's memory layout and its contributor instructions; (2) a layout-oriented fuzzing solution to explore diverging paths, which have similar memory layouts as the crashing paths, in order to search more exploitable states and generate corresponding diverging inputs; (3) a control-flow stitching solution to stitch crashing paths and diverging paths together, and synthesize EXP inputs able to trigger both vulnerabilities and exploitable states. We have developed a prototype of Revery based on the binary analysis engine angr, and evaluated it on a set of 19 CTF (capture the flag) programs. Experiment results showed that it could generate exploits for 9 (47%) of them, and generate EXP inputs able to trigger exploitable states for another 5 (26%) of them.},
author = {Wang, Yan and Zhao, Zixuan and Liu, Bingchang and Zhang, Chao and Li, Wenjie and Chen, Kaixiang and Xiang, Xiaobo and Gong, Xiaorui and Zou, Wei},
doi = {10.1145/3243734.3243847},
file = {:F\:/D2/3243734.3243847.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Exploit,Fuzzing,Symbolic execution,Taint analysis,Vulnerability},
pages = {1914--1927},
title = {{Revery: From proof-of-concept to exploitable (one step towards automatic exploit generation)}},
year = {2018}
}
@article{Shi2018,
abstract = {Virtual machine introspection (VMI) is one compelling technique to enhance system security in clouds. It is able to provide strong isolation between untrusted guests and security tools placed in guests, thereby enabling dependability of the security tools even if the guest has been compromised. Due to this benefit, VMI has been widely used for cloud security such as intrusion detection, security monitoring, and tampering forensics. However, existing VMI solutions suffer significant performance degradation mainly due to the high overhead upon frequent memory address translations and context-switches. This drawback limits its usage in many real-world scenarios, especially when fine-grained monitoring is desired. In this paper, we present ShadowMonitor, an effective VMI framework that enables efficient in-VM monitoring without imposing significant overhead. ShadowMonitor decomposes the whole monitoring system into two compartments and then assigns each compartment with isolated address space. By placing the monitored components in the protected compartment, ShadowMonitor guarantees the safety of both monitoring tools and guests. In addition, ShadowMonitor employs hardware-enforced instructions to design the gates across two compartments, thereby providing efficient switching between compartments. We have implemented ShadowMonitor on QEMU/KVM exploiting several hardware virtualization features. The experimental results show that ShadowMonitor could prevent several types of attacks and achieves 10× speedup over the existing method in terms of both event monitoring and overall application performance.},
author = {Shi, Bin and Cui, Lei and Li, Bo and Liu, Xudong and Hao, Zhiyu and Shen, Haiying},
doi = {10.1007/978-3-030-00470-5_31},
file = {:F\:/D2/Shi2018_Chapter_ShadowMonitorAnEffectiveIn-VMM.pdf:pdf},
isbn = {9783030004699},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Isolation,Monitor,Virtual machine introspection},
number = {Vmi},
pages = {670--690},
title = {{Shadowmonitor: An effective in-VM monitoring framework with hardware-enforced isolation}},
volume = {11050 LNCS},
year = {2018}
}
@article{Emamdoost2021,
author = {Emamdoost, Navid and Lu, Kangjie and Mccamant, Stephen},
file = {:F\:/D2/k-meld.pdf:pdf},
isbn = {1891562614},
journal = {NDSS},
number = {February},
title = {{Detecting Kernel Memory Leaks in Specialized Modules with Ownership Reasoning}},
year = {2021}
}
@article{Hu2016,
abstract = {As control-flow hijacking defenses gain adoption, it is important to understand the remaining capabilities of adversaries via memory exploits. Non-control data exploits are used to mount information leakage attacks or privilege escalation attacks program memory. Compared to control-flow hijacking attacks, such non-control data exploits have limited expressiveness, however, the question is: what is the real expressive power of non-control data attacks? In this paper we show that such attacks are Turing-complete. We present a systematic technique called data-oriented programming (DOP) to construct expressive non-control data exploits for arbitrary x86 programs. In the experimental evaluation using 9 programs, we identified 7518 data-oriented x86 gadgets and 5052 gadget dispatchers, which are the building blocks for DOP. 8 out of 9 real-world programs have gadgets to simulate arbitrary computations and 2 of them are confirmed to be able to build Turing-complete attacks. We build 3 end-to-end attacks to bypass randomization defenses without leaking addresses, to run a network bot which takes commands from the attacker, and to alter the memory permissions. All the attacks work in the presence of ASLR and DEP, demonstrating how the expressiveness offered by DOP significantly empowers the attacker.},
author = {Hu, Hong and Shinde, Shweta and Adrian, Sendroiu and Chua, Zheng Leong and Saxena, Prateek and Liang, Zhenkai},
doi = {10.1109/SP.2016.62},
file = {:F\:/D2/07546545.pdf:pdf},
isbn = {9781509008247},
journal = {Proceedings - 2016 IEEE Symposium on Security and Privacy, SP 2016},
pages = {969--986},
publisher = {IEEE},
title = {{Data-Oriented Programming: On the Expressiveness of Non-control Data Attacks}},
year = {2016}
}
@article{Vano-Garcia2020,
abstract = {Given the significance that the cloud paradigm has in modern society, it is extremely important to provide security to users at all levels, especially at the most fundamental ones since these are the most sensitive and potentially harmful in the event of an attack. However, the cloud computing paradigm brings new challenges in which security mechanisms are weakened or deactivated to improve profitability and exploitation of the available resources. Kernel randomization is an important security mechanism that is currently present in all main operating systems. Function-Granular Kernel Randomization is a new step that aims to be the future of the kernel randomization, because it provides much more security than current kernel randomization approaches. Unfortunately, function-granular kernel randomization also impacts significantly on the performance and potential benefits of memory deduplication. Both function-granular kernel randomization and memory deduplication are desired and beneficial; the first for the strong protection it gives, and the second for the reduction of costs in terms of memory consumption. In this paper, we analyse the impact of function-granular kernel randomization on memory deduplication revealing why it cannot offer maximum security and shareability of memory simultaneously. We also discuss the reasons why having a full position independent kernel code counter-intuitively does not solve the problem introducing a challenge to kernel randomization designers. To solve these problems, we propose a function-granular kernel randomization modification for cloud systems that enables full function-granular kernel randomization while reduces memory deduplication cancellations to almost zero. The proposed approach forces guest kernels of the same tenant to have the same random memory layout of memory regions with high impact on deduplication, ensuring a high rate of deduplicated pages while the kernel randomization is fully enabled. Our approach enables cloud providers to have both, high levels of security and an efficient use of resources.},
author = {Vano-Garcia, Fernando and Marco-Gisbert, Hector},
doi = {10.1109/ACCESS.2020.3019774},
file = {:F\:/D2/09178757.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {KASLR,Virtualization,memory deduplication,memory management,security},
pages = {161612--161629},
title = {{An Info-Leak Resistant Kernel Randomization for Virtualized Systems}},
volume = {8},
year = {2020}
}
@article{Shen2020,
abstract = {Intel Software Guard Extensions (SGX) enables user-level code to create private memory regions called enclaves, whose code and data are protected by the CPU from software and hardware attacks outside the enclaves. Recent work introduces library operating systems (LibOSes) to SGX so that legacy applications can run inside enclaves with few or even no modifications. As virtually any non-trivial application demands multiple processes, it is essential for LibOSes to support multitasking. However, none of the existing SGX LibOSes support multitasking both securely and efficiently. This paper presents Occlum, a system that enables secure and efficient multitasking on SGX. We implement the LibOS processes as SFI-Isolated Processes (SIPs). SFI is a software instrumentation technique for sandboxing untrusted modules (called domains). We design a novel SFI scheme named MPX-based, Multi-Domain SFI (MMDSFI) and leverage MMDSFI to enforce the isolation of SIPs. We also design an independent verifier to ensure the security guarantees of MMDSFI. With SIPs safely sharing the single address space of an enclave, the LibOS can implement multitasking efficiently. The Occlum LibOS outperforms the state-of-the-art SGX LibOS on multitasking-heavy workloads by up to 6, 600× on micro-benchmarks and up to 500× on application benchmarks.},
archivePrefix = {arXiv},
arxivId = {2001.07450},
author = {Shen, Youren and Tian, Hongliang and Chen, Yu and Chen, Kang and Wang, Runji and Xu, Yi and Xia, Yubin and Yan, Shoumeng},
doi = {10.1145/3373376.3378469},
eprint = {2001.07450},
file = {:F\:/D2/3373376.3378469.pdf:pdf},
isbn = {9781450371025},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {Intel MPX,Intel SGX,Library OS,Multitasking,Software Fault Isolation},
pages = {955--970},
title = {{Occlum: Secure and efficient multitasking inside a single enclave of intel SGX}},
year = {2020}
}
@article{Jeong2019,
abstract = {A data race in a kernel is an important class of bugs, critically impacting the reliability and security of the associated system. As a result of a race, the kernel may become unresponsive. Even worse, an attacker may launch a privilege escalation attack to acquire root privileges. In this paper, we propose Razzer, a tool to find race bugs in kernels. The core of Razzer is in guiding fuzz testing towards potential data race spots in the kernel. Razzer employs two techniques to find races efficiently: a static analysis and a deterministic thread interleaving technique. Using a static analysis, Razzer identifies over-approximated potential data race spots, guiding the fuzzer to search for data races in the kernel more efficiently. Using the deterministic thread interleaving technique implemented at the hypervisor, Razzer tames the non-deterministic behavior of the kernel such that it can deterministically trigger a race. We implemented a prototype of Razzer and ran the latest Linux kernel (from v4.16-rc3 to v4.18-rc3) using Razzer. As a result, Razzer discovered 30 new races in the kernel, with 16 subsequently confirmed and accordingly patched by kernel developers after they were reported.},
author = {Jeong, Dae R. and Kim, Kyungtae and Shivakumar, Basavesh and Lee, Byoungyoung and Shin, Insik},
doi = {10.1109/SP.2019.00017},
file = {:F\:/D2/jeong-razzer.pdf:pdf},
isbn = {9781538666609},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Data-race,Fuzzing,Kernel,Race-bugs},
pages = {754--768},
title = {{Razzer: Finding kernel race bugs through fuzzing}},
volume = {2019-May},
year = {2019}
}
@article{Hunt2018,
abstract = {Users of modern data-processing services such as tax preparation or genomic screening are forced to trust them with data that the users wish to keep secret. Ryoan 1 protects secret data while it is processed by services that the data owner does not trust. Accomplishing this goal in a distributed setting is difficult, because the user has no control over the service providers or the computational platform. Confining code to prevent it from leaking secrets is notoriously difficult, but Ryoan benefits from new hardware and a request-oriented data model. Ryoan provides a distributed sandbox, leveraging hardware enclaves (e.g., Intel's software guard extensions (SGX) [40]) to protect sandbox instances from potentially malicious computing platforms. The protected sandbox instances confine untrusted data-processing modules to prevent leakage of the user's input data. Ryoan is designed for a request-oriented data model, where confined modules only process input once and do not persist state about the input. We present the design and prototype implementation of Ryoan and evaluate it on a series of challenging problems including email filtering, health analysis, image processing and machine translation.},
author = {Hunt, Tyler and Zhu, Zhiting and Xu, Yuanzhong and Peter, Simon and Witchel, Emmett},
doi = {10.1145/3231594},
file = {:F\:/papers/Hunt et al. - 2018 - Ryoan A distributed sandbox for untrusted computation on secret data.pdf:pdf},
issn = {15577333},
journal = {ACM Transactions on Computer Systems},
keywords = {Enclaves,Intel SGX,Private computation,Sandboxing,Untrusted OS},
number = {4},
title = {{Ryoan: A distributed sandbox for untrusted computation on secret data}},
volume = {35},
year = {2018}
}
@article{Zeldovich2008,
abstract = {Computers are notoriously insecure, in part because application security policies do not map well onto traditional protection mechanisms such as Unix user accounts or hardware page tables. Recent work has shown that application policies can be expressed in terms of information flow restrictions and enforced in an OS kernel, providing a strong assurance of security. This paper shows that enforcement of these policies can be pushed largely into the processor itself, by using tagged memory support, which can provide stronger security guarantees by enforcing application security even if the OS kernel is compromised. We present the Loki tagged memory architecture, along with a novel operating system structure that takes advantage of tagged memory to enforce application security policies in hardware. We built a full-system prototype of Loki by modifying a synthesizable SPARC core, mapping it to an FPGA board, and porting HiStar, a Unix-like operating system, to run on it. One result is that Loki allows HiStar, an OS already designed to have a small trusted kernel, to further reduce the amount of trusted code by a factor of two, and to enforce security despite kernel compromises. Using various workloads, we also demonstrate that HiStar running on Loki incurs a low performance overhead.},
author = {Zeldovich, Nickolai and Kannan, Hari and Dalton, Michael and Kozyrakis, Christos},
file = {:F\:/D2/zeldovich.pdf:pdf},
isbn = {9781931971652},
journal = {Proceedings of the 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008},
pages = {225--240},
title = {{Hardware enforcement of application security policies using tagged memory}},
year = {2008}
}
@article{Ainsworth2020,
abstract = {Use-after-free vulnerabilities have plagued software written in low-level languages, such as C and C++, becoming one of the most frequent classes of exploited software bugs. Attackers identify code paths where data is manually freed by the programmer, but later incorrectly reused, and take advantage by reallocating the data to themselves. They then alter the data behind the program's back, using the erroneous reuse to gain control of the application and, potentially, the system. While a variety of techniques have been developed to deal with these vulnerabilities, they often have unacceptably high performance or memory overheads, especially in the worst case.We have designed MarkUs, a memory allocator that prevents this form of attack at low overhead, sufficient for deployment in real software, even under allocation- and memory-intensive scenarios. We prevent use-after-free attacks by quarantining data freed by the programmer and forbidding its reallocation until we are sure that there are no dangling pointers targeting it. To identify these we traverse live-objects accessible from registers and memory, marking those we encounter, to check whether quarantined data is accessible from any currently allocated location. Unlike garbage collection, which is unsafe in C and C++, MarkUs ensures safety by only freeing data that is both quarantined by the programmer and has no identifiable dangling pointers. The information provided by the programmer's allocations and frees further allows us to optimise the process by freeing physical addresses early for large objects, specialising analysis for small objects, and only performing marking when sufficient data is in quarantine. Using MarkUs, we reduce the overheads of temporal safety in low-level languages to 1.1× on average for SPEC CPU2006, with a maximum slowdown of only 2×, vastly improving upon the state-of-the-art.},
author = {Ainsworth, Sam and Jones, Timothy M.},
doi = {10.1109/SP40000.2020.00058},
file = {:F\:/D2/MarkUs_Drop-in_use-after-free_prevention_for_low-level_languages.pdf:pdf},
isbn = {9781728134970},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {578--591},
title = {{MarkUs: Drop-in use-after-free prevention for low-level languages}},
volume = {2020-May},
year = {2020}
}
@article{Gruss2017,
abstract = {Modern operating system kernels employ address space layout randomization (ASLR) to prevent control-flow hijacking attacks and code-injection attacks. While kernel security relies fundamentally on preventing access to address information, recent attacks have shown that the hardware directly leaks this information. Strictly splitting kernel space and user space has recently been proposed as a theoretical concept to close these side channels. However, this is not trivially possible due to architectural restrictions of the x86 platform. In this paper we present KAISER, a system that overcomes limitations of x86 and provides practical kernel address isolation. We implemented our proof-of-concept on top of the Linux kernel, closing all hardware side channels on kernel address information. KAISER enforces a strict kernel and user space isolation such that the hardware does not hold any information about kernel addresses while running in user mode. We show that KAISER protects against double page fault attacks, prefetch side-channel attacks, and TSX-based side-channel attacks. Finally, we demonstrate that KAISER has a runtime overhead of only 0.28%.},
author = {Gruss, Daniel and Lipp, Moritz and Schwarz, Michael and Fellner, Richard and Maurice, Cl{\'{e}}mentine and Mangard, Stefan},
doi = {10.1007/978-3-319-62105-0_11},
file = {:F\:/D2/Gruss2017_Chapter_KASLRIsDeadLongLiveKASLR.pdf:pdf},
isbn = {9783319621043},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {161--176},
title = {{KASLR is dead: Long live KASLR}},
volume = {10379 LNCS},
year = {2017}
}
@article{Chen2020a,
abstract = {The monolithic nature of modern OS kernels leads to a constant stream of bugs being discovered. It is often unclear which of these bugs are worth fixing, as only a subset of them may be serious enough to lead to security takeovers (i.e., privilege escalations). Therefore, researchers have recently started to develop automated exploit generation techniques (for UAF bugs) to assist the bug triage process. In this paper, we investigate another top memory vulnerability in Linux kernel-out-of-bounds (OOB) memory write from heap. We design KOOBE to assist the analysis of such vulnerabilities based on two observations: (1) Surprisingly often, different OOB vulnerability instances exhibit a wide range of capabilities. (2) Kernel exploits are multi-interaction in nature (i.e., multiple syscalls are involved in an exploit) which allows the exploit crafting process to be modular. Specifically, we focus on the extraction of capabilities of an OOB vulnerability which will feed the subsequent exploitability evaluation process. Our system builds on several building blocks, including a novel capability-guided fuzzing solution to uncover hidden capabilities, and a way to compose capabilities together to further enhance the likelihood of successful exploitations. In our evaluation, we demonstrate the applicability of KOOBE by exhaustively analyzing 17 most recent Linux kernel OOB vulnerabilities (where only 5 of them have publicly available exploits), for which KOOBE successfully generated candidate exploit strategies for 11 of them (including 5 that do not even have any CVEs assigned). Subsequently from these strategies, we are able to construct fully working exploits for all of them.},
author = {Chen, Weiteng},
file = {:F\:/D2/sec20summer_chen-weiteng_prepub.pdf:pdf},
journal = {USENIX Security},
title = {{KOOBE : Towards Facilitating Exploit Generation of Kernel Out-Of-Bounds Write Vulnerabilities}},
year = {2020}
}
@article{Rajasekaran2020,
abstract = {The widespread deployment of exploit mitigations such as CFI and shadow stacks are making code-reuse attacks increasingly difficult. This has forced adversaries to consider data-only attacks against which the venerable ASLR remains the primary deployed defense.Data-Space Randomization (DSR) techniques raise the bar against data-only attacks by making it harder for adversaries to inject malicious data flows into vulnerable applications. DSR works by masking memory load and store instructions. Masks are chosen (i) to not interfere with intended data flows and (ii) such that masking likely interferes with unintended flows introduced by malicious program inputs. In this paper, we show two new attacks that bypass all existing static DSR approaches; one that directly discloses memory and another using speculative execution. We then present CoDaRR, the first dynamic DSR scheme resilient to disclosure attacks. CoDaRR continuously rerandomizes the masks used in loads and stores, and re-masks all memory objects to remain transparent w.r.t. program execution. Our evaluation confirms that CoDaRR successfully thwarts these attacks with limited run-time overhead in standard benchmarks as well as real-world applications.},
author = {Rajasekaran, Prabhu and Crane, Stephen and Gens, David and Na, Yeoul and Volckaert, Stijn and Franz, Michael},
doi = {10.1145/3320269.3384757},
file = {:F\:/D2/3320269.3384757.pdf:pdf},
isbn = {9781450367509},
journal = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2020},
keywords = {data and application security,data space randomization,plain text attacks,runtime attacks and defenses,software diversity},
pages = {494--505},
title = {{CoDaRR: Continuous Data Space Randomization against Data-Only Attacks}},
year = {2020}
}
@article{Wu2018,
abstract = {Software vendors usually prioritize their bug remediation based on ease of their exploitation. However, accurately determining exploitability typically takes tremendous hours and requires significant manual efforts. To address this issue, automated exploit generation techniques can be adopted. In practice, they however exhibit an insufficient ability to evaluate exploitability particularly for the kernel Use-After-Free (UAF) vulnerabilities. This is mainly because of the complexity of UAF exploitation as well as the scalability of an OS kernel. In this paper, we therefore propose FUZE, a new framework to facilitate the process of kernel UAF exploitation. The design principle behind this technique is that we expect the ease of crafting an exploit could augment a security analyst with the ability to evaluate the exploitability of a kernel UAF vulnerability. Technically, FUZE utilizes kernel fuzzing along with symbolic execution to identify, analyze and evaluate the system calls valuable and useful for kernel UAF exploitation. In addition, it leverages dynamic tracing and an off-the-shelf constraint solver to guide the manipulation of vulnerable object. To demonstrate the utility of FUZE, we implement FUZE on a 64-bit Linux system by extending a binary analysis framework and a kernel fuzzer. Using 15 real-world kernel UAF vulnerabilities on Linux systems, we then demonstrate FUZE could not only escalate kernel UAF exploitability but also diversify working exploits. In addition, we show that FUZE could facilitate security mitigation bypassing, making exploitability evaluation less challenging and more efficient.},
author = {Wu, Wei and Chen, Yueqi and Xu, Jun and Xing, Xinyu and Gong, Xiaorui and Zou, Wei},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2018 - FUZE Towards facilitating exploit generation for kernel use-after-free vulnerabilities.pdf:pdf},
isbn = {9781939133045},
journal = {Proceedings of the 27th USENIX Security Symposium},
pages = {781--797},
title = {{FUZE: Towards facilitating exploit generation for kernel use-after-free vulnerabilities}},
year = {2018}
}
@article{Manco2017,
abstract = {Containers are in great demand because they are lightweight when compared to virtual machines. On the downside, containers oer weaker isolation than VMs, to the point where people run containers in virtual machines to achieve proper isolation. In this paper, we examine whether there is indeed a strict tradeo between isolation (VMs) and eciency (containers). We nd that VMs can be as nimble as containers, as long as they are small and the toolstack is fast enough. We achieve lightweight VMs by using unikernels for specialized applications and with Tinyx, a tool that enables creating tailor-made, trimmed-down Linux virtual machines. By themselves, lightweight virtual machines are not enough to ensure good performance since the virtualization control plane (the toolstack) becomes the performance bottleneck. We present LightVM, a new virtualization solution based on Xen that is optimized to oer fast boot-times regardless of the number of active VMs. LightVM features a complete redesign of Xen's control plane, transforming its centralized operation to a distributed one where interactions with the hypervisor are reduced to a minimum. LightVM can boot a VM in 2.3ms, comparable to fork/exec on Linux (1ms), and two orders of magnitude faster than Docker. LightVM can pack thousands of LightVM guests on modest hardware with memory and CPU usage comparable to that of processes.},
author = {Manco, Filipe and Mendes, Jose and Yasukata, Kenichi and Lupu, Costin and Kuenzer, Simon and Raiciu, Costin and Schmidt, Florian and Sati, Sumit and Huici, Felipe},
doi = {10.1145/3132747.3132763},
file = {:F\:/papers/3132747.3132763.pdf:pdf},
isbn = {9781450350853},
journal = {SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles},
keywords = {Containers,Hypervisor,Operating systems,Specialization,Unikernels,Virtual machine.,Virtualization,Xen},
pages = {218--233},
title = {{My VM is Lighter (and Safer) than your Container}},
year = {2017}
}
@inproceedings{Chen2020,
abstract = {Recent research has proposed various methods to perform kernel exploitation and bypass kernel protection. For example, security researchers have demonstrated an exploitation method that utilizes the characteristic of elastic kernel objects to bypass KASLR, disclose stack/heap cookies, and even perform arbitrary read in the kernel. While this exploitation method is considered a commonly adopted approach to disclosing critical kernel information, there is no evidence indicating a strong need for developing a new defense mechanism to limit this exploitation method. It is because the effectiveness of this exploitation method is demonstrated only on anecdotal kernel vulnerabilities. It is unclear whether such a method is useful for a majority of kernel vulnerabilities. To answer this question, we propose a systematic approach. It utilizes static/dynamic analysis methods to pinpoint elastic kernel objects and then employs constraint solving to pair them to corresponding kernel vulnerabilities. In this work, we implement our proposed method as a tool - ELOISE. Using this tool on three popular OSes (Linux, FreeBSD, and XNU), we discover that elastic objects are pervasive in general caches. Evaluating the effectiveness of these elastic objects on 40 kernel vulnerabilities across three OSes, we observe that they can enable most of the vulnerabilities to bypass KASLR and heap cookie protector. Besides, we also observe that these elastic objects can even escalate the exploitability of some vulnerabilities allowing them to perform arbitrary read in the kernel. Motivated by these observations, we further introduce a new defense mechanism to mitigate the threat of elastic kernel objects. We prototype our defense mechanism on Linux, showing this mechanism introduces negligible overhead.},
author = {Chen, Yueqi and Lin, Zhenpeng and Xing, Xinyu},
booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
doi = {10.1145/3372297.3423353},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Lin, Xing - 2020 - A Systematic Study of Elastic Objects in Kernel Exploitation.pdf:pdf},
isbn = {9781450370899},
issn = {15437221},
keywords = {OS security,vulnerability exploitation},
month = {oct},
pages = {1165--1184},
publisher = {Association for Computing Machinery},
title = {{A Systematic Study of Elastic Objects in Kernel Exploitation}},
year = {2020}
}
@article{Xu2020,
abstract = {The rapid growth of the Android ecosystem has led to the fragmentation problem where a wide range of (customized) versions of Android OS exist in the market. This poses a severe security issue as it is very costly for Android vendors to fix vulnerabilities in their customized Android kernels in time. The recent development of the hot patching technique provides an ideal solution to solve this problem since it can be applied to a wide range of Android kernels without interrupting their normal functionalities. However, the current hot patches are written by human experts, which can be time-consuming and error-prone. To this end, we first study the feasibility of automatic patch generation from 373 Android kernel CVEs ranging from 2012 to 2016. Then, we develop an automatic hot patch generation tool, named Vulmet, which produces semantic preserving hot patches by learning from the official patches. The key idea of Vulmet is to use the weakest precondition reasoning to transform the changes made by the official patches into the hot patch constraints. The experiments have shown that Vulmet can generate correct hot patches for 55 real-world Android kernel CVEs. The hot patches do not affect the robustness of the kernels and have low performance overhead.},
author = {Xu, Zhengzi and Zhang, Yulong and Zheng, Longri and Xia, Liangzhao and Bao, Chenfu and Wang, Zhi and Liu, Yang},
file = {:F\:/D2/sec20-xu.pdf:pdf},
isbn = {9781939133175},
journal = {Proceedings of the 29th USENIX Security Symposium},
pages = {2397--2414},
title = {{Automatic hot patch generation for android kernels}},
year = {2020}
}
@article{Levy2017a,
abstract = {Low-power microcontrollers lack some of the hardware features and memory resources that enable multiprogrammable systems. Accordingly, microcontroller-based operating systems have not provided important features like fault isolation, dynamic memory allocation, and flexible concurrency. However, an emerging class of embedded applications are software platforms, rather than single purpose devices, and need these multiprogramming features. Tock, a new operating system for low-power platforms, takes advantage of limited hardware-protection mechanisms as well as the type-safety features of the Rust programming language to provide a multiprogramming environment for microcontrollers. Tock isolates software faults, provides memory protection, and efficiently manages memory for dynamic application workloads written in any language. It achieves this while retaining the dependability requirements of long-running applications.},
author = {Levy, Amit and Giffin, Daniel B. and Campbell, Bradford and Pannuto, Pat and Levis, Philip and Ghena, Branden and Dutta, Prabal},
doi = {10.1145/3132747.3132786},
file = {:F\:/papers/3132747.3132786.pdf:pdf},
isbn = {9781450350853},
journal = {SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles},
pages = {234--251},
title = {{Multiprogramming a 64 kB Computer Safely and Efficiently}},
year = {2017}
}
@article{Chen2011,
abstract = {Avoiding kernel vulnerabilities is critical to achieving security of many systems, because the kernel is often part of the trusted computing base. This paper evaluates the current state-of-the-art with respect to kernel protection techniques, by presenting two case studies of Linux kernel vulnerabilities. First, this paper presents data on 141 Linux kernel vulnerabilities discovered from January 2010 to March 2011, and second, this paper examines how well state-of-the-art techniques address these vulnerabilities. The main findings are that techniques often protect against certain exploits of a vulnerability but leave other exploits of the same vulnerability open, and that no effective techniques exist to handle semantic vulnerabilities - -violations of high-level security invariants. {\textcopyright} 2011 ACM.},
author = {Chen, Haogang and Mao, Yandong and Wang, Xi and Zhou, Dong and Zeldovich, Nickolai and Kaashoek, M. Frans},
doi = {10.1145/2103799.2103805},
file = {:F\:/D2/chen-kbugs.pdf:pdf},
isbn = {9781450311793},
journal = {Proceedings of the 2nd Asia-Pacific Workshop on Systems, APSys'11},
title = {{Linux kernel vulnerabilities: State-of-the-art defenses and open problems}},
year = {2011}
}
@book{Hua,
abstract = {The Meltdown vulnerability, which exploits the inherent out-of-order execution in common processors like x86, ARM and PowerPC, has shown to break the fundamental isolation boundary between user and kernel space. This has stimulated a non-trivial patch to modern OS to separate page tables for user space and kernel space, namely, KPTI (kernel page table isolation). While this patch stops kernel memory leakages from rouge user processes, it mandates users to patch their kernels (usu-ally requiring a reboot), and is currently only available on the latest versions of OS kernels. Further, it also introduces non-trivial performance overhead due to page table switching during user/kernel crossings. In this paper, we present EPTI, an alternative approach to defending against the Meltdown attack for unpatched VMs (virtual machines) in cloud, yet with better performance than KPTI. Specifically, instead of using two guest page tables, we use two EPTs (extended page tables) to isolate user space and kernel space, and unmap all the kernel space in user's EPT to achieve the same effort of KPTI. The switching of EPTs is done through a hardware-support feature called EPT switching within guest VMs without hypervisor involvement. Meanwhile, EPT switching does not flush TLB since each EPT has its own TLB, which further reduces the overhead. We have implemented our design and evaluated it on Intel Kaby Lake CPU with different versions of Linux kernel. The results show that EPTI only introduces up to 13% overhead, which is around 45% less than KPTI.},
author = {Hua, Zhichao and Du, Dong and Xia, Yubin and Chen, Haibo and Zang, Binyu},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hua et al. - Unknown - EPTI Efficient Defence against Meltdown Attack for Unpatched VMs.pdf:pdf},
isbn = {978-1-939133-02-1},
title = {{EPTI: Efficient Defence against Meltdown Attack for Unpatched VMs}},
url = {www.usenix.org/conference/atc18/presentation/hua}
}
@article{Mohammadjavad2021,
abstract = {undo effects of the bug triggering syscall},
author = {Mohammadjavad, Seyed and Talebi, Seyed and Yao, Zhihao and Sani, Ardalan Amiri and Qian, Zhiyun and Austin, Daniel and Irvine, U C and Riverside, U C},
file = {:F\:/D2/sec21fall-talebi.pdf:pdf},
journal = {Usenix Security '2021},
title = {{Undo Workarounds for Kernel Bugs}},
year = {2021}
}
@article{Oakes2020,
abstract = {Serverless computing promises to provide applications with cost savings and extreme elasticity. Unfortunately, slow application and container initialization can hurt common-case latency on serverless platforms. In this work, we analyze Linux container primitives, identifying scalability bottlenecks related to storage and network isolation. We also analyze Python applications from GitHub and show that importing many popular libraries adds about 100 ms to startup. Based on these findings, we implement SOCK, a container system optimized for serverless workloads. Careful avoidance of kernel scalability bottlenecks gives SOCK an 18× speedup over Docker. A generalized-Zygote provisioning strategy yields an additional 3× speedup. A more sophisticated three-tier caching strategy based on Zygotes provides a 45× speedup over SOCK without Zygotes. Relative to AWS Lambda and OpenWhisk, OpenLambda with SOCK reduces platform overheads by 2.8× and 5.3× respectively in an image processing case study.},
author = {Oakes, Edward and Yang, Leon and Zhou, Dennis and Houck, Kevin and Harter, Tyler and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},
file = {:F\:/papers/atc18-oakes.pdf:pdf},
isbn = {9781939133021},
journal = {Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018},
pages = {57--69},
title = {{SOCK: Rapid task provisioning with serverless-optimized containers}},
year = {2020}
}
@article{Klein2019,
abstract = {IP headers include a 16-bit ID field. Our work examines the generation of this field in Windows (versions 8 and higher), Linux and Android, and shows that the IP ID field enables remote servers to assign a unique ID to each device and thus be able to identify subsequent transmissions sent from that device. This identification works across all browsers and over network changes. In modern Linux and Android versions, this field leaks a kernel address, thus we also break KASLR. Our work includes reverse-engineering of the Windows IP ID generation code, and a cryptanalysis of this code and of the Linux kernel IP ID generation code. It provides practical techniques to partially extract the key used by each of these algorithms, overcoming different implementation issues, and observing that this key can identify individual devices. We deployed a demo (for Windows) showing that key extraction and machine fingerprinting works in the wild, and tested it from networks around the world.},
author = {Klein, Amit and Pinkas, Benny},
file = {:F\:/D2/sec19-klein.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1063--1080},
title = {{From IP ID to device ID and KASLR bypass}},
year = {2019}
}
@book{Canella,
abstract = {Research on transient execution attacks including Spectre and Meltdown showed that exception or branch mispredic-tion events might leave secret-dependent traces in the CPU's microarchitectural state. This observation led to a proliferation of new Spectre and Meltdown attack variants and even more ad-hoc defenses (e.g., microcode and software patches). Both the industry and academia are now focusing on finding effective defenses for known issues. However, we only have limited insight on residual attack surface and the completeness of the proposed defenses. In this paper, we present a systematization of transient execution attacks. Our systematization uncovers 6 (new) transient execution attacks that have been overlooked and not been investigated so far: 2 new exploitable Meltdown effects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds Check Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. We evaluate the attacks in our classification tree through proof-of-concept implementations on 3 major CPU vendors (Intel, AMD, ARM). Our systematization yields a more complete picture of the attack surface and allows for a more systematic evaluation of defenses. Through this systematic evaluation, we discover that most defenses, including deployed ones, cannot fully mitigate all attack variants.},
author = {Canella, Claudio and Schwarz, Michael and Lipp, Moritz and {Von Berg}, Benjamin and Ortner, Philipp and {Van Bulck}, Jo and Piessens, Frank and Evtyushkin, Dmitry and Gruss, Daniel},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Canella et al. - Unknown - A Systematic Evaluation of Transient Execution Attacks and Defenses(2).pdf:pdf},
isbn = {9781939133069},
title = {{A Systematic Evaluation of Transient Execution Attacks and Defenses}},
url = {www.usenix.org/conference/usenixsecurity19/presentation/canella}
}
@article{Shinde2016,
abstract = {New hardware primitives such as Intel SGX have emerged which secure a user-level process in presence of an untrusted OS. Such "enclaved execution" systems are vulnerable to several side-channels, one of which is the page fault channel. In this paper, we study the cryptographic routines from OpenSSL and Libgcrypt and measure the channel capacity in the context of such an enclaved execution. We demonstrate that the page fault side-channel is powerful enough to extract bits of encryption keys used in implementations of cryptographic routines -- 33% on average and 100% leakage in best case. We show that the previously conjectured defenses do not work against these attacks. To mitigate this, our first defense masks the page fault channel by determinising the program's memory access behavior. This defense is implemented purely in software and has a significant overhead of upto 4000X, but with our optimizations is reduce to 31.85%. As a second approach we propose contractual execution. With a small change to the hardware, this defense incurs a performance overhead of 6.77% on average.},
author = {Shinde, Shweta and Chua, Zheng Leong and Narayanan, Viswesh and Saxena, Prateek},
doi = {10.1145/2897845.2897885},
file = {:F\:/D2/2897845.2897885.pdf:pdf},
isbn = {9781450342339},
pages = {317--328},
title = {{Preventing Page Faults from Telling Your Secrets}},
year = {2016}
}
@article{Heelan2019,
abstract = {We present the first approach to automatic exploit generation for heap overflows in interpreters. It is also the first approach to exploit generation in any class of program that integrates a solution for automatic heap layout manipulation. At the core of the approach is a novel method for discovering exploit primitives-inputs to the target program that result in a sensitive operation, such as a function call or a memory write, utilizing attacker-injected data. To produce an exploit primitive from a heap overflow vulnerability, one has to discover a target data structure to corrupt, ensure an instance of that data structure is adjacent to the source of the overflow on the heap, and ensure that the post-overflow corrupted data is used in a manner desired by the attacker. Our system addresses all three tasks in an automatic, greybox, and modular manner. Our implementation is called Gollum, and we demonstrate its capabilities by producing exploits from 10 unique vulnerabilities in the PHP and Python interpreters, 5 of which do not have existing public exploits.},
author = {Heelan, Sean and Melham, Tom and Kroening, Daniel},
doi = {10.1145/3319535.3354224},
file = {:F\:/D2/3319535.3354224.pdf:pdf},
isbn = {9781450367479},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Exploit generation,Greybox,Primitive search},
pages = {1689--1706},
title = {{Gollum: Modular and greybox exploit generation for heap overflows in interpreters}},
year = {2019}
}
@article{Eide1997,
abstract = {An interface definition language (IDL) is a nontraditional language for describing interfaces between software components. IDL compilers generate `stubs' that provide separate communicating processes with the abstraction of local object invocation or procedure call. High-quality stub generation is essential for applications to benefit from component-based designs, whether the components reside on a single computer or on multiple networked hosts. Typical IDL compilers, however, do little code optimization, incorrectly assuming that interprocess communication is always the primary bottleneck. More generally, typical IDL compilers are `rigid' and limited to supporting only a single IDL, a fixed mapping onto a target language, and a narrow range of data encodings and transport mechanisms. Flick, our new IDL compiler, is based on the insight that IDLS are true languages amenable to modern compilation techniques. Flick exploits concepts from traditional programming language compilers to bring both flexibility and optimization to the domain of IDL compilation. Through the use of carefully chosen intermediate representations, Flick supports multiple IDLs, diverse data encodings, multiple transport mechanisms, and applies numerous optimizations to all of the code it generates. Our experiments show that Flick-generated stubs marshal data between 2 and 17 times faster than stubs produced by traditional IDL compilers, and on today's generic operating systems, increase end-to-end throughput by factors between 1.2 and 3.7.},
author = {Eide, Eric and Frei, Kevin and Ford, Bryan and Lepreau, Jay and Lindstrom, Gary},
file = {:F\:/D2/258915.258921.pdf:pdf},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
pages = {44--56},
title = {{Flick: A flexible, optimizing IDL compiler}},
year = {1997}
}
@article{Awasthi2017,
abstract = {The time spent by an application can broadly be classified into two main categories - user mode and kernel mode. In order to optimize applications from a performance perspective, it is critical to know the code regions where they spend the bulk of their time. With datacenter applications becoming more I/O intensive and storage devices attaining higher performance with each generation, the contribution of the Linux kernel stack to overall performance is increasing to an all time high. These trends make it imperative to observe and visualize kernel behavior and performance in order to effectively optimize it for specific use cases. To that end, in this paper, we present KOVA: Kernel Overhead Visualization and Analysis framework that builds on top of existing kernel tracers to provide comprehensive insights into Linux kernel behavior.},
author = {Awasthi, Manu and Malladi, Krishna T.},
doi = {10.1109/PCCC.2016.7820601},
file = {:F\:/D2/07820601.pdf:pdf},
isbn = {9781509052523},
journal = {2016 IEEE 35th International Performance Computing and Communications Conference, IPCCC 2016},
pages = {11--13},
publisher = {IEEE},
title = {{KOVA : A tool for kernel visualization and analysis}},
year = {2017}
}
@article{Lu2016,
abstract = {The operating system kernel is the de facto trusted computing base for most computer systems. To secure the OS kernel, many security mechanisms, e.g., kASLR and StackGuard, have been increasingly deployed to defend against attacks (e.g., code reuse attack). However, the effectiveness of these protections has been proven to be inadequate-there are many information leak vulnerabilities in the kernel to leak the randomized pointer or canary, thus bypassing kASLR and StackGuard. Other sensitive data in the kernel, such as cryptographic keys and fle caches, can also be leaked. According to our study, most kernel information leaks are caused by uninitialized data reads. Unfortunately, existing techniques like memory safety enforcements and dynamic access tracking tools are not adequate or effcient enough to mitigate this threat. In this paper, we propose UniSan, a novel, compiler-based approach to eliminate all information leaks caused by uninitialized read in the OS kernel. UniSan achieves this goal using byte-level, fow-sensitive, context-sensitive, and feld-sensitive initialization analysis and reachability analysis to check whether an allocation has been fully initialized when it leaves kernel space; if not, it automatically instruments the kernel to initialize this allocation. UniSan's analyses are conservative to avoid false negatives and are robust by preserving the semantics of the OS kernel. We have implemented UniSan as passes in LLVM and applied it to the latest Linux kernel (x86-64) and Android kernel (AArch64). Our evaluation showed that UniSan can successfully prevent 43 known and many new uninitialized data leak vulnerabilities. Further, 19 new vulnerabilities in the latest kernels have been confrmed by Linux and Google. Our extensive performance evaluation with LMBench, ApacheBench, Android benchmarks, and the SPEC benchmarks also showed that UniSan imposes a negligible performance overhead.},
author = {Lu, Kangjie and Song, Chengyu and Kim, Taesoo and Lee, Wenke},
doi = {10.1145/2976749.2978366},
file = {:F\:/papers/2976749.2978366.pdf:pdf},
isbn = {9781450341394},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Initialization analysis,Kernel information leak,Memory initialization,Reachability analysis,Uninitialized read},
pages = {920--932},
title = {{UniSan: Proactive kernel memory initialization to eliminate data leakages}},
volume = {24-28-Octo},
year = {2016}
}
@article{Yun2019,
abstract = {Heap exploitation techniques to abuse the metadata of allocators have been widely studied since they are application independent and can be used in restricted environments that corrupt only metadata. Although prior work has found several interesting exploitation techniques, they are ad-hoc and manual, which cannot effectively handle changes or a variety of allocators. In this paper, we present a new naming scheme for heap exploitation techniques that systematically organizes them to discover the unexplored space in finding the techniques and ArcHeap, the tool that finds heap exploitation techniques automatically and systematically regardless of their underlying implementations. For that, ArcHeap generates a set of heap actions (e.g. allocation or deallocation) by leveraging fuzzing, which exploits common designs of modern heap allocators. Then, ArcHeap checks whether the actions result in impact of exploitations such as arbitrary write or overlapped chunks that efficiently determine if the actions can be converted into the exploitation technique. Finally, from these actions, ArcHeap generates Proof-of-Concept code automatically for an exploitation technique. We evaluated ArcHeap with real-world allocators --- ptmalloc, jemalloc, and tcmalloc --- and custom allocators from the DARPA Cyber Grand Challenge. ArcHeap successfully found 14 out of 16 known exploitation techniques and found five new exploitation techniques in ptmalloc. Moreover, ArcHeap found several exploitation techniques for jemalloc, tcmalloc, and even for the custom allocators. Further, ArcHeap can automatically show changes in exploitation techniques along with version change in ptmalloc using differential testing.},
archivePrefix = {arXiv},
arxivId = {1903.00503},
author = {Yun, Insu and Kapil, Dhaval and Kim, Taesoo},
eprint = {1903.00503},
file = {:F\:/D2/sec20-yun.pdf:pdf},
isbn = {9781939133175},
title = {{Automatic Techniques to Systematically Discover New Heap Exploitation Primitives}},
url = {http://arxiv.org/abs/1903.00503},
year = {2019}
}
@article{Deng2017,
abstract = {This paper presents a novel framework that enables practical event-driven monitoring for untrusted virtual machine monitors (VMMs) in cloud computing. Unlike previous approaches for VMM monitoring, our framework neither relies on a higher privilege level nor requires any special hardware support. Instead, we place the trusted monitor at the same privilege level and in the same address space with the untrusted VMM to achieve superior efficiency, while proposing a unique mutual-protection mechanism to ensure the integrity of the monitor. Our security analysis demonstrates that our framework can provide high-assurance for event-driven VMM monitoring, even if the highest-privilege VMM is fully compromised. The experimental results show that our framework only incurs trivial performance overhead for enforcing event-driven monitoring policies, exhibiting tremendous performance improvement on previous approaches.},
author = {Deng, Liang and Liu, Peng and Xu, Jun and Chen, Ping and Zeng, Qingkai},
doi = {10.1145/3050748.3050750},
file = {:F\:/D2/3050748.3050750.pdf:pdf},
isbn = {9781450349482},
issn = {0362-1340},
journal = {VEE 2017 - Proceedings of the 2017 ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {83--96},
title = {{Dancing with wolves: Towards practical event-driven VMM monitoring}},
year = {2017}
}
@article{Szekeres2013,
abstract = {Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corruption attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms implementing stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps designers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency. We identify some open research problems, and provide suggestions on improving the adoption of newer techniques. {\textcopyright} 2013 IEEE.},
author = {Szekeres, L{\'{a}}szl{\'{o}} and Payer, Mathias and Wei, Tao and Song, Dawn},
doi = {10.1109/SP.2013.13},
file = {:F\:/wechat-pac/WeChat Files/wangzc5514/FileStorage/File/2020-08/SoK_memory_SP2013.pdf:pdf;:F\:/D2/06547101.pdf:pdf},
isbn = {9780769549774},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {48--62},
title = {{SoK: Eternal war in memory}},
year = {2013}
}
@article{Lal2014,
abstract = {The application of software-verification technology towards building realistic bug-finding tools requires working through several precision-scalability tradeoffs. For instance, a critical aspect while dealing with C programs is to formally define the treatment of pointers and the heap. A machine-level modeling is often intractable, whereas one that leverages highlevel information (such as types) can be inaccurate. Another tradeoff is modeling integer arithmetic. Ideally, all arithmetic should be performed over bitvector representations whereas the current practice in most tools is to use mathematical integers for scalability. A third tradeoff, in the context of bounded program exploration, is to choose a bound that ensures high coverage without overwhelming the analysis. This paper works through these three tradeoffs when we applied Corral, an SMT-based verifier, inside Microsoft's Static Driver Verifier (SDV). Our decisions were guided by experimentation on a large set of drivers; the total verification time exceeded well over a month. We justify that each of our decisions were crucial in getting value out of Corral and led to Corral being accepted as the engine that powers SDV in the Windows 8.1 release, replacing the SLAM engine that had been used inside SDV for the past decade.},
author = {Lal, Akash and Qadeer, Shaz},
doi = {10.1145/2635868.2635894},
file = {:F\:/papers/2635868.2635894.pdf:pdf},
isbn = {9781450330565},
journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
keywords = {Bitvector reasoning,Device drivers,Language semantics,Loop coverage,SMT,Software verification},
pages = {202--212},
title = {{Powering the Static Driver Verifier using Corral}},
volume = {16-21-Nove},
year = {2014}
}
@article{Zhang2021,
abstract = {open-source projects are often reused in commercial software. Android, a popular mobile operating system, is a great example that has fostered an ecosystem of open-source kernels. However, due to the largely decentralized and fragmented nature, patch propagation from the upstream through multiple layers to end devices can be severely delayed. In this paper, we undertake a thorough investigation of the patch propagation behaviors in the entire Android kernel ecosystem. By analyzing the CVEs and patches available since the inception of the Android security bulletin, as well as open-source upstream kernels (e.g., Linux and AOSP) and hundreds of mostly binary OEM kernels (e.g., by Samsung), we find that the delays of patches are largely due to the current patching practices and the lack of knowledge about which upstream commits being security-critical. Unfortunately, we find that the gap between the first publicly available patch and its final application on end devices is often months and even years, leaving a large attack window for experienced hackers to exploit the unpatched vulnerabilities.},
author = {Zhang, Zheng and Zhang, Hang and Qian, Zhiyun and Lau, Billy},
file = {:F\:/D2/sec21summer_zhang.pdf:pdf},
journal = {Security},
number = {3},
title = {{An Investigation of the Android Kernel Patch Ecosystem}},
year = {2021}
}
@article{Davi2017,
abstract = {Intrusion detection is an arms race; attackers evade intrusion detection systems by developing new attack vectors to sidestep known defense mechanisms. Provenance provides a detailed, structured history of the interactions of digital objects within a system. It is ideal for intrusion detection, because it offers a holistic, attack-vector-agnostic view of system execution. As such, provenance graph analysis fundamentally strengthens detection robustness. We discuss the opportunities and challenges associated with provenance-based intrusion detection and provide insights based on our experience building such systems.},
author = {Davi, Lucas and Gens, David and Liebchen, Christopher and Sadeghi, Ahmad-Reza},
doi = {10.14722/ndss.2017.23421},
file = {:F\:/D2/pt-rand.pdf:pdf},
isbn = {1891562460},
number = {March},
title = {{PT-Rand: Practical Mitigation of Data-only Attacks against Page Tables}},
year = {2017}
}
@article{Biondo2018,
abstract = {—Attackers use memory corruption vulnerabilities to compromise systems by hijacking control flow towards attacker-controlled code. Over time, researchers proposed sev-eral countermeasures, such as Address Space Layout Random-ization, Write XOR Execute and Control Flow Integrity (CFI). CFI is one of the most promising solutions, enforcing control flow to adhere to statically determined valid execution paths. To trade with the execution and storage overhead, practical CFI implementations enforce coarser version of CFI. One of the most widely deployed implementations of CFI is the one proposed by Microsoft, named Control Flow Guard (CFG). CFG is currently in place on all Windows operating systems, from Windows 8.1 to the most recent update of Windows 10 (at the time of writing), accounting for more than 500 million machines. In this paper, we show a significant design vulnerability in Windows CFG and propose a specific attack to exploit it: the Back to The Epilogue (BATE) attack. We show that with BATE an attacker can completely evade from CFG and transfer control to any location, thus obtaining arbitrary code execution. BATE leverages the tradeoff of CFG between precision, performance, and backwards compatibility; in particular, the latter one motivates 16-byte address granularity in some circumstances. This vulnerability, inherent to the CFG design, allows us to call portions of code (gadgets) that should not be allowed, and that we can chain together to escape CFG. These gadgets are very common: we ran a thorough evaluation of Windows system libraries, and found many high value targets – exploitable gadgets in code loaded by almost all the applications on 32-bit systems and by web browsers on 64-bit. We also demonstrate the real-world feasibility of our attack by using it to build a remote code execution exploit against the Microsoft Edge web browser running on 64-bit Windows 10. Finally, we discuss possible countermeasures to BATE.},
author = {Biondo, Andrea and Conti, Mauro and Lain, Daniele},
doi = {10.14722/ndss.2018.23318},
file = {:F\:/papers/Biondo, Conti, Lain - 2018 - Back To The Epilogue Evading Control Flow Guard via Unaligned Targets.pdf:pdf},
number = {October},
title = {{Back To The Epilogue: Evading Control Flow Guard via Unaligned Targets}},
year = {2018}
}
@article{Wang2020a,
abstract = {Memory-corruption attacks such as code-reuse attacks and data-only attacks have been a key threat to systems security. To counter these threats, researchers have proposed a variety of defenses, including control-flow integrity (CFI), code-pointer integrity (CPI), and code (re-)randomization. All of them, to be effective, require a security primitive-intra-process protection of confidentiality and/or integrity for sensitive data (such as CFI's shadow stack and CPI's safe region). In this paper, we propose SEIMI, a highly efficient intra-process memory isolation technique for memory-corruption defenses to protect their sensitive data. The core of SEIMI is to use the efficient Supervisor-mode Access Prevention (SMAP), a hardware feature that is originally used for preventing the kernel from accessing the user space, to achieve intra-process memory isolation. To leverage SMAP, SEIMI creatively executes the user code in the privileged mode. In addition to enabling the new design of the SMAP-based memory isolation, we further develop multiple new techniques to ensure secure escalation of user code, e.g., using the descriptor caches to capture the potential segment operations and configuring the Virtual Machine Control Structure (VMCS) to invalidate the execution result of the control registers related operations. Extensive experimental results show that SEIMI outperforms existing isolation mechanisms, including both the Memory Protection Keys (MPK) based scheme and the Memory Protection Extensions (MPX) based scheme, while providing secure memory isolation.},
author = {Wang, Zhe and Wu, Chenggang and Xie, Mengyao and Zhang, Yinqian and Lu, Kangjie and Zhang, Xiaofeng and Lai, Yuanming and Kang, Yan and Yang, Min},
doi = {10.1109/SP40000.2020.00087},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - SEIMI Efficient and Secure SMAP-Enabled Intra-process Memory Isolation.pdf:pdf},
pages = {592--607},
title = {{SEIMI: Efficient and Secure SMAP-Enabled Intra-process Memory Isolation}},
year = {2020}
}
@article{McKenney2020,
abstract = {Read-copy update (RCU) is a scalable high-performance synchronization mechanism implemented in the Linux kernel. RCU's novel properties include support for concurrent forward progress for readers and writers as well as highly optimized inter-CPU synchronization. RCU was introduced into the Linux kernel eighteen years ago and most subsystems now use RCU. This paper discusses the requirements that drove the development of RCU, the design and API of the Linux RCU implementation, and how kernel developers apply RCU.},
author = {McKenney, Paul E. and Fernandes, Joel and Boyd-Wickizer, Silas and Walpole, Jonathan},
doi = {10.1145/3421473.3421481},
file = {:F\:/D2/3421473.3421481.pdf:pdf},
issn = {0163-5980},
journal = {ACM SIGOPS Operating Systems Review},
number = {1},
pages = {47--63},
title = {{RCU Usage In the Linux Kernel}},
volume = {54},
year = {2020}
}
@article{Pailoor2018,
abstract = {OS fuzzers primarily test the system-call interface between the OS kernel and user-level applications for security vulnerabilities. The effectiveness of all existing evolutionary OS fuzzers depends heavily on the quality and diversity of their seed system call sequences. However, generating good seeds for OS fuzzing is a hard problem as the behavior of each system call depends heavily on the OS kernel state created by the previously executed system calls. Therefore, popular evolutionary OS fuzzers often rely on hand-coded rules for generating valid seed sequences of system calls that can bootstrap the fuzzing process. Unfortunately, this approach severely restricts the diversity of the seed system call sequences and therefore limits the effectiveness of the fuzzers. In this paper, we develop MoonShine, a novel strategy for distilling seeds for OS fuzzers from system call traces of real-world programs while still preserving the dependencies across the system calls. MoonShine leverages light-weight static analysis for efficiently detecting dependencies across different system calls. We designed and implemented MoonShine as an extension to Syzkaller, a state-of-the-art evolutionary fuzzer for the Linux kernel. Starting from traces containing 2.8 million system calls gathered from 3,220 real-world programs, MoonShine distilled down to just over 14,000 calls while preserving 86% of the original code coverage. Using these distilled seed system call sequences, MoonShine was able to improve Syzkaller's achieved code coverage for the Linux kernel by 13% on average. MoonShine also found 17 new vulnerabilities in the Linux kernel that were not found by Syzkaller.},
author = {Pailoor, Shankara and Aday, Andrew and Jana, Suman},
file = {:F\:/D2/sec18-pailoor.pdf:pdf},
isbn = {9781939133045},
journal = {Proceedings of the 27th USENIX Security Symposium},
pages = {729--743},
title = {{MoonShine: Optimizing OS fuzzer seed selection with trace distillation}},
year = {2018}
}
@article{Kadav2012,
abstract = {Device drivers are the single largest contributor to operating-system kernel code with over 5 million lines of code in the Linux kernel, and cause significant complexity, bugs and development costs. Recent years have seen a flurry of research aimed at improving the reliability and simplifying the development of drivers. However, little is known about what constitutes this huge body of code beyond the small set of drivers used for research. In this paper, we study the source code of Linux drivers to understand what drivers actually do, how current research applies to them and what opportunities exist for future research. We determine whether assumptions made by most driver research, such as that all drivers belong to a class, are indeed true. We also analyze driver code and abstractions to determine whether drivers can benefit from code re-organization or hardware trends. We develop a set of static-analysis tools to analyze driver code across various axes. Broadly, our study looks at three aspects of driver code (i) what are the characteristics of driver code functionality and how applicable is driver research to all drivers, (ii) how do drivers interact with the kernel, devices, and buses, and (iii) are there similarities that can be abstracted into libraries to reduce driver size and complexity? We find that many assumptions made by driver research do not apply to all drivers. At least 44% of drivers have code that is not captured by a class definition, 28% of drivers support more than one device per driver, and 15% of drivers do significant computation over data. From the driver interactions study, we find USB bus offers an efficient bus interface with significant standardized code and coarse-grained access, ideal for executing drivers in isolation. We also find that drivers for different buses and classes have widely varying levels of device interaction, which indicates that the cost of isolation will vary by class. Finally, from our driver similarity study, we find 8% of all driver code is substantially similar to code elsewhere and may be removed with new abstractions or libraries. {\textcopyright} 2012 ACM.},
author = {Kadav, Asim and Swift, Michael M.},
doi = {10.1145/2150976.2150987},
file = {:F\:/papers/2248487.2150987.pdf:pdf},
isbn = {9781450307598},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {device drivers,measurement},
pages = {87--98},
title = {{Understanding modern device drivers}},
year = {2012}
}
@article{12345678212992018,
author = {{张 健 1, 2, 张 超 3, 玄跻峰 4, 熊英飞 5, 王千祥 6, 梁 彬 7, 李 炼 8, 2, 窦文生 1, 2, 陈振邦 9, 陈立前 9}, 蔡 彦 1},
doi = {10.13328/j.cnki.jos.000000},
file = {:F\:/papers/程序分析研究进展.pdf:pdf},
number = {973},
title = {程序分析研究进展},
year = {2018}
}
@article{Castro2009,
abstract = {Bugs in kernel extensions remain one of the main causes of poor operating system reliability despite proposed techniques that isolate extensions in separate protection domains to contain faults. We believe that previous fault isolation techniques are not widely used because they cannot isolate existing kernel extensions with low overhead on standard hardware. This is a hard problem because these extensions communicate with the kernel using a complex interface and they communicate frequently. We present BGI (Byte-Granularity Isolation), a new software fault isolation technique that addresses this problem. BGI uses efficient byte-granularity memory protection to isolate kernel extensions in separate protection domains that share the same address space. BGI ensures type safety for kernel objects and it can detect common types of errors inside domains. Our results show that BGI is practical: it can isolate Windows drivers without requiring changes to the source code and it introduces a CPU overhead between 0 and 16%. BGI can also find bugs during driver testing. We found 28 new bugs in widely used Windows drivers. Copyright 2009 ACM.},
author = {Castro, Miguel and Costa, Manuel and Martin, Jean Philippe and Peinado, Marcus and Akritidis, Periklis and Donnelly, Austin and Barham, Paul and Black, Richard},
doi = {10.1145/1629575.1629581},
file = {:F\:/D2/1629575.1629581.pdf:pdf},
isbn = {9781605587523},
journal = {SOSP'09 - Proceedings of the 22nd ACM SIGOPS Symposium on Operating Systems Principles},
keywords = {Device drivers,Isolation},
pages = {45--58},
title = {{Fast byte-granularity software fault isolation}},
year = {2009}
}
@article{Hund2009,
abstract = {Protecting the kernel of an operating system against attacks, especially injection of malicious code, is an important factor for implementing secure operating systems. Several kernel integrity protection mechanism were proposed recently that all have a particular shortcoming: They cannot protect against attacks in which the attacker re-uses existing code within the kernel to perform malicious computations. In this paper, we present the design and implementation of a system that fully automates the process of constructing instruction sequences that can be used by an attacker for malicious computations. We evaluate the system on different commodity operating systems and show the portability and universality of our approach. Finally, we describe the implementation of a practical attack that can bypass existing kernel integrity protection mechanisms.},
author = {Hund, Ralf and Holz, Thorsten and Freiling, Felix C.},
file = {:F\:/D2/hund.pdf:pdf},
isbn = {9781931971690},
journal = {Proceedings of the 18th USENIX Security Symposium},
pages = {383--398},
title = {{Return-oriented rootkits: Bypassing kernel code integrity protection mechanisms}},
year = {2009}
}
@article{Guo2018,
abstract = {While deep learning has shown a great potential in various domains, the lack of transparency has limited its application in security or safety-critical areas. Existing research has attempted to develop explanation techniques to provide interpretable explanations for each classification decision. Unfortunately, current methods are optimized for non-security tasks (e.g., image analysis). Their key assumptions are often violated in security applications, leading to a poor explanation fidelity. In this paper, we propose LEMNA, a high-fidelity explanation method dedicated for security applications. Given an input data sample, LEMNA generates a small set of interpretable features to explain how the input sample is classified. The core idea is to approximate a local area of the complex deep learning decision boundary using a simple interpretable model. The local interpretable model is specially designed to (1) handle feature dependency to better work with security applications (e.g., binary code analysis); and (2) handle nonlinear local boundaries to boost explanation fidelity. We evaluate our system using two popular deep learning applications in security (a malware classifier, and a function start detector for binary reverse-engineering). Extensive evaluations show that LEMNA's explanation has a much higher fidelity level compared to existing methods. In addition, we demonstrate practical use cases of LEMNA to help machine learning developers to validate model behavior, troubleshoot classification errors, and automatically patch the errors of the target models.},
author = {Guo, Wenbo and Mu, Dongliang and Xu, Jun and Su, Purui and Wang, Gang and Xing, Xinyu},
doi = {10.1145/3243734.3243792},
file = {:F\:/papers/Guo et al. - 2018 - Lemna Explaining deep learning based security applications.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Binary Analysis,Deep Recurrent Neural Networks,Explainable AI},
pages = {364--379},
title = {{Lemna: Explaining deep learning based security applications}},
year = {2018}
}
@article{Erlingsson2006,
abstract = {XFI is a comprehensive protection system that offers both flexible access control and fundamental integrity guarantees, at any privilege level and even for legacy code in commodity systems. For this purpose, XFI combines static analysis with inline software guards and a two-stack execution model. We have implemented XFI for Windows on the x86 architecture using binary rewriting and a simple, stand-alone verifier; the implementation's correctness depends on the verifier, but not on the rewriter. We have applied XFI to software such as device drivers and multimedia codecs. The resulting modules function safely within both kernel and user-mode address spaces, with only modest enforcement overheads.},
author = {Erlingsson, {\'{U}}lfar and Abadi, Mart{\'{i}}n and Vrable, Michael and Budiu, Mihai and Necula, George C.},
file = {:F\:/D2/erlingsson.pdf:pdf},
journal = {OSDI 2006 - 7th USENIX Symposium on Operating Systems Design and Implementation},
pages = {75--88},
title = {{XFI: Software guards for system address spaces}},
year = {2006}
}
@book{Mi,
abstract = {Today's cloud tenants are facing severe security threats such as compromised hypervisors, which forces a strong adversary model where the hypervisor should be excluded out of the TCB. Previous approaches to shielding guest VMs either suffer from insufficient protection or result in suboptimal performance due to frequent VM exits (especially for I/O operations). This paper presents CloudVisor-D, an efficient nested hypervisor design that embraces both strong protection and high performance. The core idea of CloudVisor-D is to disaggregate the nested hypervisor by separating major protection logics into a protected Guardian-VM alongside each guest VM. The Guardian-VM is securely isolated and protected by the nested hypervisor and provides secure services for most privileged operations like hypercalls, EPT violations and I/O operations from guest VMs. By lever-aging recent hardware features, most privileged operations from a guest VM require no VM exits to the nested hypervi-sor, which are the major sources of performance slowdown in prior designs. We have implemented CloudVisor-D on a commercially available machine with these recent hardware features. Experimental evaluation shows that CloudVisor-D incurs negligible performance overhead even for I/O intensive benchmarks and in some cases outperforms a vanilla hy-pervisor due to the reduced number of VM exits.},
author = {Mi, Zeyu and Li, Dingji and Chen, Haibo and Zang, Binyu and Guan, Haibing},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mi et al. - Unknown - (Mostly) Exitless VM Protection from Untrusted Hypervisor through Disaggregated Nested Virtualization(2).pdf:pdf},
isbn = {9781939133175},
title = {{ (Mostly) Exitless VM Protection from Untrusted Hypervisor through Disaggregated Nested Virtualization}},
url = {www.usenix.org/conference/usenixsecurity20/presentation/mi}
}
@article{Heelan2018,
abstract = {Heap layout manipulation is integral to exploiting heap-based memory corruption vulnerabilities. In this paper we present the first automatic approach to the problem, based on pseudo-random black-box search. Our approach searches for the inputs required to place the source of a heap-based buffer overflow or underflow next to heap-allocated objects that an exploit developer, or automatic exploit generation system, wishes to read or corrupt. We present a framework for benchmarking heap layout manipulation algorithms, and use it to evaluate our approach on several real-world allocators, showing that pseudo-random black box search can be highly effective. We then present SHRIKE, a novel system that can perform automatic heap layout manipulation on the PHP interpreter and can be used in the construction of control-flow hijacking exploits. Starting from PHP's regression tests, SHRIKE discovers fragments of PHP code that interact with the interpreter's heap in useful ways, such as making allocations and deallocations of particular sizes, or allocating objects containing sensitive data, such as pointers. SHRIKE then uses our search algorithm to piece together these fragments into programs, searching for one that achieves a desired heap layout. SHRIKE allows an exploit developer to focus on the higher level concepts in an exploit, and to defer the resolution of heap layout constraints to SHRIKE. We demonstrate this by using SHRIKE in the construction of a control-flow hijacking exploit for the PHP interpreter.},
archivePrefix = {arXiv},
arxivId = {1804.08470},
author = {Heelan, Sean and Melham, Tom and Kroening, Daniel},
eprint = {1804.08470},
file = {:F\:/D2/sec18-heelan.pdf:pdf},
isbn = {9781939133045},
journal = {Proceedings of the 27th USENIX Security Symposium},
pages = {763--779},
title = {{Automatic heap layout manipulation for exploitation}},
year = {2018}
}
@article{Criswell2014,
abstract = {We present a new system, KCoFI, that is the first we know of to provide complete Control-Flow Integrity protection for commodity operating systems without using heavyweight complete memory safety. Unlike previous systems, KCoFI protects commodity operating systems from classical control-flow hijack attacks, return-to-user attacks, and code segment modification attacks. We formally verify a subset of KCoFI's design by modeling several features in small-step semantics and providing a partial proof that the semantics maintain control-flow integrity. The model and proof account for operations such as page table management, trap handlers, context switching, and signal delivery. Our evaluation shows that KCoFI prevents all the gadgets found by an open-source Return Oriented Programming (ROP) gadget-finding tool in the FreeBSD kernel from being used, it also reduces the number of indirect control-flow targets by 98.18%. Our evaluation also shows that the performance impact of KCoFI on web server bandwidth is negligible while file transfer bandwidth using OpenSSH is reduced by an average of 13%, and at worst 27%, across a wide range of file sizes. Postmark, an extremely file-system intensive benchmark, shows 2x overhead. Where comparable numbers are available, the overheads of KCoFI are far lower than heavyweight memory-safety techniques.},
author = {Criswell, John and Dautenhahn, Nathan and Adve, Vikram},
doi = {10.1109/SP.2014.26},
file = {:F\:/papers/Criswell, Dautenhahn, Adve - 2014 - KCoFI Complete control-flow integrity for commodity operating system kernels.pdf:pdf},
isbn = {9781479946860},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Free BSD,compiler,control-flow integrity,formal verification,operating systems},
pages = {292--307},
publisher = {IEEE},
title = {{KCoFI: Complete control-flow integrity for commodity operating system kernels}},
year = {2014}
}
@article{Seshadri2007,
abstract = {We propose SecVisor, a tiny hypervisor that ensures code integrity for commodity OS kernels. In particular, SecVisor ensures that only user-approved code can execute in kernel mode over the entire system lifetime. This protects the kernel against code injection attacks, such as kernel rootkits. SecVisor can achieve this property even against an attacker who controls everything but the CPU, the memory controller, and system memory chips. Further, SecVisor can even defend against attackers with knowledge of zero-day kernel exploits. Our goal is to make SecVisor amenable to formal verification and manual audit, thereby making it possible to rule out known classes of vulnerabilities. To this end, SecVisor offers small code size and small external interface. We rely on memory virtualization to build SecVisor and implement two versions, one using software memory virtualization and the other using CPU-supported memory virtualization. The code sizes of the runtime portions of these versions are 1739 and 1112 lines, respectively. The size of the external interface for both versions of SecVisor is 2 hypercalls. It is easy to port OS kernels to SecVisor. We port the Linux kernel version 2.6.20 by adding 12 lines and deleting 81 lines, out of a total of approximately 4.3 million lines of code in the kernel. Copyright 2007 ACM.},
author = {Seshadri, Arvind and Luk, Mark and Qu, Ning and Perrig, Adrian},
file = {:F\:/D2/1294261.1294294.pdf:pdf},
isbn = {9781595935915},
journal = {SOSP'07 - Proceedings of 21st ACM SIGOPS Symposium on Operating Systems Principles},
keywords = {Code attestation,Code integrity,Hypervisor,Memory virtualization,Preventing code injection attacks},
pages = {335--350},
title = {{SecVisor: A tiny hypervisor to provide lifetime kernel code integrity for commodity OSes}},
year = {2007}
}
@article{Markuze2016,
author = {Markuze, Alex},
file = {:F\:/D2/2872362.2872379.pdf:pdf},
isbn = {9781450340915},
journal = {Proceedings of the 21st International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS'16)},
keywords = {dma attacks,iommu},
pages = {249--262},
title = {{Ture IOMMU Protection from DMA Attacks: When Copy is Fsater}},
year = {2016}
}
@article{Zhong,
author = {Zhong, Bingnan},
file = {:F\:/D2/SecPT-20210418-edit.pdf:pdf},
keywords = {memory,page table protection,smap},
title = {{SecPT ： Providing Efficient Page Table Protection based on SMAP feature in an Untrusted Commodity Kernel}}
}
@article{Bai,
author = {Bai, Jia-ju and Lu, Kangjie},
file = {:F\:/D2/sec21fall-bai.pdf:pdf},
title = {{Static Detection of Unsafe DMA Accesses in Device Drivers}}
}
@article{Narayanan2020,
abstract = {Commodity operating systems execute core kernel subsystems in a single address space along with hundreds of dynamically loaded extensions and device drivers. Lack of isolation within the kernel implies that a vulnerability in any of the kernel subsystems or device drivers opens a way to mount a successful attack on the entire kernel. Historically, isolation within the kernel remained prohibitive due to the high cost of hardware isolation primitives. Recent CPUs, however, bring a new set of mechanisms. Extended page-Table (EPT) switching with VM functions and memory protection keys (MPKs) provide memory isolation and invocations across boundaries of protection domains with overheads comparable to system calls. Unfortunately, neither MPKs nor EPT switching provide architectural support for isolation of privileged ring 0 kernel code, i.e., control of privileged instructions and well-defined entry points to securely restore state of the system on transition between isolated domains. Our work develops a collection of techniques for lightweight isolation of privileged kernel code. To control execution of privileged instructions, we rely on a minimal hypervisor that transparently deprivileges the system into a non-root VT-x guest. We develop a new isolation boundary that leverages extended page table (EPT) switching with the VMFUNC instruction. We define a set of invariants that allows us to isolate kernel components in the face of an intricate execution model of the kernel, e.g., provide isolation of preemptable, concurrent interrupt handlers. To minimize overheads of virtualization, we develop support for exitless interrupt delivery across isolated domains. We evaluate our approach by developing isolated versions of several device drivers in the Linux kernel.},
author = {Narayanan, Vikram and Huang, Yongzhe and Tan, Gang and Jaeger, Trent and Burtsev, Anton},
doi = {10.1145/3381052.3381328},
file = {:F\:/D2/3381052.3381328.pdf:pdf},
isbn = {9781450375542},
journal = {VEE 2020 - Proceedings of the 16th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {157--171},
title = {{Lightweight kernel isolation with virtualization and VM functions}},
year = {2020}
}
@article{Lawall2018,
abstract = {The Coccinelle C-program matching and transformation tool was first released in 2008 to facilitate specification and automation in the evolution of Linux kernel code. The novel contribution of Coccinelle was that it allows software developers to write code manipulation rules in terms of the code structure itself, via a generalization of the patch syntax. Over the years, Coccinelle has been extensively used in Linux kernel development, resulting in over 6000 commits to the Linux kernel, and has found its place as part of the Linux kernel development process. This paper studies the impact of Coccinelle on Linux kernel development and the features of Coccinelle that have made it possible. It provides guidance on how other research-based tools can achieve practical impact in the open-source development community.},
author = {Lawall, Julia and Muller, Gilles},
file = {:F\:/papers/atc18-lawall.pdf:pdf},
isbn = {978-1-931971-44-7},
journal = {Atc},
title = {{Coccinelle: 10 Years of Automated Evolution in the Linux Kernel}},
url = {https://www.usenix.org/conference/atc18/presentation/lawall},
year = {2018}
}
@article{Ispoglou2018,
abstract = {With the widespread deployment of Control-Flow Integrity (CFI), control-flow hijacking attacks, and consequently code reuse attacks, are significantly more difficult. CFI limits control flow to well-known locations, severely restricting arbitrary code execution. Assessing the remaining attack surface of an application under advanced control-flow hijack defenses such as CFI and shadow stacks remains an open problem. We introduce BOPC, a mechanism to automatically assess whether an attacker can execute arbitrary code on a binary hardened with CFI/shadow stack defenses. BOPC computes exploits for a target program from payload specifications written in a Turing-complete, high-level language called SPL that abstracts away architecture and program-specific details. SPL payloads are compiled into a program trace that executes the desired behavior on top of the target binary. The input for BOPC is an SPL payload, a starting point (e.g., from a fuzzer crash) and an arbitrary memory write primitive that allows application state corruption. To map SPL payloads to a program trace, BOPC introduces Block Oriented Programming (BOP), a new code reuse technique that utilizes entire basic blocks as gadgets along valid execution paths in the program, i.e., without violating CFI or shadow stack policies. We find that the problem of mapping payloads to program traces is NP-hard, so BOPC first reduces the search space by pruning infeasible paths and then uses heuristics to guide the search to probable paths. BOPC encodes the BOP payload as a set of memory writes. We execute 13 SPL payloads applied to 10 popular applications. BOPC successfully finds payloads and complex execution traces – which would likely not have been found through manual analysis – while following the target's Control-Flow Graph under an ideal CFI policy in 81% of the cases.},
archivePrefix = {arXiv},
arxivId = {1805.04767},
author = {Ispoglou, Kyriakos K. and Jaeger, Trent and AlBassam, Bader and Payer, Mathias},
doi = {10.1145/3243734.3243739},
eprint = {1805.04767},
file = {:F\:/D2/3243734.3243739.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
pages = {1868--1882},
title = {{Block oriented programming: Automating data-only attacks}},
year = {2018}
}
@article{Kwon2018,
abstract = {Large OS kernels always suffer from attacks due to their numerous inherent vulnerabilities. To protect the kernel, hypervisors have been employed by many security solutions. However, relying on a hypervisor has a detrimental impact on the system performance due mainly to nested paging. In this paper, we present Hypernel, a security framework combining hardware and software components to address this problem. Hypersec, the software component, provides an isolated execution environment for security solutions, and the hardware monitor component enables a word-granularity monitoring capability on the kernel memory. Our evaluation shows that Hypernel efficiently fulfills the role of a security framework, while imposing mere 3.1% of runtime overhead on the system.},
author = {Kwon, Donghyun and Oh, Kuenwhee and Park, Junmo and {Yang KAIST}, Seungyong and Cho, Yeongpil and {Byunghoon Kang KAIST}, Brent and Paek, Yunheung},
doi = {10.1145/3195970.3196061},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwon et al. - 2018 - Hypernel A Hardware-Assisted Framework for Kernel Protection without Nested Paging.pdf:pdf},
isbn = {9781450357005},
title = {{Hypernel: A Hardware-Assisted Framework for Kernel Protection without Nested Paging}},
url = {https://doi.org/10.1145/3195970.3196061},
year = {2018}
}
@article{Zhang2017,
abstract = {Code diversification, combined with execute-only memory, provides an effective defense against just-in-Time code reuse attacks. However, existing techniques for combining code diversification and hardware-Assisted memory protections typically require compiler support, as well as the deployment or modification of a hypervisor. These requirements often cannot be met, either because source code is not available, or because the required hardware features may not be available on the target system. In this paper we present SECRET, a software hardening technique tailored to legacy and closed-source software that provides equivalent protection to execute-only memory without relying on hardware features or recompilation. This is achieved using two novel techniques, code space isolation and code pointer remapping, which prevent read accesses to the executable memory of the protected code. Furthermore, SECRET thwarts code pointer harvesting attacks on ELF files by remapping existing code pointers to use random values. SECRET has been implemented on 32-bit Linux systems. Our evaluation shows that it introduces just 2% additional runtime overhead on top of a stateof-the-Art CFI implementation, bringing the total average overhead to about 16%. In addition, it achieves better protection coverage compared to compiler-based techniques, as it can handle low-level machine code such as inline assembly or extra code introduced by the linker and loader.},
author = {Zhang, Mingwei and Sekar, R.},
doi = {10.1145/3134600.3134634},
file = {:F\:/D2/3134600.3134634.pdf:pdf},
isbn = {9781450353458},
journal = {ACM International Conference Proceeding Series},
pages = {128--140},
title = {{Protecting COTS binaries from disclosure-guided code reuse attacks}},
volume = {Part F1325},
year = {2017}
}
@article{Wressnegger2016,
abstract = {Subtle flaws in integer computations are a prime source for exploitable vulnerabilities in system code. Unfortunately, even code shown to be secure on one platform can be vulnerable on another, making the migration of code a notable security challenge. In this paper, we provide the first study on how code that works as expected on 32-bit platforms can become vulnerable on 64-bit platforms. To this end, we systematically review the effects of data model changes between platforms. We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable ("Jessie") and 200 popular open-source projects hosted on GitHub. Moreover, we discuss 64-bit migration vulnerabilities that have been discovered as part of our study, including vulnerabilities in Chromium, the Boost C++ Libraries, libarchive, the Linux Kernel, and zlib.},
author = {Wressnegger, Christian and Yamaguchi, Fabian and Maier, Alwin and Rieck, Konrad},
doi = {10.1145/2976749.2978403},
file = {:F\:/papers/2976749.2978403.pdf:pdf},
isbn = {9781450341394},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Data models,Integer-based vulnerabilities,Software security},
pages = {541--552},
title = {{Twice the bits, twice the trouble: Vulnerabilities induced by migrating to 64-bit platforms}},
volume = {24-28-Octo},
year = {2016}
}
@article{Azab2017,
abstract = {—Previous research on kernel monitoring and protec-tion widely relies on higher privileged system components, such as hardware virtualization extensions, to isolate security tools from potential kernel attacks. These approaches increase both the maintenance effort and the code base size of privileged system components, which consequently increases the risk of having security vulnerabilities. SKEE, which stands for Secure Kernel-level Execution Environment, solves this fundamental problem. SKEE is a novel system that provides an isolated lightweight execution environment at the same privilege level of the kernel. SKEE is designed for commodity ARM platforms. Its main goal is to allow secure monitoring and protection of the kernel without active involvement of higher privileged software. SKEE provides a set of novel techniques to guarantee isola-tion. It creates a protected address space that is not accessible to the kernel, which is challenging to achieve when both the kernel and the isolated environment share the same privilege level. SKEE solves this challenge by preventing the kernel from managing its own memory translation tables. Hence, the kernel is forced to switch to SKEE to modify the system's memory layout. In turn, SKEE verifies that the requested modification does not compromise the isolation of the protected address space. Switch-ing from the OS kernel to SKEE exclusively passes through a well-controlled switch gate. This switch gate is carefully designed so that its execution sequence is atomic and deterministic. These properties combined guarantee that a potentially compromised kernel cannot exploit the switching sequence to compromise the isolation. If the kernel attempts to violate these properties, it will only cause the system to fail without exposing the protected address space. SKEE exclusively controls access permissions of the entire OS memory. Hence, it prevents attacks that attempt to inject unverified code into the kernel. Moreover, it can be easily extended to intercept other system events in order to support various intrusion detection and integrity verification tools. This paper presents a SKEE prototype that runs on both 32-bit ARMv7 and 64-bit ARMv8 architectures. Performance evaluation results demonstrate that SKEE is a practical solution for real world systems.},
author = {Azab, Ahmed and Swidowski, Kirk and Bhutkar, Rohan and Ma, Jia and Shen, Wenbo and Wang, Ruowen and Ning, Peng},
doi = {10.14722/ndss.2016.23009},
file = {:F\:/D2/skee-ndss16.pdf:pdf},
isbn = {189156241X},
number = {February},
pages = {21--24},
title = {{SKEE: A Lightweight Secure Kernel-level Execution Environment for ARM}},
year = {2017}
}
@article{Koromilas2016,
abstract = {Kernel rootkits can exploit an operating system and enable future accessibility and control, despite all recent advances in software protection. A promising defense mechanism against rootkits is Kernel Integrity Monitor (KIM) systems, which inspect the kernel text and data to discover any malicious changes. A KIM can be implemented either in software, using a hypervisor, or using extra hardware. The latter option is more attractive due to better performance and higher security, since the monitor is isolated from the potentially vulnerable host. To remain under the radar and avoid detection it is paramount for a rootkit to conceal its malicious activities. In order to detect self-hiding rootkits researchers have proposed snooping for inferring suspicious behaviour in kernel memory. This is accomplished by constantly monitoring all memory accesses on the bus and not the actual memory area where the kernel is mapped. In this paper, we present GRIM, an external memory monitor that is built on commodity, off-the-shelf, graphics hardware, and is able to verify OS kernel integrity at a speed that outperforms all so-far published snapshot-based systems. GRIM allows for checking eight thousand 64-bit values simultaneously at a 10 KHz snapshot frequency, which is sufficient to accurately detect a self-hiding loadable kernel module insertion. According to the state-of-the-art, this detection can only happen using a snoop-based monitor. GRIM does not only demonstrate that snapshot-based monitors can be significantly improved, but it additionally offers a fully programmable platform that can be instantly deployed without requiring any modifications to the host it protects. Notice that all snoop-based monitors require substantial changes at the microprocessor level. L. Koromilas-This work was performed while at FORTH, Greece.},
author = {Koromilas, Lazaros and Vasiliadis, Giorgos and Athanasopoulos, Elias and Ioannidis, Sotiris},
doi = {10.1007/978-3-319-45719-2},
file = {:F\:/D2/Koromilas2016_Chapter_GRIMLeveragingGPUsForKernelInt.pdf:pdf},
journal = {RAID},
pages = {3--23},
publisher = {Springer International Publishing Switzerland},
title = {{GRIM: Leveraging GPUs for Kernel Integrity Monitoring}},
volume = {9854},
year = {2016}
}
@article{Osterlund2019,
abstract = {Kernel information leak vulnerabilities are a major security threat to production systems. Attackers can exploit them to leak confidential information such as cryptographic keys or kernel pointers. Despite efforts by kernel developers and researchers, existing defenses for kernels such as Linux are limited in scope or incur a prohibitive performance overhead. In this paper, we present kMVX, a comprehensive defense against information leak vulnerabilities in the kernel by running multiple diversified kernel variants simultaneously on the same machine. By constructing these variants in a careful manner, we can ensure they only show divergences when an attacker tries to exploit bugs present in the kernel. By detecting these divergences we can prevent kernel information leaks. Our kMVX design is inspired by multi-variant execution (MVX). Traditional MVX designs cannot be applied to kernels because of their assumptions on the run-time environment. kMVX, on the other hand, can be applied even to commodity kernels. We show our Linux-based prototype provides powerful protection against information leaks at acceptable performance overhead (20-50% in the worst case for popular server applications).},
author = {{\"{O}}sterlund, Sebastian and Koning, Koen and Olivier, Pierre and Barbalace, Antonio and Bos, Herbert and Giuffrida, Cristiano},
doi = {10.1145/3297858.3304054},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/{\"{O}}sterlund et al. - 2019 - KMVX Detecting Kernel Information Leaks with Multi-variant Execution.pdf:pdf},
isbn = {9781450362405},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {information leaks,multi-variant exection,operating systems,security},
pages = {559--572},
title = {{KMVX: Detecting Kernel Information Leaks with Multi-variant Execution}},
year = {2019}
}
@book{Beschastnikh2020,
abstract = {Distributed systems pose unique challenges for software developers. Understanding the system's communication topology and reasoning about concurrent activities of system hosts can be difficult. The standard approach, analyzing system logs, can be a tedious and complex process that involves reconstructing a system log from multiple hosts' logs, reconciling timestamps among hosts with non-synchronized clocks, and understanding what took place during the execution encoded by the log. This article presents a novel approach for tackling three tasks frequently performed during analysis of distributed system executions: (1) understanding the relative ordering of events, (2) searching for specific patterns of interaction between hosts, and (3) identifying structural similarities and differences between pairs of executions. Our approach consists of XVector, which instruments distributed systems to capture partial ordering information that encodes the happens-before relation between events, and ShiViz, which processes the resulting logs and presents distributed system executions as interactive time-space diagrams. Two user studies with a total of 109 students and a case study with 2 developers showed that our method was effective, helping participants answer statistically significantly more system-comprehension questions correctly, with a very large effect size.},
author = {Beschastnikh, Ivan and Liu, Perry and Xing, Albert and Wang, Patty and Brun, Yuriy and Ernst, Michael D.},
booktitle = {ACM Transactions on Software Engineering and Methodology},
doi = {10.1145/3375633},
file = {:F\:/D2/3375633.pdf:pdf},
isbn = {8750122010},
issn = {15577392},
keywords = {Distributed systems,log analysis,program comprehension},
number = {2},
title = {{Visualizing Distributed System Executions}},
volume = {29},
year = {2020}
}
@article{Li2020,
abstract = {Context sensitivity is an essential technique for ensuring high precision in static analyses. It has been observed that applying context sensitivity partially, only on a select subset of the methods, can improve the balance between analysis precision and speed. However, existing techniques are based on heuristics that do not provide much insight into what characterizes this method subset. In this work, we present a more principled approach for identifying precision-critical methods, based on general patterns of value flows that explain where most of the imprecision arises in context-insensitive pointer analysis. Using this theoretical foundation, we present an efficient algorithm, ZIPPER, to recognize these flow patterns in a given program and employ context sensitivity accordingly. We also present a variant, ZIPPERe, that additionally takes into account which methods are disproportionally costly to analyze with context sensitivity. Our experimental results on standard benchmark and real-world Java programs show that ZIPPER preserves effectively all of the precision (98.8%) of a highly precise conventional context-sensitive pointer analysis (2-object-sensitive with a context-sensitive heap, 2obj for short), with a substantial speedup (on average, 3.4× and up to 9.4×), and that ZIPPERe preserves 94.7% of the precision of 2obj, with an order-of-magnitude speedup (on average, 25.5× and up to 88×). In addition, for 10 programs that cannot be analyzed by 2obj within a three-hour time limit, on average ZIPPERe can guide 2obj to finish analyzing them in less than 11 minutes with high precision compared to context-insensitive and introspective context-sensitive analyses.},
author = {Li, Yue and Tan, Tian and M{\o}ller, Anders and Smaragdakis, Yannis},
doi = {10.1145/3381915},
file = {:F\:/D2/3381915.pdf:pdf},
issn = {15584593},
journal = {ACM Transactions on Programming Languages and Systems},
keywords = {Java,Static analysis,points-to analysis},
number = {2},
title = {{A Principled Approach to Selective Context Sensitivity for Pointer Analysis}},
volume = {42},
year = {2020}
}
@article{Kornmesser2008,
abstract = {In this article I will compare two approaches for defining theoretical terms, that of Logical Empirism (especially the approach of R. Carnap) and that of Structuralism (according to the works of J. Sneed and W. Stegm{\"{u}}ller). I will determine explicitly the accounts of theoreticity in both Logical Empirism and Structuralism, and compare them by means of a case study: a structuralistic reconstruction of Neurobiological Constructivism (according to the theory of G. Roth). I will point out that the structuralistic criticism on the account of theoreticity of Logical Empirism is insufficient and that the structuralistic criterion of theoreticity does not satisfy the requirements of demarcation for theoretical terms demanded by Logical Empirism. {\textcopyright} 2008 Springer Science+Business Media B.V.},
author = {Kornmesser, Stephan},
doi = {10.1007/s10838-008-9062-0},
file = {:F\:/papers/Kornmesser - 2008 - Theoretizit{\"{a}}t im logischen empirismus und im strukturalismus - Erl{\"{a}}utert am fallbeispiel des neurobiologischen konst.pdf:pdf},
issn = {09254560},
journal = {Journal for General Philosophy of Science},
number = {1},
pages = {53--67},
title = {{Bitcoin: A Peer-to-Peer Electronic Cash System}},
volume = {39},
year = {2008}
}
@article{Jiang2020,
abstract = {Error handling code is often critical but difficult to test in reality. As a result, many hard-to-find bugs exist in error handling code and may cause serious security problems once triggered. Fuzzing has become a widely used technique for finding software bugs nowadays. Fuzzing approaches mutate and/or generate various inputs to cover infrequently-executed code. However, existing fuzzing approaches are very limited in testing error handling code, because some of this code can be only triggered by occasional errors (such as insufficient memory and network-connection failures), but not specific inputs. Therefore, existing fuzzing approaches in general cannot effectively test such error handling code. In this paper, we propose a new fuzzing framework named FIFUZZ, to effectively test error handling code and detect bugs. The core of FIFUZZ is a context-sensitive software fault injection (SFI) approach, which can effectively cover error handling code in different calling contexts to find deep bugs hidden in error handling code with complicated contexts. We have implemented FIFUZZ and evaluated it on 9 widely-used C programs. It reports 317 alerts which are caused by 50 unique bugs in terms of the root causes. 32 of these bugs have been confirmed by related developers. We also compare FIFUZZ to existing fuzzing tools (including AFL, AFLFast, AFLSmart and FairFuzz), and find that FIFUZZ finds many bugs missed by these tools. We believe that FIFUZZ can effectively augment existing fuzzing approaches to find many real bugs that have been otherwise missed.},
author = {Jiang, Zu-Ming and Bai, Jia-Ju and Lu, Kangjie and Hu, Shi-Min},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2020 - Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection.pdf:pdf},
journal = {USENIX Security},
title = {{Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection}},
year = {2020}
}
@article{Bittau2014,
abstract = {We show that it is possible to write remote stack buffer overflow exploits without possessing a copy of the target binary or source code, against services that restart after a crash. This makes it possible to hack proprietary closed-binary services, or open-source servers manually compiled and installed from source where the binary remains unknown to the attacker. Traditional techniques are usually paired against a particular binary and distribution where the hacker knows the location of useful gadgets for Return Oriented Programming (ROP). Our Blind ROP (BROP) attack instead remotely finds enough ROP gadgets to perform a write system call and transfers the vulnerable binary over the network, after which an exploit can be completed using known techniques. This is accomplished by leaking a single bit of information based on whether a process crashed or not when given a particular input string. BROP requires a stack vulnerability and a service that restarts after a crash. We implemented Braille, a fully automated exploit that yielded a shell in under 4,000 requests (20 minutes) against a contemporary nginx vulnerability, yaSSL + MySQL, and a toy proprietary server written by a colleague. The attack works against modern 64-bit Linux with address space layout randomization (ASLR), no-execute page protection (NX) and stack canaries.},
author = {Bittau, Andrea and Belay, Adam and Mashtizadeh, Ali and Mazi{\`{e}}res, David and Boneh, Dan},
doi = {10.1109/SP.2014.22},
file = {:F\:/papers/Bittau et al. - 2014 - Hacking blind.pdf:pdf},
isbn = {9781479946860},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {227--242},
title = {{Hacking blind}},
year = {2014}
}
@article{Raj2007,
abstract = {While industry is making rapid advances in system virtualization, for server consolidation and for improving system maintenance and management, it has not yet become clear how virtualization can contribute to the performance of high end systems. In this context, this paper addresses a key issue in system virtualization - how to efficiently virtualize I/O subsystems and peripheral devices. We have developed a novel approach to I/O virtualization, termed self-virtualized devices, which improves I/O performance by off loading select virtualization functionality onto the device. This permits guest virtual machines to more efficiently (i.e., with less overhead and reduced latency) interact with the virtualized device. The concrete instance of such a device developed and evaluated in this paper is a self-virtualized network interface (SV-NIC), targeting the high end NICs used in thehigh performance domain. The SV-NIC (1) provides virtual interfaces (VIFs) to guest virtual machines for an underlying physical device, the network interface, (2) manages the wayin which the device's physical resources are used by guest operating systems, and (3) provides high performance, low overhead network access to guest domains. Experimental results are attained in a prototyping environment using an IXP 2400-based ethernet board as a programmable network device. The SV-NIC scales to large numbers of VIFs and guests, and offers VIFs with 77% higher throughput and 53% less latency compared to the current standard virtualized device implementations on hyper visor-based platforms. Copyright 2007 ACM.},
author = {Raj, Himanshu and Schwan, Karsten},
doi = {10.1145/1272366.1272390},
file = {:F\:/D2/1272366.1272390.pdf:pdf},
isbn = {1595936734},
journal = {Proceedings of the 16th International Symposium on High Performance Distributed Computing 2007, HPDC'07},
keywords = {Virtual devices,Virtualization},
pages = {179--188},
title = {{High performance and scalable I/O virtualization via self-virtualized devices}},
year = {2007}
}
@article{Xu2019,
abstract = {CONFIRM (CONtrol-Flow Integrity Relevance Metrics) is a new evaluation methodology and microbenchmarking suite for assessing compatibility, applicability, and relevance of control-flow integrity (CFI) protections for preserving the intended semantics of software while protecting it from abuse. Although CFI has become a mainstay of protecting certain classes of software from code-reuse attacks, and continues to be improved by ongoing research, its ability to preserve intended program functionalities (semantic transparency) of diverse, mainstream software products has been under-studied in the literature. This is in part because although CFI solutions are evaluated in terms of performance and security, there remains no standard regimen for assessing compatibility. Researchers must often therefore resort to anecdotal assessments, consisting of tests on homogeneous software collections with limited variety (e.g., GNU Coreutils), or on CPU benchmarks (e.g., SPEC) whose limited code features are not representative of large, mainstream software products. Reevaluation of CFI solutions using CONFIRM reveals that there remain significant unsolved challenges in securing many large classes of software products with CFI, including software for market-dominant OSes (e.g., Windows) and code employing certain ubiquitous coding idioms (e.g., event-driven callbacks and exceptions). An estimated 47% of CFI-relevant code features with high compatibility impact remain incompletely supported by existing CFI algorithms, or receive weakened controls that leave prevalent threats unaddressed (e.g., return-oriented programming attacks). Discussion of these open problems highlights issues that future research must address to bridge these important gaps between CFI theory and practice.},
author = {Xu, Xiaoyang and Ghaffarinia, Masoud and Wang, Wenhao and Hamlen, Kevin W. and Lin, Zhiqiang},
file = {:F\:/D2/sec19-xu-xiaoyang.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1805--1821},
title = {{ConfirM: Evaluating compatibility and relevance of control-flow integrity protections for modern software}},
year = {2019}
}
@book{Fiky2021,
abstract = {Nowadays, smartphones became an integral part of human life due to the great necessity for their daily activities. Most smartphone users are downloading and installing mobile apps without worrying about security. Therefore, smartphones are a winning goal for malware, mainly with Android devices. So, it was necessary to provide an intelligent model for detecting malware applications before installing them on android smartphones. In this paper, an intelligent model using machine learning algorithms is proposed for detecting the malware applications in smartphones based on the static malware analysis technique. The contents of an android application features are analyzed, such as permissions, intents, system commands, and API-calls that were extracted from the application manifest file and source code. The proposed model is applied on two separate datasets DREBIN and MALGENOME. The experimental results are compared with some other similar researches, and their results were analyzed. The results indicate that the performance of the proposed model outperforms other similar models for some selected classifiers and can reliably detect both malware and benign Android applications with high accuracy.},
author = {Fiky, Ahmed Hashem El and Elshenawy, Ayman and Madkour, Mohamed Ashraf},
booktitle = {2021 International Mobile, Intelligent, and Ubiquitous Computing Conference, MIUCC 2021},
doi = {10.1109/MIUCC52538.2021.9447661},
file = {:F\:/D2/Pandey2021_Chapter_DetectionOfAndroidMalwareUsing.pdf:pdf},
isbn = {9781665412438},
keywords = {Android apps,Android malware,Android malware detection,Machine Learning,Static Analysis},
pages = {9--16},
publisher = {Springer Singapore},
title = {{Detection of Android Malware using Machine Learning}},
url = {http://dx.doi.org/10.1007/978-981-33-4543-0_71},
year = {2021}
}
@article{Miller2019,
abstract = {The ability to extend kernel functionality safely has long been a design goal for operating systems. Modern operating systems, such as Linux, are structured for extensibility to enable sharing a single code base among many environments. Unfortunately, safety has lagged behind, and bugs in kernel extensions continue to cause problems. We study three recent kernel extensions critical to Docker containers (Overlay File System, Open vSwitch Datapath, and AppArmor) to guide further research in extension safety. We find that all the studied kernel extensions suffer from the same set of low-level memory, concurrency, and type errors. Though safe kernel extensibility is a well-studied area, existing solutions are heavyweight, requiring extensive changes to the kernel and/or expensive runtime checks. We then explore the feasibility of writing kernel extensions in a high-level, type safe language (i.e., Rust) while preserving compatibility with Linux and find this to be an appealing approach. We show that there are key challenges to implementing this approach and propose potential solutions.},
author = {Miller, Samantha and Zhang, Kaiyuan and Zhuo, Danyang and Xu, Shibin and Krishnamurthy, Arvind and Anderson, Thomas},
doi = {10.1145/3317550.3321429},
file = {:F\:/papers/3317550.3321429.pdf:pdf},
isbn = {9781450367271},
journal = {Proceedings of the Workshop on Hot Topics in Operating Systems, HotOS 2019},
keywords = {Rust,extensibility,operating systems},
pages = {170--176},
title = {{Practical Safe Linux Kernel Extensibility}},
year = {2019}
}
@article{Hofmann2013,
abstract = {InkTag is a virtualization-based architecture that gives strong safety guarantees to high-assurance processes even in the presence of a malicious operating system. InkTag advances the state of the art in untrusted operating systems in both the design of its hypervisor and in the ability to run useful applications without trusting the operating system. We introduce paraverification, a technique that simplifies the InkTag hypervisor by forcing the untrusted operating system to participate in its own verification. Attribute-based access control allows trusted applications to create decentralized access control policies. InkTag is also the first system of its kind to ensure consistency between secure data and metadata, ensuring recoverability in the face of system crashes.},
author = {Hofmann, Owen S. and Kim, Sangman and Dunn, Alan M. and Lee, Michael Z. and Witchel, Emmett},
doi = {10.1145/2499368.2451146},
file = {:F\:/papers/Hofmann et al. - 2013 - InkTag Secure applications on an untrusted operating system.pdf:pdf},
isbn = {9781450318709},
issn = {15232867},
journal = {ACM SIGPLAN Notices},
keywords = {Application protection,Paraverification,Virtualization-based security},
number = {4},
pages = {265--278},
pmid = {24429939},
title = {{InkTag: Secure applications on an untrusted operating system}},
volume = {48},
year = {2013}
}
@article{Liljestrand2018,
abstract = {Run-time attacks against programs written in memory-unsafe programming languages (e.g., C and C++) remain a prominent threat against computer systems. The prevalence of techniques like return-oriented programming (ROP) in attacking real-world systems has prompted major processor manufacturers to design hardware-based countermeasures against specific classes of run-time attacks. An example is the recently added support for pointer authentication (PA) in the ARMv8-A processor architecture, commonly used in devices like smartphones. PA is a low-cost technique to authenticate pointers so as to resist memory vulnerabilities. It has been shown to enable practical protection against memory vulnerabilities that corrupt return addresses or function pointers. However, so far, PA has received very little attention as a general purpose protection mechanism to harden software against various classes of memory attacks. In this paper, we use PA to build novel defenses against various classes of run-time attacks, including the first PA-based mechanism for data pointer integrity. We present PARTS, an instrumentation framework that integrates our PA-based defenses into the LLVM compiler and the GNU/Linux operating system and show, via systematic evaluation, that PARTS provides better protection than current solutions at a reasonable performance overhead.},
author = {Liljestrand, Hans and Nyman, Thomas and Wang, Kui and Perez, Carlos Chinea and Ekberg, Jan Erik and Asokan, N.},
file = {:F\:/D2/sec19-liljestrand_0.pdf:pdf},
isbn = {9781939133069},
journal = {arXiv},
title = {{PAC it up: Towards Pointer Integrity using ARM Pointer Authentication}},
year = {2018}
}
@article{Mishra2018,
abstract = {Code reuse attacks have been a threat to software security since the introduction of non-executable memory protections. Despite signiicant advances in various types of additional defenses, such as control low integrity (CFI) and leakage-resilient code random-ization, recent code reuse attacks have demonstrated that these defenses are often not enough to prevent successful exploitation. Sophisticated exploits can reuse code comprising larger code fragments that conform to the enforced CFI policy and which are not aaected by randomization. As a step towards improving our defenses against code reuse attacks , in this paper we present Shredder, a defense-in-depth exploit mitigation tool for the protection of closed-source applications. In a preprocessing phase, Shredder statically analyzes a given application to pinpoint the call sites of potentially useful (to attackers) system API functions, and uses backwards data aow analysis to derive their expected argument values and generate whitelisting policies in a best-eeort way. At runtime, using library interposi-tion, Shredder exposes to the protected application only specialized versions of these critical API functions, and blocks any invocation that violates the enforced policy. We have experimentally evaluated our prototype implementation for Windows programs using a large set of 251 shellcode and 30 code reuse samples, and show that it improves signiicantly upon code stripping, a state-of-the-art code surface reduction technique, by blocking a larger number of malicious payloads with negligible runtime overhead.},
author = {Mishra, Shachee and Polychronakis, Michalis},
doi = {10.1145/3274694.3274703},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra, Polychronakis - 2018 - Shredder Breaking Ex-ploits through API Specialization.pdf:pdf},
isbn = {9781450365697},
pages = {16},
publisher = {ACM},
title = {{Shredder: Breaking Ex-ploits through API Specialization}},
url = {https://doi.org/10.1145/3274694.3274703},
year = {2018}
}
@book{Matrenichev2005,
author = {Matrenichev, V. A. and Pin'kova, L. O. and Levchenkov, O. A. and Makeev, A. F. and Yakovleva, S. Z. and Alfimova, N. A.},
booktitle = {Doklady Earth Sciences},
file = {:F\:/papers/linux.pdf:pdf},
isbn = {9780596009588},
issn = {1028334X},
number = {1},
pages = {62--66},
title = {{Linux System Programming by Robert Love}},
volume = {400},
year = {2005}
}
@article{Eckert2018,
author = {Eckert, Moritz and Barbara, Santa and Bianchi, Antonio and Kruegel, Christopher and Vigna, Giovanni and Barbara, Santa and Eckert, Moritz and Bianchi, Antonio and Wang, Ruoyu and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
file = {:F\:/D2/sec18-eckert.pdf:pdf},
isbn = {9781939133045},
title = {{H eap H opper : Bringing Bounded Model Checking to Heap Implementation Security}},
year = {2018}
}
@inproceedings{Baumann2019,
abstract = {The received wisdom suggests that Unix's unusual combination of fork() and exec() for process creation was an inspired design. In this paper, we argue that fork was a clever hack for machines and programs of the 1970s that has long outlived its usefulness and is now a liability. We catalog the ways in which fork is a terrible abstraction for the modern programmer to use, describe how it compromises OS implementations, and propose alternatives. As the designers and implementers of operating systems, we should acknowledge that fork's continued existence as a first-class OS primitive holds back systems research, and deprecate it. As educators, we should teach fork as a historical artifact, and not the first process creation mechanism students encounter.},
author = {Baumann, Andrew and Appavoo, Jonathan and Krieger, Orran and {Roscoe ETH Zurich}, Timothy},
booktitle = {Workshop on Hot Topics in Operating Systems (HotOS '19)},
doi = {10.1145/3317550},
file = {:C\:/Users/purpl/Desktop/3317550.3321435.pdf:pdf},
isbn = {9781450367271},
title = {{A fork() in the road}},
url = {https://doi.org/10.1145/3317550.},
year = {2019}
}
@article{Corral2016,
abstract = {In this paper, we present our experience designing and testing an energy saving strategy for mobile phones, implemented at operating system level, using Android OS. Our approach was to deploy kernel extensions that assess the status of the device, and enable economic profiles without user intervention. Our experiments showed that the power management kernel extension was able to extend the battery runtime by 70% to 75%, at the expense of impacting the experience of the user with an estimated performance degradation of 20% to 30%. Copyright is held by the owner/author(s).},
author = {Corral, Luis and Fronza, Ilenia and {El Ioini}, Nabil and Janes, Andrea and Plant, Peter},
doi = {10.1145/2897073.2897124},
file = {:F\:/papers/2897073.2897124.pdf:pdf},
isbn = {9781450341783},
journal = {Proceedings - International Conference on Mobile Software Engineering and Systems, MOBILESoft 2016},
keywords = {Android,Energy,Kernel,Mobile},
pages = {23--24},
title = {{Preserving energy resources using an android kernel extension: A case study}},
year = {2016}
}
@article{Xiong2013a,
abstract = {Untrusted kernel extensions remain one of the major threats to the security of commodity OS kernels. Current containment approaches still have limitations in terms of security, granularity and flexibility, primarily due to the absence of secure resource management and communication methods. This paper presents SILVER, a framework that offers transparent protection domain primitives to achieve fine-grained access control and secure communication between OS kernel and extensions. SILVER keeps track of security properties (e.g., owner principal and integrity level) of data objects in kernel space with a novel security-aware memory management scheme, which enables fine-grained access control in an effective manner. Moreover, SILVER introduces secure primitives for data communication between protection domains based on a unified integrity model. SILVER's protection domain primitives provide great flexibility by allowing developers to explicitly define security properties of individual program data, as well as control privilege delegation, data transfer and service exportation. We have implemented a prototype of SILVER in Linux. The evaluation results reveal that SILVER is effective against various kinds of kernel threats with a reasonable performance and resource overhead. {\textcopyright} 2013 Springer-Verlag.},
author = {Xiong, Xi and Liu, Peng},
doi = {10.1007/978-3-642-41284-4_6},
file = {:F\:/papers/SILVER.pdf:pdf},
isbn = {9783642412837},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {OS kernel,Protection domain,Virtualization},
pages = {103--122},
title = {{SILVER: Fine-grained and transparent protection domain primitives in commodity OS kernel}},
volume = {8145 LNCS},
year = {2013}
}
@techreport{UmitAkgun2020,
abstract = {Despite the ever-changing software and hardware profiles of modern computing systems, many operating systems (OS) components adhere to designs developed decades ago. Considering the variety of dynamic workloads that modern operating systems are expected to manage, it is quite beneficial to develop adaptive systems that learn from data patterns and OS events. However, developing such adaptive systems in kernel space involves the bottom-up implementation of math and machine learning (ML) primitives that are readily available in user space via widely-used ML libraries. However, user-level ML engines are often too costly (in terms of CPU and memory footprint) to be used inside a tightly controlled, resource constrained OS. To this end, we started developing KMLib, a lightweight yet efficient ML engine targeting kernel space components. We detail our proposed design in this paper, demonstrated through a first prototype targeting the OS I/O scheduler. Our prototype's memory footprint is 804KB for the kernel module and 96KB for the library; experiments show we can reduce I/O latency by 8% on our benchmark workload and testbed, which is significant for typically slow I/O devices.},
author = {{Umit Akgun}, Ibrahim and {Selman Aydin}, Ali and Zadok, Erez},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Umit Akgun, Selman Aydin, Zadok - 2020 - KMLIB TOWARDS MACHINE LEARNING FOR OPERATING SYSTEMS.pdf:pdf},
title = {{KMLIB: TOWARDS MACHINE LEARNING FOR OPERATING SYSTEMS}},
year = {2020}
}
@article{Khandaker2019,
abstract = {CFI is an effective, generic defense against control-flow hijacking attacks, especially for C/C++ programs. However, most previous CFI systems have poor security as demonstrated by their large equivalence class (EC) sizes. An EC is a set of targets that are indistinguishable from each other in the CFI policy; i.e., an attacker can “bend” the control flow within an EC without being detected. As such, the large ECs denote the weakest link in a CFI system and should be broken down in order to improve security. An approach to improve the security of CFI is to use contextual information, such as the last branches taken, to refine the CFI policy, the so-called context-sensitive CFI. However, contexts based on the recent execution history are often inadequate in breaking down large ECs due to the limited number of incoming execution paths to an indirect control transfer instruction (ICT).1 In this paper, we propose a new context for CFI, origin sensitivity, that can effectively break down large ECs and reduce the average and largest EC size. Origin-sensitive CFI (OS-CFI) takes the origin of the code pointer called by an ICT as the context and constrains the targets of the ICT with this context. It supports both C-style indirect calls and C++ virtual calls. Additionally, we leverage common hardware features in the commodity Intel processors (MPX and TSX) to improve both security and performance of OS-CFI. Our evaluation shows that OS-CFI can substantially reduce the largest and average EC sizes (by 98% in some cases) and has strong performance - 7.6% overhead on average for all C/C++ benchmarks of SPEC CPU2006 and NGINX.},
author = {Khandaker, Mustakimur Rahman and Liu, Wenqing and Naser, Abu and Wang, Zhi and Yang, Jie},
file = {:F\:/D2/sec19-khandaker.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {195--211},
title = {{Origin-sensitive control flow integrity}},
year = {2019}
}
@article{McCune2008,
abstract = {We present Flicker, an infrastructure for executing security-sensitive code in complete isolation while trusting as few as 250 lines of additional code. Flicker can also provide meaningful, fine-grained attestation of the code executed (as well as its inputs and outputs) to a remote party. Flicker guarantees these properties even if the BIOS, OS and DMA-enabled devices are all malicious. Flicker leverages new commodity processors from AMD and Intel and does not require a new OS or VMM. We demonstrate a full implementation of Flicker on an AMD platform and describe our development environment for simplifying the construction of Flicker-enabled code. Copyright 2008 ACM.},
author = {McCune, Jonathan M. and Parno, Bryan J. and Perrig, Adrian and Reiter, Michael K. and Isozaki, Hiroshi},
doi = {10.1145/1357010.1352625},
file = {:F\:/D2/1352592.1352625.pdf:pdf},
isbn = {9781605580135},
issn = {01635980},
journal = {Operating Systems Review (ACM)},
keywords = {Late launch,Secure execution,Trusted computing},
number = {4},
pages = {315--328},
title = {{Flicker: An execution infrastructure for TCB minimization}},
volume = {42},
year = {2008}
}
@article{Shalev2017,
abstract = {System administrators have unlimited access to system resources. As the Snowden case highlighted, these permissions can be exploited to steal valuable personal, classified, or commercial data. This problem is exacerbated when a third party administers the system. For example, a bank outsourcing its IT would not want to allow administrators access to the actual data. We propose WatchIT: a strategy that constrains IT personnel's view of the system and monitors their actions. To this end, we introduce the abstraction of perforated containers – while regular Linux containers are too restrictive to be used by system administrators, by “punching holes” in them, we strike a balance between information security and required administrative needs. Following the principle of least privilege, our system predicts which system resources should be accessible for handling each IT issue, creates a perforated container with the corresponding isolation, and deploys it as needed for fixing the problem. Under this approach, the system administrator retains superuser privileges, however only within the perforated container limits. We further provide means for the administrator to bypass the isolation, but such operations are monitored and logged for later analysis and anomaly detection. We provide a proof-of-concept implementation of our strategy, which includes software for deploying perforated containers, monitoring mechanisms, and changes to the Linux kernel. Finally, we present a case study conducted on the IT database of IBM Research in Israel, showing that our approach is feasible.},
author = {Shalev, Noam and Keidar, Idit and Weinsberg, Yaron and Moatti, Yosef and Ben-Yehuda, Elad},
doi = {10.1145/3132747.3132752},
file = {:F\:/D2/3132747.3132752.pdf:pdf},
isbn = {9781450350853},
journal = {SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles},
keywords = {Perforated Container,Privileged Insider Threat},
pages = {515--530},
title = {{WatchIT: Who Watches Your IT Guy?}},
year = {2017}
}
@article{Li,
abstract = {Commodity hypervisors are widely deployed to support virtual machines (VMs) on multiprocessor hardware. Their growing complexity poses a security risk. To enable formal verification over such a large codebase, we introduce microverification, a new approach that decomposes a commodity hypervisor into a small core and a set of untrusted services so that we can prove security properties of the entire hypervisor by verifying the core alone. To verify the multi-processor hypervisor core, we introduce security-preserving layers to modularize the proof without hiding information leakage so we can prove each layer of the implementation refines its specification, and the top layer specification is refined by all layers of the core implementation. To verify commodity hypervisor features that require dynamically changing information flow, we introduce data oracles to mask intentional information flow. We can then prove noninterference at the top layer specification and guarantee the resulting security properties hold for the entire hypervisor implementation. Using microverifica-tion, we retrofitted the Linux KVM hypervisor with only modest modifications to its codebase. Using Coq, we proved that the hypervisor protects the confidentiality and integrity of VM data, while retaining KVM's functionality and performance. Our work is the first machine-checked security proof for a commodity multiprocessor hypervisor.},
author = {Li, Shih-wei and Li, Xupeng and Gu, Ronghui and Nieh, Jason and Hui, John Zhuang},
file = {:F\:/D2/oakland21-li.pdf:pdf},
title = {{A Secure and Formally Verified Linux KVM Hypervisor}}
}
@article{Bellard2005,
abstract = {We present the internals of QEMU, a fast machine emulator using an original portable dynamic translator. It emulates several CPUs (x86, PowerPC, ARM and Sparc) on several hosts (x86, PowerPC, ARM, Sparc, Alpha and MIPS). QEMU supports full system emulation in which a complete and unmodified operating system is run in a virtual machine and Linux user mode emulation where a Linux process compiled for one target CPU can be run on another CPU.},
author = {Bellard, Fabrice},
file = {:F\:/D2/bellard.pdf:pdf},
journal = {USENIX 2005 Annual Technical Conference},
pages = {41--46},
title = {{QEMU, a fast and portable dynamic translator}},
year = {2005}
}
@article{Wang2012,
abstract = {Integer errors have emerged as an important threat to systems security, because they allow exploits such as buffer overflow and privilege escalation. This paper presents KINT, a tool that uses scalable static analysis to detect integer errors in C programs. KINT generates constraints from source code and user annotations, and feeds them into a constraint solver for deciding whether an integer error can occur. KINT introduces a number of techniques to reduce the number of false error reports. KINT identified more than 100 integer errors in the Linux kernel, the lighttpd web server, and OpenSSH, which were confirmed and fixed by the developers. Based on the experience with KINT, the paper further proposes a new integer family with NaN semantics to help developers avoid integer errors in C programs.},
author = {Wang, Xi and Chen, Haogang and Jia, Zhihao and Zeldovich, Nickolai and {Frans Kaashoek}, M.},
file = {:F\:/D2/osdi12-final-88.pdf:pdf},
isbn = {9781931971966},
journal = {Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2012},
pages = {163--177},
title = {{Improving integer security for systems with KINT}},
year = {2012}
}
@article{Russell2008,
abstract = {The Linux Kernel currently supports at least 8 distinct virtualization systems: Xen, KVM, VMware's VMI, IBM's System p, IBM's System z, User Mode Linux, lguest and IBM's legacy iSeries. It seems likely that more such systems will appear, and until recently each of these had its own block, network, console and other drivers with varying features and optimizations. The attempt to address this is virtio: a series of efficient, well-maintained Linux drivers which can be adapted for various different hypervisor implementations using a shim layer. This includes a simple extensible feature mechanism for each driver. We also provide an obvious ring buffer transport implementation called vring, which is currently used by KVM and lguest. This has the subtle effect of providing a path of least resistance for any new hypervisors: supporting this efficient transport mechanism will immediately reduce the amount of work which needs to be done. Finally, we provide an implementation which presents the vring transport and device configuration as a PCI device: this means guest operating systems merely need a new PCI driver, and hypervisors need only add vring support to the virtual devices they implement (currently only KVM does this). This paper will describe the virtio API layer as implemented in Linux, then the vring implementation, and finally its embodiment in a PCI device for simple adoption on otherwise fully-virtualized guests. We'll wrap up with some of the preliminary work to integrate this I/O mechanism deeper into the Linux host kernel.},
author = {Russell, Rusty},
doi = {10.1145/1400097.1400108},
file = {:F\:/D2/1400097.1400108.pdf:pdf},
issn = {01635980},
journal = {Operating Systems Review (ACM)},
keywords = {I/O,KVM,Lguest,Linux,Ring buffer,Virtio,Virtio-pci,Virtualization,Vring},
number = {5},
pages = {95--103},
title = {{Virtio: Towards a de-facto standard for virtual I/O devices}},
volume = {42},
year = {2008}
}
@article{Xu2015,
abstract = {Since vulnerabilities in Linux kernel are on the increase, attackers have turned their interests into related exploitation techniques. However, compared with numerous researches on exploiting use-after-free vulnerabilities in the user applications, few efforts studied how to exploit use-after-free vulnerabilities in Linux kernel due to the difficulties that mainly come from the uncertainty of the kernel memory lay-out. Without specific information leakage, attackers could only conduct a blind memory overwriting strategy trying to corrupt the critical part of the kernel, for which the success rate is negligible. In this work, we present a novel memory collision strategy to exploit the use-after-free vulnerabilities in Linux kernel reliably. The insight of our exploit strategy is that a probabilistic memory collision can be constructed according to the widely deployed kernel memory reuse mechanisms, which significantly increases the success rate of the attack. Based on this insight, we present two practical memory collision attacks: An object-based attack that leverages the memory recycling mechanism of the kernel allocator to achieve freed vulnerable object covering, and a physmap based attack that takes advantage of the overlap between the physmap and the SLAB caches to achieve a more flexible memory manipulation. Our proposed attacks are universal for various Linux kernels of different architectures and could successfully exploit systems with use-after-free vulnerabilities in kernel. Particularly, we achieve privilege escalation on various popular Android devices (kernel version >=4.3) including those with 64-bit processors by exploiting the CVE-2015-3636 use-after-free vulnerability in Linux kernel. To our knowledge, this is the first generic kernel exploit for the latest version of Android. Finally, to defend this kind of memory collision, we propose two corresponding mitigation schemes.},
author = {Xu, Wen and Li, Juanru and Shu, Junliang and Yang, Wenbo and Xie, Tianyi and Zhang, Yuanyuan and Gu, Dawu},
doi = {10.1145/2810103.2813637},
file = {:F\:/D2/2810103.2813637.pdf:pdf},
isbn = {9781450338325},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Linux kernel exploit,Memory collision,User-after-free vulnerability},
pages = {414--425},
title = {{From collision to exploitation: Unleashing use-after-free vulnerabilities in Linux kernel}},
volume = {2015-Octob},
year = {2015}
}
@article{Gruss2018,
abstract = {Use-after-free is a type of vulnerability commonly present in software written in memory-unsafe languages like C or C++, where a program frees a memory buffer too early. By placing counterfeit structures at the freed memory location, an attacker can leak information or gain execution control upon subsequent access. In this paper, we show that the concept of use-after-free can be generalized to any environment and situation where resources can be silently exchanged. As an instance of our generalization we demonstrate Use-After-FreeMail attacks. Use-After-FreeMail attacks gather email addresses from publicly available database leaks. The fully automated quantitative analysis brought to light that 33.5% of all free-mail addresses we tested are not valid anymore. In two user studies with 100 and 31 participants we found that 11-19% of users are affected by our attack. In qualitative case studies we investigated what information can be gained in Use-After-FreeMail attacks, e.g., payment information, and how far currently used accounts can be compromised (identity theft). Finally, drawing the connection between mitigations against traditional use-after-free scenarios and the Use-After-FreeMail scenario, we provide a concise list of recommendations to free-mail providers and users as a protection against use-after-free attacks.},
author = {Gruss, Daniel and Schwarz, Michael and W{\"{u}}bbeling, Matthias and Guggi, Simon and Malderle, Timo and More, Stefan and Lipp, Moritz},
doi = {10.1145/3196494.3196514},
file = {:F\:/D2/3196494.3196514.pdf:pdf},
isbn = {9781450355766},
journal = {ASIACCS 2018 - Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security},
pages = {297--311},
title = {{Use-after-FreeMail: Generalizing the use-after-free problem and applying it to email services}},
year = {2018}
}
@article{Palix2012,
abstract = {In 2001, Chou et al. published a study of faults found by applying a static analyzer to Linux versions 1.0 through 2.4.1. A major result of their work was that the drivers directory contained up to 7 times more of certain kinds of faults than other directories. This result inspired a number of development and research efforts on improving the reliability of driver code. Today Linux is used in a much wider range of environments, provides a much wider range of services, and has adopted a new development and release model. What has been the impact of these changes on code quality? Are drivers still a major problem? To answer these questions, we have transported the experiments of Chou et al. to Linux versions 2.6.0 to 2.6.33, released between late 2003 and early 2010. We find that Linux has more than doubled in size during this period, but that the number of faults per line of code has been decreasing. And, even though drivers still accounts for a large part of the kernel code and contains the most faults, its fault rate is now below that of other directories, such as arch (HAL) and fs (file systems). These results can guide further development and research efforts. To enable others to continually update these results as Linux evolves, we define our experimental protocol and make our checkers and results available in a public archive. Copyright {\textcopyright} 2011 ACM.},
author = {Palix, Nicolas and Thomas, Ga{\"{e}}l and Saha, Suman and Calv{\`{e}}s, Christophe and Lawall, Julia and Muller, Gilles},
doi = {10.1145/2248487.1950401},
file = {:F\:/papers/1961296.1950401.pdf:pdf;:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Palix et al. - 2012 - Faults in linux Ten years later.pdf:pdf},
isbn = {9781450302661},
issn = {15232867},
journal = {ACM SIGPLAN Notices},
keywords = {Fault-finding tools,Linux},
number = {4},
pages = {305--318},
title = {{Faults in linux: Ten years later}},
volume = {47},
year = {2012}
}
@article{Zhang2016,
abstract = {Hardware-assisted Isolated Execution Environments (HIEEs) have been widely adopted to build effective and efficient defensive tools for securing systems. Hardware vendors have introduced a variety of HIEEs including system management mode, Intel management engine, ARM TrustZone, and Intel software guard extensions. This SoK paper presents a comprehensive study of existing HIEEs and compares their features from the security perspective. Additionally, we explore both defensive and offensive use scenarios of HIEEs and discuss the attacks against HIEE-based systems. Overall, this paper aims to give an essential checkpoint of the state-of-the-art systems that use HIEEs for trustworthy computing.},
author = {Zhang, Fengwei and Zhang, Hongwei},
doi = {10.1145/2948618.2948621},
file = {:F\:/D2/sok-hasp16.pdf:pdf},
isbn = {9781450347693},
journal = {ACM International Conference Proceeding Series},
keywords = {Hardware,Isolated execution environments,Security},
title = {{SoK: A study of using hardware-assisted isolated execution environments for security}},
volume = {18-June-20},
year = {2016}
}
@article{Levy2017,
abstract = {Decades of research has attempted to add safety mechanisms to operating system kernels, but this effort has failed in most practical systems. In particular, solutions that sacrifice performance have been generally avoided. However, isolation techniques in modern languages can provide safety while avoiding performance issues. Moreover, utilizing a type-safe language with no garbage collector or other runtime services avoids what would otherwise be some of the largest sections of trusted code base. We report on our experiences in writing a resource efficient embedded kernel in Rust, finding that only a small set of unsafe abstractions are necessary in order to form common kernel building blocks. Further, we argue that Rust's choice to avoid runtime memory management by using a linear type system will enable the next generation of safe operating systems.},
author = {Levy, Amit and Campbell, Bradford and Ghena, Branden and Pannuto, Pat and Dutta, Prabal and Levis, Philip},
doi = {10.1145/3124680.3124717},
file = {:F\:/D2/3124680.3124717.pdf:pdf},
isbn = {9781450351973},
journal = {Proceedings of the 8th Asia-Pacific Workshop on Systems, APSys 2017},
title = {{The case for writing a kernel in rust}},
year = {2017}
}
@article{Liljestrand2019,
abstract = {A popular run-time attack technique is to compromise the controlflow integrity of a program by modifying function return addresses on the stack. So far, shadow stacks have proven to be essential for comprehensively preventing return address manipulation. Shadow stacks record return addresses in integrity-protected memory, secured with hardware-assistance or software access control. Software shadow stacks incur high overheads or trade off security for efficiency. Hardware-assisted shadowstacks are efficient and secure, but require the deployment of special-purpose hardware. We present authenticated call stack (ACS), an approach that uses chained message authentication codes (MACs) to achieve comparable security without requiring additional hardware support. We present PACStack, a realization of ACS on the ARMv8.3-A architecture, using its general purpose hardware mechanism for pointer authentication (PA). Via a rigorous security analysis, we show that PACStack achieves security comparable to hardware-assisted shadow stacks without requiring dedicated hardware. We demonstrate that PACStack's performance overhead is negligible (<1%).},
archivePrefix = {arXiv},
arxivId = {1905.10242},
author = {Liljestrand, Hans and Nyman, Thomas and Gunn, Lachlan J. and Ekberg, Jan Erik and Asokan, N.},
eprint = {1905.10242},
file = {:F\:/D2/sec21summer_liljestrand.pdf:pdf},
journal = {arXiv},
title = {{PACStack: An authenticated call stack}},
year = {2019}
}
@article{Gu2013,
abstract = {Kernel drivers are usually provided in the form of loadable kernel extensions, which can be loaded/unloaded dynamically at runtime and execute with the same privilege as the core operating system kernel. The unrestricted security access from the drivers to the kernel is nevertheless a double-edged sword that makes them susceptible targets of trojan attacks. Given a benign driver, it is now easy to implant malicious logic with existing hacking tools. Once implanted, such malicious logic is difficult to detect. In this paper we propose DRIP, a framework for detecting and eliminating malicious logic embedded in a kernel driver through iteratively eliminating unnecessary kernel API invocations from the driver. When provided with the binary of a trojaned driver, DRIP generates a purified driver with benign functionalities preserved and malicious ones eliminated. Our evaluation shows that DRIP successfully eliminates malicious effects of trojaned drivers in the system, with the purified drivers maintaining or even improving their performance over the trojaned drivers. {\textcopyright} 2013 IEEE.},
author = {Gu, Zhongshu and Sumner, William N. and Deng, Zhui and Zhang, Xiangyu and Xu, Dongyan},
doi = {10.1109/DSN.2013.6575342},
file = {:F\:/D2/06575342.pdf:pdf},
isbn = {9781467364713},
journal = {Proceedings of the International Conference on Dependable Systems and Networks},
keywords = {Kernel Drivers,System Security,Trojan Detection},
publisher = {IEEE},
title = {{DRIP: A framework for purifying trojaned kernel drivers}},
year = {2013}
}
@article{Bastys2018,
abstract = {- Security and privacy -> Web application security; Domain-specific security and privacy architectures; },
author = {Bastys, Iulia and Balliu, Musard and Sabelfeld, Andrei},
doi = {10.1145/3243734.3243841},
file = {:F\:/papers/Bastys, Balliu, Sabelfeld - 2018 - If This Then What.pdf:pdf},
isbn = {9781450356930},
keywords = {2018,IoT apps,access control,acm reference format,and andrei sabelfeld,if this then what,information flow,iot apps,iulia bastys,musard balliu},
pages = {1102--1119},
title = {{If This Then What?}},
year = {2018}
}
@article{Abouzahra1985,
abstract = {Based on Kummer's 2-variable functional equations for the second through fifth orders of the polylogarithm function, certain linear combinations, with rational coefficients, of polylogarithms of powers of an algebraic base were discovered to possess significant mathematical properties. These combinations are designated "ladders," and it is here proved that the ladder structure is invariant with order when the order is decreased from its permissible maximum value for the corresponding ladder. In view of Wechsung's demonstration that the functions of sixth and higher orders possess no functional equations of Kummer's type, this analytical proof is currently limited to a maximum of the fifth order. The invariance property does not necessarily persist in reverse-increasing the order need not produce a valid ladder with rational coefficients. Nevertheless, quite a number of low-order ladders do lend themselves to such extension, with the needed additional rational coefficients being determined by numerical computation. With sufficient accuracy there is never any doubt as to the rational character of the numbers ensuing from this process. This method of extrapolation to higher orders has led to many quite new results; although at this time completely lacking any analytical proof. Even more astonishing, in view of Wechsung's theorem mentioned above, is the fact that in some cases the ladders can be validly extended beyond the fifth order. This has led to the first-ever results for polylogarithms of order six through nine. A meticulous attention to the finer points in the formulas was necessary to achieve these results; and a number of conjectural rules for extrapolating ladders in this way has emerged from this study. Although it is known that the polylogarithm does not possess any relations of a polynomial character with rational coefficients between the different orders, such relations do exist for some of the ladder structures. A number of examples are given, together with a representative sample of ladders of both the analytical and numerically-verified types. The significance of these new and striking results is not clear, but they strongly suggest that polylogarithmic functional equations, of a more far-reaching character than those currently known, await discovery; probably up to at least the ninth order. {\textcopyright} 1985.},
author = {{Dawson R. Engler, M. Frans Kaashoek}, James O'Toole Jr.},
doi = {10.1016/0022-314X(85)90052-6},
file = {:F\:/D2/224057.224076.pdf:pdf},
issn = {0022314X},
journal = {ACM SIGOPS Operating Systems Review},
number = {2},
pages = {214--244},
title = {{ExoKernel:An Operating System Architecture for Application-Level Resource Management}},
volume = {21},
year = {1995}
}
@article{Lu2018,
abstract = {With the wide deployment of security mechanisms such as Address Space Layout Randomization (ASLR), memory disclosures have become a prerequisite for critical memory-corruption attacks (e.g., code-reuse attack)---adversaries are forced to exploit memory disclosures to circumvent ASLR as the first step. As a result, the security threats of memory disclosures are now significantly aggravated---they break not only data confidentiality but also the effectiveness of security mechanisms. In this paper, we propose a general detection methodology and develop a system to stop memory disclosures. We observe that memory disclosures are not root causes but rather consequences of a variety of hard-to-detect program errors such as memory corruption and uninitialized read. We thus propose a replicated execution-based methodology to generally detect memory disclosures, regardless of their causes. We realize this methodology with Buddy : By seamlessly maintaining two identical running instances of a target program and diversifying only its target data, Buddy can accurately detects memory disclosures of the data, as doing so will result in the two instances outputting different values. Extensive evaluation results show that Buddy is reliable and efficient while stopping real memory disclosures such as the Heartbleed leak.},
author = {Lu, Kangjie and Xu, Meng and Song, Chengyu and Kim, Taesoo and Lee, Wenke},
doi = {10.1109/TDSC.2018.2878234},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2018 - Stopping Memory Disclosures via Diversification and Replicated Execution.pdf:pdf},
issn = {19410018},
journal = {IEEE Transactions on Dependable and Secure Computing},
keywords = {Benchmark testing,Kernel,Layout,Memory disclosure,Memory management,N-version system,Security,Synchronization,Web servers,code-reuse attack,diversification,replicated execution},
number = {c},
publisher = {IEEE},
title = {{Stopping Memory Disclosures via Diversification and Replicated Execution}},
volume = {5971},
year = {2018}
}
@article{Shu2016,
abstract = {Security isolation is a foundation of computing systems that enables resilience to different forms of attacks. This article seeks to understand existing security isolation techniques by systematically classifying different approaches and analyzing their properties. We provide a hierarchical classification structure for grouping different security isolation techniques. At the top level, we consider two principal aspects: mechanism and policy. Each aspect is broken down into salient dimensions that describe key properties. We break the mechanism into two dimensions, enforcement location and isolation granularity, and break the policy aspect down into three dimensions: policy generation, policy configurability, and policy lifetime. We apply our classification to a set of representative articles that cover a breadth of security isolation techniques and discuss tradeoffs among different design choices and limitations of existing approaches.},
author = {Shu, Rui and Wang, Peipei and Gorski, Sigmund A. and Andow, Benjamin and Nadkarni, Adwait and Deshotels, Luke and Gionta, Jason and Enck, William and Gu, Xiaohui},
doi = {10.1145/2988545},
file = {:F\:/D2/2988545.pdf:pdf},
issn = {15577341},
journal = {ACM Computing Surveys},
keywords = {Access control,Resilient architectures,Security isolation},
number = {3},
title = {{A study of security isolation techniques}},
volume = {49},
year = {2016}
}
@article{Lu2019a,
abstract = {System software commonly uses indirect calls to realize dynamic program behaviors. However, indirect-calls also bring challenges to constructing a precise control-flow graph that is a standard prerequisite for many static program-analysis and system-hardening techniques. Unfortunately, identifying indirect-call targets is a hard problem. In particular, modern compilers do not recognize indirect-call targets by default. Existing approaches identify indirect-call targets based on type analysis that matches the types of function pointers and the ones of address-taken functions. Such approaches, however, suffer from a high false-positive rate as many irrelevant functions may share the same types. In this paper, we propose a new approach, namely Multi-Layer Type Analysis (MLTA), to effectively refine indirect-call targets for C/C++ programs. MLTA relies on an observation that function pointers are commonly stored into objects whose types have a multilayer type hierarchy; before indirect calls, function pointers will be loaded from objects with the same type hierarchy “layer by layer”. By matching the multi-layer types of function pointers and functions, MLTA can dramatically refine indirect-call targets. MLTA is effective because multi-layer types are more restrictive than single-layer types. It does not introduce false negatives by conservatively tracking targets propagation between multi-layer types, and the layered design allows MLTA to safely fall back whenever the analysis for a layer becomes infeasible. We have implemented MLTA in a system, namely TypeDive, based on LLVM and extensively evaluated it with the Linux kernel, the FreeBSD kernel, and the Firefox browser. Evaluation results show that TypeDive can eliminate 86% to 98% more indirect-call targets than existing approaches do, without introducing new false negatives. We also demonstrate that TypeDive not only improves the scalability of static analysis but also benefits semantic-bug detection. With TypeDive, we have found 35 new deep semantic bugs in the Linux kernel.},
author = {Lu, Kangjie and Hu, Hong},
doi = {10.1145/3319535.3354244},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Hu - 2019 - Where does it go Refining indirect-call targets with multi-layer type analysis.pdf:pdf},
isbn = {9781450367479},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {CFI,Function pointers,Indirect-call targets,Layered type analysis},
pages = {1867--1881},
title = {{Where does it go? Refining indirect-call targets with multi-layer type analysis}},
year = {2019}
}
@article{Belleville2019,
abstract = {Modern operating system kernels deploy Kernel Address Space Layout Randomization (KASLR) to mitigate control-flow hijacking attacks. KASLR randomizes the base addresses of the kernel&#x0027;s code and data segments. However, it randomizes both with a single offset and does not randomize the internal layout of either of these segments, so relative addresses remain known to adversaries. If the kernel discloses a single code or global data pointer, an adversary can therefore infer the entire layout of the kernel&#x0027;s code segment and bypass KASLR. In this paper, we present Kernel Address Leak Detector (KALD), a tool that finds direct disclosure vulnerabilities by statically analyzing the kernel source code. KALD can analyze the source code of modern operating system kernels and find previously unreported leaks. KALD compiles a list of functions that can leak information to user-space accessible locations, and it uses the results of a points-to analysis to determine whether individual invocations of such functions can disclose kernel pointers. We show that KALD successfully detects several direct disclosure vulnerabilities in the Linux kernel and that it is flexible enough to be useful in practice.},
author = {Belleville, Brian and Shen, Wenbo and Volckaert, Stijn and Azab, Ahmed M. and Franz, Michael},
doi = {10.1109/TDSC.2019.2915829},
file = {:F\:/papers/08712444.pdf:pdf},
issn = {19410018},
journal = {IEEE Transactions on Dependable and Secure Computing},
keywords = {Kernel,Layout,Linux,Memory management,Smart phones,Tools},
number = {c},
pages = {1},
publisher = {IEEE},
title = {{KALD: Detecting Direct Pointer Disclosure Vulnerabilities}},
volume = {PP},
year = {2019}
}
@article{Wright2002,
abstract = {Computer security is a chronic and growing prob- lem, even for Linux, as evidenced by the seem- ingly endless stream of software security vulnera- bilities. Security research has produced numerous access control mechanisms that help improve sys- tem security; however, there is little concensus on the best solution. Many powerful security systems have been implemented as research prototypes or highly specialized products, leaving systems opera- tors with a difficult challenge: how to utilize these advanced features, without having to throw away their existing systems? The Linux Security Modules (LSM) project ad- dresses this problem by providing the Linux kernel with a general purpose framework for access control. LSM enables loading enhanced security policies as kernel modules. By providing Linux with a stan- dard API for policy enforcement modules, the LSM project hopes to enable widespread deployment of security hardened systems. This paper presents the design and implementation of the LSM framework, a discussion of performance and security impact on the kernel, and a brief overview of existing security modules. ∗This},
author = {Wright, Chris and Cowan, Crispin and Morris, James and Smalley, Stephen and Kroah-Hartman, Greg},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wright et al. - 2002 - Linux security module framework.pdf:pdf},
journal = {Ottawa Linux Symposium},
pages = {6},
title = {{Linux security module framework}},
volume = {8032},
year = {2002}
}
@article{Koo2018,
abstract = {Despite decades of research on software diversification, only address space layout randomization has seen widespread adoption. Code randomization, an effective defense against return-oriented programming exploits, has remained an academic exercise mainly due to i) the lack of a transparent and streamlined deployment model that does not disrupt existing software distribution norms, and ii) the inherent incompatibility of program variants with error reporting, whitelisting, patching, and other operations that rely on code uniformity. In this work we present compiler-assisted code randomization (CCR), a hybrid approach that relies on compiler-rewriter cooperation to enable fast and robust fine-grained code randomization on end-user systems, while maintaining compatibility with existing software distribution models. The main concept behind CCR is to augment binaries with a minimal set of transformation-assisting metadata, which i) facilitate rapid fine-grained code transformation at installation or load time, and ii) form the basis for reversing any applied code transformation when needed, to maintain compatibility with existing mechanisms that rely on referencing the original code. We have implemented a prototype of this approach by extending the LLVM compiler toolchain, and developing a simple binary rewriter that leverages the embedded metadata to generate randomized variants using basic block reordering. The results of our experimental evaluation demonstrate the feasibility and practicality of CCR, as on average it incurs a modest file size increase of 11.46% and a negligible runtime overhead of 0.28%, while it is compatible with link-time optimization and control flow integrity.},
author = {Koo, Hyungjoon and Chen, Yaohui and Lu, Long and Kemerlis, Vasileios P. and Polychronakis, Michalis},
doi = {10.1109/SP.2018.00029},
file = {:F\:/D2/Compiler-Assisted_Code_Randomization.pdf:pdf},
isbn = {9781538643525},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {code randomization,compiler level protection,return oriented programming},
pages = {461--477},
publisher = {IEEE},
title = {{Compiler-Assisted Code Randomization}},
volume = {2018-May},
year = {2018}
}
@article{Klein2009,
author = {Klein, Gerwin and Elphinstone, Kevin and Heiser, Gernot and Engelhardt, Kai},
file = {:F\:/D2/klein-sosp09.pdf:pdf},
issn = {09556419},
journal = {SOSP},
number = {1},
pages = {76--78},
title = {{seL4: Formal Verification of an OS Kernel}},
volume = {18},
year = {2009}
}
@article{Wang2014,
abstract = {Modern operating systems run multiple interpreters in the kernel, which enable user-space applications to add new functionality or specialize system policies. The correct-ness of such interpreters is critical to the overall system security: bugs in interpreters could allow adversaries to compromise user-space applications and even the kernel. Jitk is a new infrastructure for building in-kernel in-terpreters that guarantee functional correctness as they compile user-space policies down to native instructions for execution in the kernel. To demonstrate Jitk, we im-plement two interpreters in the Linux kernel, BPF and INET-DIAG, which are used for network and system call filtering and socket monitoring, respectively. To help ap-plication developers write correct filters, we introduce a high-level rule language, along with a proof that Jitk correctly translates high-level rules all the way to native machine code, and demonstrate that this language can be integrated into OpenSSH with tens of lines of code. We built a prototype of Jitk on top of the CompCert verified compiler and integrated it into the Linux kernel. Ex-perimental results show that Jitk is practical, fast, and trustworthy.},
author = {Wang, Xi and Lazar, David and Zeldovich, Nickolai and Chlipala, Adam and Tatlock, Zachary},
file = {:F\:/papers/osdi14-paper-wang_xi.pdf:pdf},
isbn = {9781931971164},
journal = {USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
pages = {33--48},
title = {{Jitk : A Trustworthy In-Kernel Interpreter Infrastructure}},
year = {2014}
}
@article{Vahldiek-Oberwagner2019,
abstract = {Isolating sensitive state and data can increase the security and robustness of many applications. Examples include protecting cryptographic keys against exploits like OpenSSL's Heartbleed bug or protecting a language runtime from native libraries written in unsafe languages. When runtime references across isolation boundaries occur relatively infrequently, then conventional page-based hardware isolation can be used, because the cost of kernel- or hypervisor-mediated domain switching is tolerable. However, some applications, such as the isolation of cryptographic session keys in network-facing services, require very frequent domain switching. In such applications, the overhead of kernel- or hypervisor-mediated domain switching is prohibitive. In this paper, we present ERIM, a novel technique that provides hardware-enforced isolation with low overhead on x86 CPUs, even at high switching rates (ERIM's measured overhead is less than 1% for 100,000 switches per second). The key idea is to combine protection keys (MPKs), a feature recently added to x86 that allows protection domain switches in userspace, with binary inspection to prevent circumvention. We show that ERIM can be applied with little effort to new and existing applications, doesn't require compiler changes, can run on a stock Linux kernel, and has low runtime overhead even at high domain switching rates.},
archivePrefix = {arXiv},
arxivId = {1801.06822},
author = {Vahldiek-Oberwagner, Anjo and Sammler, Michael and Elnikety, Eslam and Druschel, Peter and Duarte, Nuno O. and Garg, Deepak},
eprint = {1801.06822},
file = {:F\:/D2/sec19-vahldiek-oberwagner_0.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1221--1238},
title = {{ERIM: Secure, efficient in-process isolation with protection keys (MPK)}},
year = {2019}
}
@book{Delshadtehrani,
abstract = {There has been a resurgent trend in the industry to enforce a variety of security policies in hardware. The current trend for developing dedicated hardware security extensions is an imperfect , lengthy, and costly process. In contrast to this trend, a flexible hardware monitor can efficiently enforce and enhance a variety of security policies as security threats evolve. Existing hardware monitors typically suffer from one (or more) of the following drawbacks: a restricted set of monitoring actions, considerable performance and power overheads, or an invasive design. In this paper, we propose a minimally-invasive and efficient implementation of a Programmable Hardware Monitor (PHMon) with expressive monitoring rules and flexible fine-grained actions. PHMon can enforce a variety of security policies and can also assist with detecting software bugs and security vulnerabilities. Our prototype of PHMon on an FPGA includes the hardware monitor and its interface with a RISC-V Rocket processor as well as a complete Linux software stack. We demonstrate the versatility of PHMon and its ease of adoption through four different use cases: a shadow stack, a hardware-accelerated fuzzing engine, an information leak prevention mechanism, and a hardware-accelerated debugger. Our prototype implementation of PHMon incurs 0.9% performance overhead on average, while the hardware-accelerated fuzzing engine improves fuzzing performance on average by 16× over the state-of-the art software-based implementation. Our ASIC implementation of PHMon only incurs a 5% power overhead and a 13.5% area overhead.},
author = {Delshadtehrani, Leila and Canakci, Sadullah and Zhou, Boyou and Eldridge, Schuyler and Joshi, Ajay and Egele, Manuel},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Delshadtehrani et al. - Unknown - PHMon A Programmable Hardware Monitor and Its Security Use Cases.pdf:pdf},
isbn = {9781939133175},
title = {{PHMon: A Programmable Hardware Monitor and Its Security Use Cases}},
url = {https://www.usenix.org/conference/usenixsecurity20/presentation/delshadtehrani}
}
@inproceedings{Jang2014,
abstract = {Hardware-based external monitors have been proposed as a trustworthy method for protecting the kernel integrity. We introduce the design and implementation of Address Translation Redirection Attack (ATRA) that enables complete evasion of the hardware-based external monitor that anchors its trust on a separate processor. ATRA circumvents the external monitor by redirecting the memory access to critical kernel objects into a non-monitored region. Despite the seriousness of the ATRA issue, the address translation integrity has been assumed in many hardware-based external monitors and the possibility of its exploitation has been suggested yet many considered hypothetical. We explore the intricate details of ATRA, explain major challenges in realizing ATRA in practice, and address them with two types of ATRA called Memory-bound ATRA and Register-bound ATRA. Our evaluations with benchmarks show that ATRA does not introduce a noticeable performance degradation to the host system, proving practical applicability of the at-tack to alert the researchers to seriously address ATRA in designing future external monitors. Copyright is held by the author/owner(s).},
author = {Jang, Daehee and Lee, Hojoon and Kim, Minsu and Kim, Daehyeok and Kim, Daegyeong and Kang, Brent Byunghoon},
booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
doi = {10.1145/2660267.2660303},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jang et al. - Unknown - ATRA Address Translation Redirection Attack gainst Hardware-based External Monitors.pdf:pdf},
isbn = {9781450329576},
issn = {15437221},
pages = {167--178},
title = {{ATRA: Address translation redirection attack gainst hardware-based external monitors}},
url = {http://dx.doi.org/10.1145/2660267.2660303},
year = {2014}
}
@article{CCF2019,
author = {CCF},
file = {:C\:/Users/purpl/Desktop/中国计算机学会推荐国际学术会议和期刊目录-2019.pdf:pdf},
title = {中国计算机学会推荐国际学术会议和期刊目录 （2019 年） 中国计算机学会},
year = {2019}
}
@article{Ben-Ami2008,
abstract = {The I/O interfaces between a host platform and a guest virtual machine take one of three forms: either the hypervisor provides the guest with emulation of hardware devices, or the hypervisor provides virtual I/O drivers, or the hypervisor assigns a selected sub- set of the host's real I/O devices directly to the guest. Each method has advantages and disadvantages, but letting VMs access devices directly has a number of particularly interesting benefits, such as not requir- ing any guest VM changes and in theory providing near-native performance. In an effort to quantify the benefits of direct device access, we have implemented direct device assign- ment for untrusted, fully-virtualized virtual machines in the Linux/KVM environment using Intel's VT-d IOMMU. Our implementation required no guest OS changes and—unlike alternative I/O virtualization approaches—provided near native I/O performance. In particular, a quantitative comparison of network performance on a 1GbE network shows that with large-enough messages direct device access through- put is statistically indistinguishable from native, al- beit},
author = {Ben-Ami, Yassour and Muli, Ben-Yehuda and Orit, Wasserman},
file = {:F\:/D2/H-0263.pdf:pdf},
journal = {Tech. Rep. H-0263, IBM Research},
keywords = {Xen virtualization system,data privacy,operating systems,operating systems (computers),resource utilization,software portability,software reliability,trusted computing base,untrusted management OS,virtual machine execution,virtual machine monitor,virtual machines,virtualization},
title = {{Direct device assignment for untrusted fully-virtualized virtual machines}},
volume = {0263},
year = {2008}
}
@article{Hsiao2020,
abstract = {With the advance of hardware, network, and virtualization technologies, cloud computing has prevailed and become the target of security threats such as the cross virtual machine (VM) side channel attack, with which malicious users exploit vulnerabilities to gain information or access to other guest virtual machines. Among the many virtualization technologies, the hypervisor manages the shared resource pool to ensure that the guest VMs can be properly served and isolated from each other. However, while managing the shared hardware resources, due to the presence of the virtualization layer and different CPU modes (root and non-root mode), when a CPU is switched to non-root mode and is occupied by a guest machine, a hypervisor cannot intervene with a guest at runtime. Thus, the execution status of a guest is like a black box to a hypervisor, and the hypervisor cannot mediate possible malicious behavior at runtime. To rectify this, we propose a hardware-assisted VMI (virtual machine introspection) based in-guest process monitoring mechanism which supports monitoring and management applications such as process profiling. The mechanism allows hooks placed within a target process (which the security expert selects to monitor and profile) of a guest virtual machine and handles hook invocations via the hypervisor. In order to facilitate the needed monitoring and/or management operations in the guest machine, the mechanism redirects access to in-guest memory space to a controlled, self-defined memory within the hypervisor by modifying the extended page table (EPT) to minimize guest and host machine switches. The advantages of the proposed mechanism include transparency, high performance, and comprehensive semantics. To demonstrate the capability of the proposed mechanism, we develop an API profiling system (APIf) to record the API invocations of the target process. The experimental results show an average performance degradation of about 2.32%, far better than existing similar systems.},
author = {Hsiao, Shun Wen and Sun, Yeali S. and Chen, Meng Chang},
doi = {10.1109/TIFS.2020.2969514},
file = {:F\:/D2/08970339.pdf:pdf},
issn = {15566021},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {API hooking,MMU,malware,profiling,virtual machine introspection},
pages = {2402--2416},
title = {{Hardware-Assisted MMU Redirection for In-Guest Monitoring and API Profiling}},
volume = {15},
year = {2020}
}
@article{Backes2014,
abstract = {Code reuse attacks allow an adversary to impose malicious behavior on an otherwise benign program. To mitigate such attacks, a common approach is to disguise the address or content of code snippets by means of randomization or rewriting, leaving the adversary with no choice but guessing. However, disclosure attacks allow an adversary to scan a process-even remotely-and enable her to read executable memory on-the-fly, thereby allowing the just-in-time assembly of exploits on the target site. In this paper, we propose an approach that fundamentally thwarts the root cause of memory disclosure exploits by pre-venting the inadvertent reading of code while the code itself can still be executed. We introduce a new primitive we call Execute-no-Read (XnR) which ensures that code can still be executed by the processor, but at the same time code cannot be read as data. This ultimately forfeits the self-disassembly which is necessary for just-in-time code reuse attacks (JIT-ROP) to work. To the best of our knowledge, XnR is the first approach to prevent memory disclosure attacks of executable code and JIT-ROP attacks in general. Despite the lack of hardware support for XnR in contemporary Intel x86 and ARM processors, our software emulations for Linux and Windows have a run-time overhead of only 2.2% and 3.4%, respectively. Copyright is held by the owner/author(s).},
author = {Backes, Michael and Holz, Thorsten and Kollenda, Benjamin and Koppe, Philipp and N{\"{u}}rnberger, Stefan and Pewny, Jannik},
doi = {10.1145/2660267.2660378},
file = {:F\:/papers/Backes et al. - 2014 - You can run but you can't read Preventing disclosure exploits in executable code.pdf:pdf},
isbn = {9781450329576},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Buffer overflows,Code reuse attacks,Information leaks,Memory disclosure exploits,Return-oriented programming},
pages = {1342--1353},
title = {{You can run but you can't read: Preventing disclosure exploits in executable code}},
year = {2014}
}
@article{MohammadjavadSeyedTalebi2018,
abstract = {Mobile systems, such as smartphones and tablets, incorporate a diverse set of I/O devices, such as camera, audio devices, GPU, and sensors. This in turn results in a large number of diverse and customized device drivers running in the operating system kernel of mobile systems. These device drivers contain various bugs and vulnerabilities, making them a top target for kernel exploits [78]. Unfortunately , security analysts face important challenges in analyzing these device drivers in order to find, understand , and patch vulnerabilities. More specifically, using the state-of-the-art dynamic analysis techniques such as interactive debugging, fuzzing, and record-and-replay for analysis of these drivers is difficult, inefficient, or even completely inaccessible depending on the analysis. In this paper, we present Charm 1 , a system solution that facilitates dynamic analysis of device drivers of mobile systems. Charm's key technique is remote device driver execution, which enables the device driver to execute in a virtual machine on a workstation. Charm makes this possible by using the actual mobile system only for servicing the low-level and infrequent I/O operations through a low-latency and customized USB channel. Charm does not require any specialized hardware and is immediately available to analysts. We show that it is feasible to apply Charm to various device drivers, including camera, audio, GPU, and IMU sensor drivers, in different mobile systems, including LG Nexus 5X, Huawei Nexus 6P, and Samsung Galaxy S7. In an extensive evaluation, we show that Charm enhances the us-ability of fuzzing of device drivers, enables record-and-replay of driver's execution, and facilitates detailed vulnerability analysis. Altogether, these capabilities have enabled us to find 25 bugs in device drivers, analyze 3 existing ones, and even build an arbitrary-code-execution kernel exploit using one of them.},
author = {{Mohammadjavad Seyed Talebi}, Seyed and Tavakoli, Hamid and Irvine, Uc and Zhang, Hang and Zhang, Zheng and Riverside, Uc and {Amiri Sani}, Ardalan and Qian, Zhiyun},
file = {:F\:/papers/sec18-talebi.pdf:pdf},
isbn = {978-1-931971-46-1},
journal = {Ccs'18},
title = {{Charm: Facilitating Dynamic Analysis of Device Drivers of Mobile Systems}},
year = {2018}
}
@article{Vogl2014,
abstract = {Generally speaking, malicious code leverages hooks within a system to divert the control flow. Without them, an attacker is blind to the events occurring in the system , rendering her unable to perform malicious activities (e.g., hiding of files or capturing of keystrokes). However , while hooks are an integral part of modern attacks, they are at the same time one of their biggest weaknesses: Even the most sophisticated attack can be easily identified if one of its hooks is found. In spite of this fact, hooking mechanisms have remained almost unchanged over the last years and still rely on the persistent modification of code or control data to divert the control flow. As a consequence, hooks represent an abnormality within the system that is permanently evident and can in many cases easily be detected as the hook detection mechanisms of recent years amply demonstrated. In this paper, we propose a novel hooking concept that we refer to as dynamic hooking. Instead of modifying persistent control data permanently, this hooking mechanisms targets transient control data such as return addresses at run-time. The hook itself will thereby reside within non-control data and remains hidden until it is triggered. As a result, there is no evident connection between the hook and the actual control flow change, which enables dynamic hooks to successfully evade existing detection mechanisms. To realize this idea, dynamic hooks make use of exploitation techniques to trigger vulner-abilities at run-time. Due to this approach, dynamic hooks cannot only be used to arbitrarily modify the control flow, but can also be applied to conduct non-control data attacks, which makes them more powerful than their predecessors. We implemented a prototype that makes uses of static program slicing and symbolic execution to automatically extract paths for dynamic hooks that can then be used by a human expert for their realization. To demonstrate this, we used the output provided by our prototype to implement concrete examples of dynamic hooks for both modern Linux and Windows kernels.},
author = {Vogl, Sebastian and Gawlik, Robert and Garmany, Behrad and Kittel, Thomas and Pfoh, Jonas and Eckert, Claudia and Holz, Thorsten},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogl et al. - Unknown - Dynamic Hooks Hiding Control Flow Changes within Non-Control Data.pdf:pdf},
isbn = {978-1-931971-15-7},
journal = {USENIX Security},
title = {{Dynamic Hooks: Hiding Control Flow Changes within Non-Control Data}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/vogl},
year = {2014}
}
@article{Wang2017,
abstract = {We present the first static approach that systematically detects potential double-fetch vulnerabilities in the Linux kernel. Using a pattern-based analysis, we identified 90 double fetches in the Linux kernel. 57 of these occur in drivers, which previous dynamic approaches were unable to detect without access to the corresponding hardware. We manually investigated the 90 occurrences, and inferred three typical scenarios in which double fetches occur. We discuss each of them in detail. We further developed a static analysis, based on the Coccinelle matching engine, that detects double-fetch situations which can cause kernel vulnerabilities. When applied to the Linux, FreeBSD, and Android kernels, our approach found six previously unknown double-fetch bugs, four of them in drivers, three of which are exploitable double-fetch vulnerabilities. All of the identified bugs and vulnerabilities have been confirmed and patched by maintainers. Our approach has been adopted by the Coccinelle team and is currently being integrated into the Linux kernel patch vetting. Based on our study, we also provide practical solutions for anticipating double-fetch bugs and vulnerabilities. We also provide a solution to automatically patch detected double-fetch bugs.},
author = {Wang, Pengfei and Krinke, Jens and Lu, Kai and Li, Gen and Dodier-Lazaro, Steve},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - How double-fetch situations turn into double-fetch vulnerabilities A study of double fetches in the Linux kernel.pdf:pdf},
isbn = {9781931971409},
journal = {Proceedings of the 26th USENIX Security Symposium},
pages = {1--16},
title = {{How double-fetch situations turn into double-fetch vulnerabilities: A study of double fetches in the Linux kernel}},
year = {2017}
}
@article{Corina2017,
abstract = {Device drivers are an essential part in modern Unix-like systems to handle operations on physical devices, from hard disks and printers to digital cameras and Bluetooth speakers. The surge of new hardware, particularly on mobile devices, introduces an explosive growth of device drivers in system kernels. Many such drivers are provided by third-party developers, which are susceptible to security vulnerabilities and lack proper vetting. Unfortunately, the complex input data structures for device drivers render traditional analysis tools, such as fuzz testing, less effective, and so far, research on kernel driver security is comparatively sparse. In this paper, we present DIFUZE, an interface-aware fuzzing tool to automatically generate valid inputs and trigger the execution of the kernel drivers. We leverage static analysis to compose correctly-structured input in the userspace to explore kernel drivers. DIFUZE is fully automatic, ranging from identifying driver handlers, to mapping to device file names, to constructing complex argument instances. We evaluate our approach on seven modern Android smartphones. The results showthat DIFUZE can effectively identify kernel driver bugs, and reports 32 previously unknown vulnerabilities, including flaws that lead to arbitrary code execution.},
author = {Corina, Jake and MacHiry, Aravind and Salls, Christopher and Shoshitaishvili, Yan and Hao, Shuang and Kruegel, Christopher and Vigna, Giovanni},
doi = {10.1145/3133956.3134069},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Corina et al. - 2017 - Difuze Interface aware fuzzing for kernel drivers.pdf:pdf},
isbn = {9781450349468},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Fuzzing,Interface aware,Kernel drivers},
pages = {2123--2138},
title = {{Difuze: Interface aware fuzzing for kernel drivers}},
year = {2017}
}
@article{Li2019a,
abstract = {Hypervisors are widely deployed by cloud computing providers to support virtual machines, but their growing complexity poses a security risk as large codebases contain many vulnerabilities. We have created HypSec, a new hypervisor design for retrofitting an existing commodity hypervisor using microkernel principles to reduce its trusted computing base while protecting the confidentiality and integrity of virtual machines. HypSec partitions the hypervisor into an untrusted host that performs most complex hypervisor functionality without access to virtual machine data, and a trusted core that provides access control to virtual machine data and performs basic CPU and memory virtualization. Hardware virtualization support is used to isolate and protect the trusted core and execute it at a higher privilege level so it can mediate virtual machine exceptions and protect VM data in CPU and memory. HypSec takes an end-to-end approach to securing I/O to simplify its design, with applications increasingly using secure network connections in the cloud. We have used HypSec to retrofit KVM, showing how our approach can support a widely-used full-featured hypervisor integrated with a commodity operating system. The implementation has a trusted computing base of only a few thousand lines of code, many orders of magnitude less than KVM. We show that HypSec protects the confidentiality and integrity of virtual machines running unmodified guest operating systems while only incurring modest performance overhead for real application workloads.},
author = {Li, Shih Wei and Koh, John S. and Nieh, Jason},
file = {:F\:/D2/sec19-li-shih-wei.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1357--1374},
title = {{Protecting cloud virtual machines from commodity hypervisor and host operating system exploits}},
year = {2019}
}
@article{Lee,
abstract = {A kernel data race is notoriously challenging to detect, reproduce , and diagnose, mainly caused by nondeterministic thread interleaving. The kernel data race has a critical security implication since it often leads to memory corruption, which can be abused to launch privilege escalation attacks. Interestingly, due to the challenges above, the exploitation of the kernel data race is also challenging. Specifically, we find that some kernel races are nearly impossible to exploit due to their unique requirement on execution orders, which are almost impossible to happen without manual intervention. This paper develops a generic exploitation technique for kernel data races. To this end, we first analyze kernel data races, which finds an intrinsic condition classifying easy-to-exploit and hard-to-exploit races. Then we develop EXPRACE, a generic race exploitation technique for modern kernels, including Linux, Microsoft Windows, and MAC OS X. EXPRACE turns hard-to-exploit races into easy-to-exploit races by manipulating an interrupt mechanism during the exploitation. According to our evaluation with 10 real-world hard-to-exploit races, EXPRACE was able to exploit all of those within 10 to 118 seconds, while an exploitation without EXPRACE failed for all given 24 hours.},
author = {Lee, Yoochan and Min, Changwoo and Tech, Virginia and Lee, Byoungyoung},
file = {:F\:/D2/sec21fall-lee-yoochan.pdf:pdf},
title = {{EXPRACE: Exploiting Kernel Races through Raising Interrupts}}
}
@article{Mao2011,
abstract = {The security of many applications relies on the kernel being secure, but history suggests that kernel vulnerabilities are routinely discovered and exploited. In particular, exploitable vulnerabilities in kernel modules are common. This paper proposes LXFI, a system which isolates kernel modules from the core kernel so that vulnerabilities in kernel modules cannot lead to a privilege escalation attack. To safely give kernel modules access to complex kernel APIs, LXFI introduces the notion of API integrity, which captures the set of contracts assumed by an interface. To partition the privileges within a shared module, LXFI introduces module principals. Programmers specify principals and API integrity rules through capabilities and annotations. Using a compiler plugin, LXFI instruments the generated code to grant, check, and transfer capabilities between modules, according to the programmer's annotations. An evaluation with Linux shows that the annotations required on kernel functions to support a new module are moderate, and that LXFI is able to prevent three known privilege-escalation vulnerabilities. Stress tests of a network driver module also show that isolating this module using LXFI does not hurt TCP throughput but reduces UDP throughput by 35%, and increases CPU utilization by 2.2-3.7x. {\textcopyright} 2011 ACM.},
author = {Mao, Yandong and Chen, Haogang and Zhou, Dong and Wang, Xi and Zeldovich, Nickolai and Kaashoek, M. Frans},
doi = {10.1145/2043556.2043568},
file = {:F\:/D2/2043556.2043568.pdf:pdf},
isbn = {9781450309776},
journal = {SOSP'11 - Proceedings of the 23rd ACM Symposium on Operating Systems Principles},
pages = {115--128},
title = {{Software fault isolation with API integrity and multi-principal modules}},
year = {2011}
}
@article{Lattner,
author = {Lattner, Chris},
file = {:F\:/D2/2004-01-30-CGO-LLVM.pdf:pdf},
number = {c},
title = {{Llvm-a-Compilation-Framework-for-Lifelong-Program-Analysis.Pdf}}
}
@article{Szekeres2013a,
abstract = {Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corruption attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms implementing stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps designers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency. We identify some open research problems, and provide suggestions on improving the adoption of newer techniques. {\textcopyright} 2013 IEEE.},
author = {Szekeres, L{\'{a}}szl{\'{o}} and Payer, Mathias and Wei, Tao and Song, Dawn},
doi = {10.1109/SP.2013.13},
file = {:F\:/D2/06547101.pdf:pdf},
isbn = {9780769549774},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {48--62},
title = {{SoK: Eternal war in memory}},
year = {2013}
}
@article{Wang2009,
abstract = {Kernel rootkits have posed serious security threats due to their stealthy manner. To hide their presence and activities, many rootkits hijack control flows by modifying control data or hooks in the kernel space. A critical step towards eliminating rootkits is to protect such hooks from being hijacked. However, it remains a challenge because there exist a large number of widely-scattered kernel hooks and many of them could be dynamically allocated from kernel heap and co-located together with other kernel data. In addition, there is a lack of flexible commodity hardware support, leading to the socalled protection granularity gap - kernel hook protection requires byte-level granularity but commodity hardware only provides page level protection. To address the above challenges, in this paper, we present HookSafe, a hypervisor-based lightweight system that can protect thousands of kernel hooks in a guest OS from being hijacked. One key observation behind our approach is that a kernel hook, once initialized, may be frequently "read"- accessed, but rarely write"-accessed. As such, we can relocate those kernel hooks to a dedicated page-aligned memory space and then regulate accesses to them with hardware-based page-level protection. We have developed a prototype of HookSafe and used it to protect more than 5,900 kernel hooks in a Linux guest. Our experiments with nine real-world rootkits show that HookSafe can effectively defeat their attempts to hijack kernel hooks. We also show that HookSafe achieves such a large-scale protection with a small overhead (e.g., around 6% slowdown in performance benchmarks). Copyright 2009 ACM.},
author = {Wang, Zhi and Jiang, Xuxian and Cui, Weidong and Ning, Peng},
doi = {10.1145/1653662.1653728},
file = {:F\:/D2/1653662.1653728.pdf:pdf},
isbn = {9781605583525},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Malware protection,Rootkits,Virtual machines},
pages = {545--554},
title = {{Countering kernel rootkits with lightweight hook protection}},
year = {2009}
}
@article{Lu2019,
abstract = {Missing a security check is a class of semantic bugs in software programs where erroneous execution states are not validated. Missing-check bugs are particularly common in OS kernels because they frequently interact with external untrusted user space and hardware, and carry out error-prone computation. Missing-check bugs may cause a variety of critical security consequences, including permission bypasses, out-of-bound accesses, and system crashes. While missing-check bugs are common and critical, only a few research works have attempted to detect them, which is arguably because of the inherent challenges in the detection-whether a variable requires a security check depends on its semantics, contexts and developer logic, and understanding them is a hard problem. In this paper, we present CRIX, a system for detecting missing-check bugs in OS kernels. CRIX can scalably and precisely evaluate whether any security checks are missing for critical variables, using an inter-procedural, semantic- and context-aware analysis. In particular, CRIX's modeling and cross-checking of the semantics of conditional statements in the peer slices of critical variables infer their criticalness, which allows CRIX to effectively detect missing-check bugs. Evaluation results show that CRIX finds missing-check bugs with reasonably low false-report rates. Using CRIX, we have found 278 new missing-check bugs in the Linux kernel that can cause security issues. We submitted patches for all these bugs; Linux maintainers have accepted 151 of them. The promising results show that missing-check bugs are a common occurrence, and CRIX is effective and scalable in detecting missing-check bugs in OS kernels.},
author = {Lu, Kangjie and Pakki, Aditya and Wu, Qiushi},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Pakki, Wu - 2019 - Detecting missing-check bugs via semantic- And context-aware criticalness and constraints inferences.pdf:pdf},
isbn = {9781939133069},
journal = {Proceedings of the 28th USENIX Security Symposium},
pages = {1769--1786},
title = {{Detecting missing-check bugs via semantic- And context-aware criticalness and constraints inferences}},
year = {2019}
}
@article{Wang2018,
abstract = {Operating system kernels carry a large number of security checks to validate security-sensitive variables and operations. For example, a security check should be embedded in a code to ensure that a user-supplied pointer does not point to the kernel space. Using security-checked variables is typically safe. However, in reality, security-checked variables are often subject to modification after the check. If a recheck is lacking after a modification, security issues may arise, e.g., adversaries can control the checked variable to launch critical attacks such as out-of-bound memory access or privilege escalation. We call such cases lacking-recheck (LRC) bugs, a subclass of TOCTTOU bugs, which have not been explored yet. In this paper, we present the first in-depth study of LRC bugs and develop LRSan, a static analysis system that systematically detects LRC bugs in OS kernels. Using an inter-procedural analysis and multiple new techniques, LRSan first automatically identifies security checks, critical variables, and uses of the checked variables, and then reasons about whether a modification is present after a security check. A case in which a modification is present but a recheck is lacking is an LRC bug. We apply LRSan to the latest Linux kernel and evaluate the effectiveness of LRSan. LRSan reports thousands of potential LRC cases, and we have confirmed 19 new LRC bugs. We also discuss patching strategies of LRC bugs based on our study and bug-fixing experience.},
author = {Wang, Wenwen and Lu, Kangjie and Yew, Pen Chung},
doi = {10.1145/3243734.3243844},
file = {:F\:/papers/Wang, Lu, Yew - 2018 - Check it again Detecting lacking-recheck bugs in OS kernels.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Error code,Lacking-recheck,Missing check,OS Kernel Bug,Static analysis,TOCTTOU},
pages = {1899--1913},
title = {{Check it again: Detecting lacking-recheck bugs in OS kernels}},
year = {2018}
}
@article{Elphinstone2013,
abstract = {The L4 microkernel has undergone 20 years of use and evolution. It has an active user and developer community, and there are commercial versions which are deployed on a large scale and in safety-critical systems. In this paper we examine the lessons learnt in those 20 years about microkernel design and implementation. We revisit the L4 design papers, and examine the evolution of design and implementation from the original L4 to the latest generation of L4 kernels, especially seL4, which has pushed the L4 model furthest and was the first OS kernel to undergo a complete formal verification of its implementation as well as a sound analysis of worst-case execution times. We demonstrate that while much has changed, the fundamental principles of minimality and high IPC performance remain the main drivers of design and implementation decisions. {\textcopyright} 2013 ACM.},
author = {Elphinstone, Kevin and Heiser, Gernot},
doi = {10.1145/2517349.2522720},
file = {:F\:/D2/p133-elphinstone.pdf:pdf},
isbn = {9781450323888},
journal = {SOSP 2013 - Proceedings of the 24th ACM Symposium on Operating Systems Principles},
pages = {133--150},
title = {{From L3 to seL4: What have we learnt in 20 years of L4 microkernels?}},
year = {2013}
}
@article{Checkoway2013,
abstract = {In recent years, researchers have proposed systems for running trusted code on an untrusted operating system. Protection mechanisms deployed by such systems keep a malicious kernel from directly manipulating a trusted application's state. Under such},
author = {Checkoway, Stephen and Shacham, Hovav},
doi = {10.1145/2499368.2451145},
file = {:F\:/D2/2490301.2451145.pdf:pdf},
isbn = {9781450318709},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
number = {4},
pages = {253--264},
title = {{Iago attacks}},
volume = {48},
year = {2013}
}
@article{Hwang2019,
abstract = {The OS kernel is typically the assumed trusted computing base in a system. Consequently, when they try to protect the kernel, developers often build their solutions in a separate secure execution environment externally located and protected by special hardware. Due to limited visibility into the host system, the external solutions basically all entail the semantic gap problem which can be easily exploited by an adversary to circumvent them. Thus, for complete kernel protection against such adversarial exploits, previous solutions resorted to aggressive techniques that usually come with various adverse side effects, such as high performance overhead, kernel code modifications and/or excessively complicated hardware designs. In this paper, we introduce RiskiM, our new hardware-based monitoring platform to ensure kernel integrity from outside the host system. To overcome the semantic gap problem, we have devised a hardware interface architecture, called PEMI, by which RiskiM is supplied with all internal states of the host system essential for fulfilling its monitoring task to protect the kernel even in the presence of attacks exploiting the semantic gap between the host and RiskiM. To empirically validate the security strength and performance of our monitoring platform in existing systems, we have fully implemented RiskiM in a RISC-V system. Our experiments show that RiskiM succeeds in the host kernel protection by detecting even the advanced attacks which could circumvent previous solutions, yet suffering from virtually no aforementioned side effects.},
author = {Hwang, Dongil and Yang, Myonghoon and Jeon, Seongil and Lee, Younghan and Kwon, Donghyun and Paek, Yunheung},
doi = {10.23919/DATE.2019.8715277},
file = {:F\:/D2/RiskiM_Toward_Complete_Kernel_Protection_with_Hardware_Support.pdf:pdf},
isbn = {9783981926323},
journal = {Proceedings of the 2019 Design, Automation and Test in Europe Conference and Exhibition, DATE 2019},
pages = {740--745},
publisher = {EDAA},
title = {{RiskiM: Toward Complete Kernel Protection with Hardware Support}},
year = {2019}
}
@inproceedings{Madhavapeddy2013,
abstract = {We present unikernels, a new approach to deploying cloud services via applications written in high-level source code. Unikernels are single-purpose appliances that are compile-time specialised into standalone kernels, and sealed against modification when deployed to a cloud platform. In return they offer significant reduction in image sizes, improved efficiency and security, and should reduce operational costs. Our Mirage prototype compiles OCaml code into unikernels that run on commodity clouds and offer an order of magnitude reduction in code size without significant performance penalty. The architecture combines static type-safety with a single address-space layout that can be made immutable via a hypervisor extension. Mirage contributes a suite of type-safe protocol libraries, and our results demonstrate that the hypervisor is a platform that overcomes the hardware compatibility issues that have made past library operating systems impractical to deploy in the real-world.},
author = {Madhavapeddy, Anil and Mortier, Richard and Rotsos, Charalampos and Scott, David and Singh, Balraj and Gazagnaire, Thomas and Smith, Steven and Hand, Steven and Crowcroft, Jon},
booktitle = {ASPLOS'13,},
doi = {10.1145/2499368.2451167},
file = {:F\:/D2/2490301.2451167.pdf:pdf},
isbn = {9781450318709},
issn = {15232867},
keywords = {Microkernels,Type-safety,Virtualization},
number = {4},
pages = {461--472},
title = {{Unikernels: Library operating systems for the cloud}},
volume = {48},
year = {2013}
}
@article{Pomonis2018,
abstract = {The abundance of memory corruption and disclosure vulnerabilities in kernel code necessitates the deployment of hardening techniques to prevent privilege escalation attacks. As stricter memory isolation mechanisms between the kernel and user space become commonplace, attackers increasingly rely on code reuse techniques to exploit kernel vulnerabilities. Contrary to similar attacks in more restrictive settings, as in web browsers, in kernel exploitation, non-privileged local adversaries have great flexibility in abusing memory disclosure vulnerabilities to dynamically discover, or infer, the location of code snippets in order to construct code-reuse payloads. Recent studies have shown that the coupling of code diversification with the enforcement of a “read XOR execute” (R ∧ X) memory safety policy is an effective defense against the exploitation of userland software, but so far this approach has not been applied for the protection of the kernel itself. In this article, we fill this gap by presenting kR ∧ X: a kernel-hardening scheme based on execute-only memory and code diversification. We study a previously unexplored point in the design space, where a hypervisor or a super-privileged component is not required. Implemented mostly as a set of GCC plugins, kR ∧ X is readily applicable to x86 Linux kernels (both 32b and 64b) and can benefit from hardware support (segmentation on x86, MPX on x86-64) to optimize performance. In full protection mode, kR ∧ X incurs a low runtime overhead of 4.04%, which drops to 2.32% when MPX is available, and 1.32% when memory segmentation is in use.},
author = {Pomonis, Marios and Petsios, Theofilos and Keromytis, Angelos D. and Polychronakis, Michalis and Kemerlis, Vasileios P.},
doi = {10.1145/3277592},
file = {:F\:/D2/3277592.pdf:pdf},
isbn = {0001415123},
issn = {24712574},
journal = {ACM Transactions on Privacy and Security},
keywords = {Code diversification,Execute-only memory},
number = {1},
pages = {1--28},
title = {{Kernel protection against just-in-time code reuse}},
volume = {22},
year = {2018}
}
@article{Cho2020,
abstract = {Information leaks are the most prevalent type of vulnerabilities among all known vulnerabilities in Linux kernel. Many of them are caused by the use of uninitialized variables or data structures. It is generally believed that the majority of information leaks in Linux kernel are low-risk and do not have severe impact due to the difficulty (or even the impossibility) of exploitation. As a result, developers and security analysts do not pay enough attention to mitigating these vulnerabilities. Consequently, these vulnerabilities are usually assigned low CVSS scores or without any CVEs assigned. Moreover, many patches that address uninitialized data use bugs in Linux kernel are not accepted, leaving billions of Linux systems vulnerable. Nonetheless, information leak vulnerabilities in Linux kernel are not as low-risk as people believe. In this paper, we present a generic approach that converts stack-based information leaks in Linux kernel into kernel-pointer leaks, which can be used to defeat modern security defenses such as KASLR. Taking an exploit that triggers an information leak in Linux kernel, our approach automatically converts it into a highly impactful exploit that leaks pointers to either kernel functions or the kernel stack. We evaluate our approach on four known CVEs and one security patch in Linux kernel and demonstrate its effectiveness. Our findings provide solid evidence for Linux kernel developers and security analysts to treat information leaks in Linux kernel more seriously.},
author = {Cho, Haehyun and Park, Jinbum and Kang, Joonwon and Bao, Tiffany and Wang, Ruoyu and Shoshitaishvili, Yan and Doup{\'{e}}, Adam and Ahn, Gail Joon},
file = {:F\:/D2/woot20-paper-cho.pdf:pdf},
journal = {WOOT 2020 - 14th USENIX Workshop on Offensive Technologies, co-located with USENIX Security 2020},
title = {{Exploiting uses of uninitialized stack variables in linux kernels to leak kernel pointers}},
year = {2020}
}
@article{Dang2015,
author = {Dang, Thurston H Y and Wagner, David},
file = {:F\:/D2/2714576.2714635.pdf:pdf},
isbn = {9781450332453},
journal = {Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security},
pages = {555--566},
title = {{The Performance Cost of Shadow Stacks and Stack Canaries Time of Check to Time of Use}},
year = {2015}
}
@article{Akkus2020,
abstract = {Serverless computing has emerged as a new cloud computing paradigm, where an application consists of individual functions that can be separately managed and executed. However, existing serverless platforms normally isolate and execute functions in separate containers, and do not exploit the interactions among functions for performance. These practices lead to high startup delays for function executions and inefficient resource usage. This paper presents SAND, a new serverless computing system that provides lower latency, better resource efficiency and more elasticity than existing serverless platforms. To achieve these properties, SAND introduces two key techniques: 1) application-level sandboxing, and 2) a hierarchical message bus. We have implemented and deployed a complete SAND system. Our results show that SAND outperforms the state-of-the-art serverless platforms significantly. For example, in a commonly-used image processing application, SAND achieves a 43% speedup compared to Apache OpenWhisk.},
author = {Akkus, Istemi Ekin and Chen, Ruichuan and Rimac, Ivica and Satzke, Manuel Stein Klaus and Beck, Andre and Aditya, Paarijaat and Hilt, Volker},
file = {:F\:/papers/atc18-akkus.pdf:pdf},
isbn = {9781939133021},
journal = {Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018},
pages = {923--935},
title = {{SAND: Towards high-performance serverless computing}},
year = {2020}
}
@article{Lee2013a,
abstract = {Kernel rootkits undermine the integrity of system by manipulating its operating system kernel. External hardware-based monitors can serve as a root of trust that is resilient to rootkit attacks. The existing external hardware-based approaches lack an event-triggered verification scheme for mutable kernel objects. To address the issue, we present KI-Mon, a hardware-based platform for event-triggered kernel integrity monitor. A refined form of bus traffic monitoring efficiently verifies the update values of the objects, and callback verification routines can be programmed and executed for a designated event space. We have built a KI-Mon prototype to demonstrate the efficacy of KI-Mon's event-triggered mechanism in terms of performance overhead for the monitored host system and the processor usage of the KI-Mon processor.},
author = {Lee, Hojoon and Moon, Hyungon and Jang, Daehee and Kim, Kihwan and Lee, Jihoon and Paek, Yunheung and Kang, Brent Byung Hoon},
file = {:F\:/D2/07874084.pdf:pdf},
isbn = {9781931971034},
journal = {Proceedings of the 22nd USENIX Security Symposium},
number = {2},
pages = {511--526},
publisher = {IEEE},
title = {{KI-Mon ARM: A Hardware-Assisted Event-triggered Monitoring Platform for Mutable Kernel Object}},
volume = {16},
year = {2013}
}
@book{Srivastava2012,
abstract = {Commodity operating system kernels isolate applications via separate memory address spaces provided by virtual memory management hardware. However, kernel memory is unified and mixes core kernel code with driver components of different provenance. Kernel-level malicious software exploits this lack of isolation between the kernel and its modules by illicitly modifying security-critical kernel data structures. In this paper, we design an access control policy and enforcement system that prevents kernel components with low trust from altering security-critical data used by the kernel to manage its own execution. Our policies are at the granularity of kernel variables and structure elements, and they can protect data structures dynamically allocated at runtime. Our hypervisor-based design uses memory page protection bits as part of its policy enforcement. The granularity difference between page-level protection and variable-level policies challenges the system's ability to remain performant. We develop kernel data-layout partitioning and reorganization techniques to maintain kernel performance in the presence of our protections. We show that our system can prevent malicious modifications to security-critical kernel data with small overhead. By offering protection for critical kernel data structures, we can detect unknown kernel-level malware and guarantee that security utilities relying on the integrity of kernel-level state remain accurate.},
author = {Srivastava, Abhinav and Giffin, Jonathon and Fortify, H P},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava, Giffin, Fortify - 2012 - Efficient Protection of Kernel Data Structures via Object Partitioning.pdf:pdf},
isbn = {9781450313124},
title = {{Efficient Protection of Kernel Data Structures via Object Partitioning}},
year = {2012}
}
@book{Pan,
abstract = {Discovering vulnerabilities in operating system (OS) kernels and patching them is crucial for OS security. However , there is a lack of effective kernel vulnerability detection tools, especially for closed-source OSes such as Microsoft Windows. In this paper, we present Digtool, an effective, binary-code-only, kernel vulnerability detection framework. Built atop a virtualization monitor we designed, Digtool successfully captures various dynamic behaviors of kernel execution, such as kernel object allocation, kernel memory access, thread scheduling, and function invoking. With these behaviors, Digtool has identified 45 zero-day vulnerabilities such as out-of-bounds access, use-after-free, and time-of-check-to-time-of-use among both kernel code and device drivers of recent versions of Microsoft Windows, including Windows 7 and Windows 10.},
author = {Pan, Jianfeng and Yan, Guanglu and Fan, Xiaocao},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Yan, Fan - Unknown - Digtool A Virtualization-Based Framework for Detecting Kernel Vulnerabilities.pdf:pdf},
isbn = {978-1-931971-40-9},
title = {{Digtool: A Virtualization-Based Framework for Detecting Kernel Vulnerabilities}},
url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/pan}
}
@article{Berger2006,
abstract = {Applications written in unsafe languages like C and C++ are vulnerable to memory errors such as buffer overflows, dangling pointers, and reads of uninitialized data. Such errors can lead to program crashes, security vulnerabilities, and unpredictable behavior. We present DieHard, a runtime system that tolerates these errors while probabilistically maintaining soundness. DieHard uses randomization and replication to achieve probabilistic memory safety by approximating an infinite-sized heap. DieHard's memory manager randomizes the location of objects in a heap that is at least twice as large as required. This algorithm prevents heap corruption and provides a probabilistic guarantee of avoiding memory errors. For additional safety, DieHard can operate in a replicated mode where multiple replicas of the same application are run simultaneously. By initializing each replica with a different random seed and requiring agreement on output, the replicated version of DieHard increases the likelihood of correct execution because errors are unlikely to have the same effect across all replicas. We present analytical and experimental results that show DieHard's resilience to a wide range of memory errors, including a heap-based buffer overflow in an actual application. Copyright {\textcopyright} 2006 ACM.},
author = {Berger, Emery D. and Zorn, Benjamin G.},
doi = {10.1145/1133255.1134000},
file = {:F\:/D2/1133255.1134000.pdf:pdf},
isbn = {1595933204},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {DieHard,Dynamic memory allocation,Probabilistic memory safety,Randomization,Replication},
number = {6},
pages = {158--168},
title = {{DieHard: Probabilistic memory safety for unsafe languages}},
volume = {41},
year = {2006}
}
@article{Demarinis,
abstract = {Modern OSes provide a rich set of services to applications, primarily accessible via the system call API, to support the ever growing functionality of contemporary software. However , despite the fact that applications require access to part of the system call API (to function properly), OS kernels allow full and unrestricted use of the entire system call set. This not only violates the principle of least privilege, but also enables attackers to utilize extra OS services, after seizing control of vulnerable applications, or escalate privileges further via exploiting vulnerabilities in less-stressed kernel interfaces. To tackle this problem, we present sysfilter: a binary analysis-based framework that automatically (1) limits what OS services attackers can (ab)use, by enforcing the principle of least privilege with respect to the system call API, and (2) reduces the attack surface of the kernel, by restricting the system call set available to userland processes. We implement sysfilter for x86-64 Linux, and present a set of program analyses for constructing system call sets statically, and in a scalable, precise, and complete (safe over-approximation) manner. In addition, we evaluate our prototype in terms of cor-rectness using 411 binaries (real-world C/C++ applications) and ≈38.5K tests to assert their functionality. Furthermore, we measure the impact of our enforcement mechanism(s), demonstrating minimal, or negligible, run-time slowdown. Lastly, we conclude with a large scale study of the system call profile of ≈30K C/C++ applications (from Debian sid), reporting insights that justify our design and can aid that of future (system call-based) policing mechanisms.},
author = {Demarinis, Nicholas and Williams-King, Kent and Jin, Di and Fonseca, Rodrigo and Kemerlis, Vasileios P},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Demarinis et al. - Unknown - sysfilter Automated System Call Filtering for Commodity Software.pdf:pdf},
title = {{sysfilter: Automated System Call Filtering for Commodity Software}}
}
@article{Zhang2011,
abstract = {Multi-tenant cloud, which usually leases resources in the form of virtual machines, has been commercially available for years. Unfortunately, with the adoption of commodity virtualized infrastructures, software stacks in typical multi-tenant clouds are non-trivially large and complex, and thus are prone to compromise or abuse from adversaries including the cloud operators, which may lead to leakage of security-sensitive data. In this paper, we propose a transparent, backward-compatible approach that protects the privacy and integrity of customers' virtual machines on commodity virtualized infrastructures, even facing a total compromise of the virtual machine monitor (VMM) and the management VM. The key of our approach is the separation of the resource management from security protection in the virtualization layer. A tiny security monitor is introduced underneath the commodity VMM using nested virtualization and provides protection to the hosted VMs. As a result, our approach allows virtualization software (e.g., VMM, management VM and tools) to handle complex tasks of managing leased VMs for the cloud, without breaking security of users' data inside the VMs. We have implemented a prototype by leveraging commercially-available hardware support for virtualization. The prototype system, called CloudVisor, comprises only 5.5K LOCs and supports the Xen VMM with multiple Linux and Windows as the guest OSes. Performance evaluation shows that CloudVisor incurs moderate slow-down for I/O intensive applications and very small slowdown for other applications. {\textcopyright} 2011 ACM.},
author = {Zhang, Fengzhe and Chen, Jin and Chen, Haibo and Zang, Binyu},
doi = {10.1145/2043556.2043576},
file = {:F\:/D2/2043556.2043576.pdf:pdf},
isbn = {9781450309776},
journal = {SOSP'11 - Proceedings of the 23rd ACM Symposium on Operating Systems Principles},
keywords = {multi-tenant cloud,nested virtualization,virtual machine security},
pages = {203--216},
title = {{CloudVisor: Retrofitting protection of virtual machines in multi-tenant cloud with nested virtualization}},
year = {2011}
}
@article{Ge2016,
author = {Ge, Xinyang and Talele, Nirupama and Payer, Mathias and Jaeger, Trent},
doi = {10.1109/EuroSP.2016.24},
file = {:F\:/D2/07467354.pdf:pdf},
isbn = {9781509017522},
publisher = {IEEE},
title = {{Fine-Grained Control-Flow Integrity for Kernel Software}},
year = {2016}
}
@article{Lipp2018,
abstract = {The security of computer systems fundamentally relies on memory isolation, e.g., kernel address ranges are marked as non-accessible and are protected from user access. In this paper, we present Meltdown. Meltdown exploits side effects of out-of-order execution on modern processors to read arbitrary kernel-memory locations including personal data and passwords. Out-of-order execution is an indispensable performance feature and present in a wide range of modern processors. The attack works on different Intel microarchitectures since at least 2010 and potentially other processors are affected. The root cause of Meltdown is the hardware. The attack is independent of the operating system, and it does not rely on any software vulnerabilities. Meltdown breaks all security assumptions given by address space isolation as well as paravirtualized environments and, thus, every security mechanism building upon this foundation. On affected systems, Meltdown enables an adversary to read memory of other processes or virtual machines in the cloud without any permissions or privileges, affecting millions of customers and virtually every user of a personal computer. We show that the KAISER defense mechanism for KASLR has the important (but inadvertent) side effect of impeding Meltdown. We stress that KAISER must be deployed immediately to prevent large-scale exploitation of this severe information leakage.},
author = {Lipp, Moritz and Schwarz, Michael and Gruss, Daniel and Prescher, Thomas and Haas, Werner and Fogh, Anders and Horn, Jann and Mangard, Stefan and Kocher, Paul and Genkin, Daniel and Yarom, Yuval and Hamburg, Mike and Lanssen, N. and Flaven, C.},
file = {:F\:/papers/Lipp et al. - 2018 - Meltdown Reading Kernel Memory from User Space.pdf:pdf},
issn = {08960615},
journal = {27th USENIX Security Symposium (USENIX Security 18)},
number = {3},
pages = {23--31},
title = {{Meltdown: Reading Kernel Memory from User Space}},
volume = {9},
year = {2018}
}
@article{Checkoway2010,
abstract = {We show that on both the x86 and ARM architectures it is possible to mount return-oriented programming attacks without using return instructions. Our attacks instead make use of certain instruction sequences that behave like a return, which occur with sufficient frequency in large libraries on (x86) Linux and (ARM) Android to allow creation of Turing-complete gadget sets. Because they do not make use of return instructions, our new attacks have negative implications for several recently proposed classes of defense against return-oriented programming: those that detect the too-frequent use of returns in the instruction stream; those that detect violations of the last-in, first-out invariant normally maintained for the return-address stack; and those that modify compilers to produce code that avoids the return instruction. Copyright 2010 ACM.},
author = {Checkoway, Stephen and Davi, Lucas and Dmitrienko, Alexandra and Sadeghi, Ahmad Reza and Shacham, Hovav and Winandy, Marcel},
doi = {10.1145/1866307.1866370},
file = {:F\:/papers/Checkoway et al. - 2010 - Return-oriented programming without returns.pdf:pdf},
isbn = {9781450302449},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Algorithms,Security},
pages = {559--572},
title = {{Return-oriented programming without returns}},
year = {2010}
}
@article{Charlebois2012,
author = {Charlebois, Mark},
file = {:F\:/papers/Mark_Charlebois.pdf:pdf},
pages = {1--33},
title = {{Compiling Linux with LLVM}},
year = {2012}
}
@article{Wojtczuk2011,
abstract = {We (iscuss three software attacks that might allow for escaing from a -(-rotecte( (river (omain in a virtualization sstem. We then focus on one of those attacks+ an( (emonstrate ractical and reliable code e!ec"tion e! loit against a en syste. ,inall+ we (iscuss how new har(ware from Intel offers a otential for rotection against our attacks in the form of Interrut Remaing -for client sstems available onl on the ver latest .an( /ri(ge rocessors0. /ut we also (iscuss how this rotection coul( be circumvente( on a 1en sstem un(er certain circumstances...},
author = {Wojtczuk, Rafal and Rutkowska, Joanna},
file = {:F\:/D2/Software Attacks on Intel VT-d.pdf:pdf},
journal = {Matrix},
pages = {1--27},
title = {{Following the White Rabbit : Software attacks against Intel ( R ) VT-d technology}},
year = {2011}
}
@article{Xu2018,
abstract = {During system call execution, it is common for operating system kernels to read userspace memory multiple times (multi-reads). A critical bug may exist if the fetched userspace memory is subject to change across these reads, i.e., a race condition, which is known as a double-fetch bug. Prior works have attempted to detect these bugs both statically and dynamically. However, due to their improper assumptions and imprecise definitions regarding double-fetch bugs, their multi-read detection is inherently limited and suffers from significant false positives and false negatives. For example, their approach is unable to support device emulation, inter-procedural analysis, loop handling, etc. More importantly, they completely leave the task of finding real double-fetch bugs from the haystack of multi-reads to manual verification, which is expensive if possible at all. In this paper, we first present a formal and precise definition of double-fetch bugs and then implement a static analysis system-Deadline-to automatically detect double-fetch bugs in OS kernels. Deadline uses static program analysis techniques to systematically find multi-reads throughout the kernel and employs specialized symbolic checking to vet each multi-read for double-fetch bugs. We apply Deadline to Linux and FreeBSD kernels and find 23 new bugs in Linux and one new bug in FreeBSD. We further propose four generic strategies to patch and prevent double-fetch bugs based on our study and the discussion with kernel maintainers.},
author = {Xu, Meng and Qian, Chenxiong and Lu, Kangjie and Backes, Michael and Kim, Taesoo},
doi = {10.1109/SP.2018.00017},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2018 - Precise and Scalable Detection of Double-Fetch Bugs in OS Kernels.pdf:pdf},
isbn = {9781538643525},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {bug,detection,kernel},
pages = {661--678},
publisher = {IEEE},
title = {{Precise and Scalable Detection of Double-Fetch Bugs in OS Kernels}},
volume = {2018-May},
year = {2018}
}
@article{Chen2008,
abstract = {Commodity operating systems entrusted with securing sensitive data are remarkably large and complex, and consequently, frequently prone to compromise. To address this limitation, we introduce a virtual-machine-based system called Overshadow that protects the privacy and integrity of application data, even in the event of a total OScompromise. Overshadow presents an application with a normal view of its resources, but the OS with an encrypted view. This allows the operating system to carry out the complex task of managing an application's resources, without allowing it to read or modify them. Thus, Overshadow offers a last line of defense for application data. Overshadow builds on multi-shadowing, a novel mechanism that presents different views of "physical" memory, depending on the context performing the access. This primitive offers an additional dimension of protection beyond the hierarchical protection domains implemented by traditional operating systems and processor architectures. We present the design and implementation of Overshadow and show how its new protection semantics can be integrated with existing systems. Our design has been fully implemented and used to protect a wide range of unmodified legacy applications running on an unmodified Linux operating system. We evaluate the performance of our implementation, demonstrating that this approach is practical. Copyright {\textcopyright} 2008 ACM.},
author = {Chen, Xiaoxin and Garfinkel, Tal and Lewis, E. Christopher and Subrahmanyam, Pratap and Waldspurger, Carl A. and Boneh, Dan and Dwoskin, Jeffrey and Ports, Dan R.K.},
doi = {10.1145/1346281.1346284},
file = {:F\:/D2/1353535.1346284.pdf:pdf},
isbn = {9781595939586},
issn = {01635980},
journal = {Operating Systems Review (ACM)},
keywords = {Cloaking,Hypervisors,Memory protection,Multi-shadowing,Operating systems,VMM,Virtual machine monitors},
number = {2},
pages = {2--13},
title = {{Overshadow: A virtualization-based approach to retrofitting protection in commodity operating systems}},
volume = {42},
year = {2008}
}
@article{Dalton2008,
abstract = {Despite having been around for more than 25 years, buffer overflow attacks are still a major security threat for deployed software. Existing techniques for buffer overflow detection provide partial protection at best as they detect limited cases, suffer from many false positives, require source code access, or introduce large performance overheads. Moreover, none of these techniques are easily applicable to the operating system kernel. This paper presents a practical security environment for buffer overflow detection in userspace and kernelspace code. Our techniques build upon dynamic information flow tracking (DIFT) and prevent the attacker from overwriting pointers in the application or operating system. Unlike previous work, our technique does not have false positives on unmodified binaries, protects both data and control pointers, and allows for practical hardware support. Moreover, it is applicable to the kernel and provides robust detection of buffer overflows and user/kernel pointer dereferences. Using a full system prototype of a Linux workstation (hardware and software), we demonstrate our security approach in practice and discuss the major challenges for robust buffer overflow protection in real-world software.},
author = {Dalton, Michael and Kannan, Hari and Kozyrakis, Christos},
file = {:F\:/D2/dalton.pdf:pdf},
journal = {Proceedings of the 17th USENIX Security Symposium},
pages = {395--410},
title = {{Real-world buffer overflow protection for userspace & kernelspace}},
year = {2008}
}
@article{Davis2019,
abstract = {The CHERI architecture allows pointers to be implemented as capabilities (rather than integer virtual addresses) in a manner that is compatible with, and strengthens, the semantics of the C language. In addition to the spatial protections offered by conventional fat pointers, CHERI capabilities offer strong integrity, enforced provenance validity, and access monotonicity. The stronger guarantees of these architectural capabilities must be reconciled with the real-world behavior of operating systems, run-time environments, and applications. When the process model, user-kernel interactions, dynamic linking, and memory management are all considered, we observe that simple derivation of architectural capabilities is insufficient to describe appropriate access to memory. We bridge this conceptual gap with a notional abstract capability that describes the accesses that should be allowed at a given point in execution, whether in the kernel or userspace. To investigate this notion at scale, we describe the first adaptation of a full C-language operating system (FreeBSD) with an enterprise database (PostgreSQL) for complete spatial and referential memory safety. We show that awareness of abstract capabilities, coupled with CHERI architectural capabilities, can provide more complete protection, strong compatibility, and acceptable performance overhead compared with the pre-CHERI baseline and software-only approaches. Our observations also have potentially significant implications for other mitigation techniques.},
author = {Davis, Brooks and Watson, Robert N.M. and Richardson, Alexander and Neumann, Peter G. and Moore, Simon W. and Baldwin, John and Chisnall, David and Clarke, James and Filardo, Nathaniel Wesley and Gudka, Khilan and Joannou, Alexandre and Laurie, Ben and Markettos, A. Theodore and Maste, J. Edward and Mazzinghi, Alfredo and Napierala, Edward Tomasz and Norton, Robert M. and Roe, Michael and Sewell, Peter and Son, Stacey and Woodruff, Jonathan},
doi = {10.1145/3297858.3304042},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis et al. - 2019 - CheriABI Enforcing Valid Pointer Provenance and Minimizing Pointer Privilege in the POSIX C Run-time Environment.pdf:pdf},
isbn = {9781450362405},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {CHERI,hardware,operating systems,security},
pages = {379--393},
title = {{CheriABI: Enforcing Valid Pointer Provenance and Minimizing Pointer Privilege in the POSIX C Run-time Environment}},
year = {2019}
}
@article{Sharif2009,
abstract = {Kernel-level attacks or rootkits can compromise the security of an operating system by executing with the privilege of the kernel. Current approaches use virtualization to gain higher privilege over these attacks, and isolate security tools from the untrusted guest VM by moving them out and placing them in a separate trusted VM. Although out-of-VM isolation can help ensure security, the added overhead of world-switches between the guest VMs for each invocation of the monitor makes this approach unsuitable for many applications, especially fine-grained monitoring. In this paper, we present Secure In-VM Monitoring (SIM), a general-purpose framework that enables security monitoring applications to be placed back in the untrusted guest VM for efficiency without sacrificing the security guarantees provided by running them outside of the VM. We utilize contemporary hardware memory protection and hardware virtualization features available in recent processors to create a hypervisor protected address space where a monitor can execute and access data in native speeds and to which execution is transferred in a controlled manner that does not require hypervisor involvement. We have developed a prototype into KVM utilizing Intel VT hardware virtualization technology. We have also developed two representative applications for the Windows OS that monitor system calls and process creations. Our microbenchmarks show at least 10 times performance improvement in invocation of a monitor inside SIM over a monitor residing in another trusted VM. With a systematic security analysis of SIM against a number of possible threats, we show that SIM provides at least the same security guarantees as what can be achieved by out-of-VM monitors. Copyright 2009 ACM.},
author = {Sharif, Monirul I. and Lee, Wenke and Cui, Weidong and Lanzi, Andrea},
doi = {10.1145/1653662.1653720},
file = {:F\:/D2/1653662.1653720.pdf:pdf},
isbn = {9781605583525},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Kernel integrity,Malware,Secure monitoring,Virtual machines},
pages = {477--487},
title = {{Secure In-VM monitoring using hardware virtualization}},
year = {2009}
}
@article{Lu2019b,
abstract = {Kernel vulnerability may lead to information disclosure, privilege escalation, rootkit planting, etc. Nowadays mobile devices and other smart products has been increasingly available. Modern operation systems need to support new functions like GSM, Bluetooth, Wi-Fi, GPS, Camera of the smart devices. As a result, the number and categories of vulnerabilities and attacks is dramatically increasing. Correspondingly, varieties of researches have gone into finding such vulnerabilities in kernel. The kernel vulnerability analysis methods are vastly diverse. This paper surveys the state of the art on kernel vulnerability analysis. We summarize, compare, evaluate existing methods and provide the features, strengths and weaknesses of each kind of approaches. Then we present the trend on kernel vulnerability analysis. First, analysis on the system call, file system and the driver code become increasingly important. Second, existing methods can only handle limited kinds of vulnerabilities, which is insufficient for kernels, which contains modules, drivers, core kernel etc.. Third, the method for kernel vulnerability analysis will continuously focused on restricted parts of kernels or limited types of vulnerabilities for the kernel is implemented differently according to their platforms.},
author = {Lu, Shuaibing and Lin, Zhechao and Zhang, Ming},
doi = {10.1109/DSC.2019.00089},
file = {:F\:/D2/08923779.pdf:pdf},
isbn = {9781728145280},
journal = {Proceedings - 2019 IEEE 4th International Conference on Data Science in Cyberspace, DSC 2019},
keywords = {Dynamic analysis,Kernel fuzzing,Static analysis,Vulnerability analysis},
pages = {549--554},
publisher = {IEEE},
title = {{Kernel vulnerability analysis: A survey}},
year = {2019}
}
@article{Xiong2013,
abstract = {Untrusted kernel extensions remain one of the major threats to the security of commodity OS kernels. Current containment approaches still have limitations in terms of security, granularity and flexibility, primarily due to the absence of secure resource management and communication methods. This paper presents SILVER, a framework that offers transparent protection domain primitives to achieve fine-grained access control and secure communication between OS kernel and extensions. SILVER keeps track of security properties (e.g., owner principal and integrity level) of data objects in kernel space with a novel security-aware memory management scheme, which enables fine-grained access control in an effective manner. Moreover, SILVER introduces secure primitives for data communication between protection domains based on a unified integrity model. SILVER's protection domain primitives provide great flexibility by allowing developers to explicitly define security properties of individual program data, as well as control privilege delegation, data transfer and service exportation. We have implemented a prototype of SILVER in Linux. The evaluation results reveal that SILVER is effective against various kinds of kernel threats with a reasonable performance and resource overhead. {\textcopyright} 2013 Springer-Verlag.},
author = {Xiong, Xi and Liu, Peng},
doi = {10.1007/978-3-642-41284-4_6},
file = {:F\:/papers/SILVER linux kernel protection.pdf:pdf},
isbn = {9783642412837},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {OS kernel,Protection domain,Virtualization},
pages = {103--122},
title = {{SILVER: Fine-grained and transparent protection domain primitives in commodity OS kernel}},
volume = {8145 LNCS},
year = {2013}
}
@techreport{Tian,
abstract = {Kernel heap buffer overflow vulnerabilities have been exposed for decades, but there are few practical countermeasure that can be applied to OS kernels. Previous solutions either suffer from high performance overhead or compatibility problems with mainstream kernels and hardware. In this paper, we present KRUISER, a concurrent kernel heap buffer overflow monitor. Unlike conventional methods, the security enforcement of which is usually in-lined into the kernel execution, Kruiser migrates security enforcement from the kernel's normal execution to a concurrent monitor process, leveraging the increasingly popular multi-core architectures. To reduce the synchronization overhead between the monitor process and the running kernel, we design a novel semi-synchronized non-blocking monitoring algorithm, which enables efficient runtime detection on live memory without incurring false positives. To prevent the monitor process from being tampered and provide guaranteed performance isolation, we utilize the virtu-alization technology to run the monitor process out of the monitored VM, while heap memory allocation information is collected inside the monitored VM in a secure and efficient way. The hybrid VM monitoring technique combined with the secure canary that cannot be counterfeited by attackers provides guaranteed overflow detection with high efficiency. We have implemented a prototype of KRUISER based on Linux and the Xen hypervisor. The evaluation shows that Kruiser can detect realistic kernel heap buffer overflow attacks effectively with minimal overhead.},
author = {Tian, Donghai and Zeng, Qiang and Wu, Dinghao and Liu, Peng and Hu, Changzhen},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - Unknown - Kruiser Semi-synchronized Non-blocking Concurrent Kernel Heap Buffer Overflow Monitoring.pdf:pdf},
title = {{Kruiser: Semi-synchronized Non-blocking Concurrent Kernel Heap Buffer Overflow Monitoring}}
}
@inproceedings{Porter2012,
abstract = {This paper revisits an old approach to operating system construc-tion, the library OS, in a new context. The idea of the library OS is that the personality of the OS on which an application depends runs in the address space of the application. A small, fixed set of abstractions connects the library OS to the host OS kernel, offer-ing the promise of better system security and more rapid inde-pendent evolution of OS components. We describe a working prototype of a Windows 7 library OS that runs the latest releases of major applications such as Microsoft Excel, PowerPoint, and Internet Explorer. We demonstrate that desktop sharing across independent, securely isolated, library OS instances can be achieved through the pragmatic reuse of net-working protocols. Each instance has significantly lower overhead than a full VM bundled with an application: a typical application adds just 16MB of working set and 64MB of disk footprint. We contribute a new ABI below the library OS that enables applica-tion mobility. We also show that our library OS can address many of the current uses of hardware virtual machines at a fraction of the overheads. This paper describes the first working prototype of a full commercial OS redesigned as a library OS capable of run-ning significant applications. Our experience shows that the long-promised benefits of the library OS approach - better protection of system integrity and rapid system evolution - are readily ob-tainable. Copyright {\textcopyright} 2011 ACM.},
author = {Porter, Donald E. and Boyd-Wickizer, Silas and Howell, Jon and Olinsky, Reuben and Hunt, Galen C.},
booktitle = {ASPLOS'11},
doi = {10.1145/2248487.1950399},
file = {:F\:/D2/1950365.1950399.pdf:pdf},
issn = {15232867},
keywords = {Experimentation,Performance},
number = {4},
pages = {291--304},
title = {{Rethinking the library OS from the top down}},
volume = {47},
year = {2012}
}
@article{Lee2013,
abstract = {Kernel rootkits undermine the integrity of system by manipulating its operating system kernel. External hardware-based monitors can serve as a root of trust that is resilient to rootkit attacks. The existing external hardware-based approaches lack an event-triggered verification scheme for mutable kernel objects. To address the issue, we present KI-Mon, a hardware-based platform for event-triggered kernel integrity monitor. A refined form of bus traffic monitoring efficiently verifies the update values of the objects, and callback verification routines can be programmed and executed for a designated event space. We have built a KI-Mon prototype to demonstrate the efficacy of KI-Mon's event-triggered mechanism in terms of performance overhead for the monitored host system and the processor usage of the KI-Mon processor.},
author = {Lee, Hojoon and Moon, Hyungon and Jang, Daehee and Kim, Kihwan and Lee, Jihoon and Paek, Yunheung and Kang, Brent Byung Hoon},
file = {:F\:/D2/sec13-paper_lee.pdf:pdf},
isbn = {9781931971034},
journal = {Proceedings of the 22nd USENIX Security Symposium},
pages = {511--526},
title = {{KI-Mon: A hardware-assisted event-triggered monitoring platform for mutable kernel object}},
year = {2013}
}
@article{Jang2016,
abstract = {Kernel hardening has been an important topic since many applications and security mechanisms often consider the kernel as part of their Trusted Computing Base (TCB). Among various hardening techniques, Kernel Address Space Layout Randomization (KASLR) is the most effective and widely adopted defense mechanism that can practically mitigate various memory corruption vulnerabilities, such as buffer overfow and use-after-free. In principle, KASLR is secure as long as no memory leak vulnerability exists and high entropy is ensured. In this paper, we introduce a highly stable timing attack against KASLR, called DrK, that can precisely de-randomize the memory layout of the kernel without violating any such assumptions. DrK exploits a hardware feature called Intel Transactional Synchronization Extension (TSX) that is readily available in most modern commodity CPUs. One surprising behavior of TSX, which is essentially the root cause of this security loophole, is that it aborts a transaction without notifying the underlying kernel even when the transaction fails due to a critical error, such as a page fault or an access violation, which traditionally requires kernel intervention. DrK turned this property into a precise timing channel that can determine the mapping status (i.e., mapped versus unmapped) and execution status (i.e., executable versus non-executable) of the privileged kernel address space. In addition to its surprising accuracy and precision, DrK is universally applicable to all OSes, even in virtualized environments, and generates no visible footprint, making it diffcult to detect in practice. We demonstrated that DrK can break the KASLR of all major OSes (i.e., Windows, Linux, and OS X) with near-perfect accuracy in under a second. Finally, we propose potential countermeasures that can effectively prevent or mitigate the DrK attack. We urge our community to be aware of the potential threat of having Intel TSX, which is present in most recent Intel CPUs-100% in workstation and 60% in high-end Intel CPUs since Skylake- and is even available on Amazon EC2 (X1).},
author = {Jang, Yeongjin and Lee, Sangho and Kim, Taesoo},
doi = {10.1145/2976749.2978321},
file = {:F\:/D2/2976749.2978321.pdf:pdf},
isbn = {9781450341394},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
pages = {380--392},
title = {{Breaking Kernel Address Space Layout Randomization with Intel TSX}},
volume = {24-28-Octo},
year = {2016}
}
@article{Bauman2015,
abstract = {When designing computer monitoring systems, one goal has always been to have a complete view of the monitored target and at the same time stealthily protect the monitor itself. One way to achieve this is to use hypervisor-based, or more generally out of virtual machine (VM)-based, monitoring. There are, however, challenges that limit the use of this mechanism; the most significant of these is the semantic gap problem. Over the past decade, a considerable amount of research has been carried out to bridge the semantic gap and develop all kinds of out-of-VM monitoring techniques and applications. By tracing the evolution of out-of-VM security solutions, this article examines and classifies different approaches that have been proposed to overcome the semantic gap-the fundamental challenge in hypervisor-based monitoring-and how they have been used to develop various security applications. In particular, we review how the past approaches address different constraints, such as practicality, flexibility, coverage, and automation, while bridging the semantic gap; how they have developed different monitoring systems; and how the monitoring systems have been applied and deployed. In addition to systematizing all of the proposed techniques, we also discuss the remaining research problems and shed light on the future directions of hypervisor-based monitoring.. 2015. A survey on hypervisor-based monitoring: Approaches , applications, and evolutions.},
author = {Bauman, Erick and Ayoade, Gbadebo and Lin, Zhiqiang},
doi = {10.1145/2775111},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauman, Ayoade, Lin - 2015 - A Survey on Hypervisor-Based Monitoring Approaches, Applications, and Evolutions.pdf:pdf},
journal = {ACM Comput. Surv},
keywords = {D46 [Operating Systems]: Security and Protection G,VM,detection,hypervisor,in-tegrity,introspection,isolation,malware,monitoring,semantic gap,virtual machine monitor},
number = {10},
title = {{A Survey on Hypervisor-Based Monitoring: Approaches, Applications, and Evolutions}},
url = {http://dx.doi.org/10.1145/2775111},
volume = {48},
year = {2015}
}
@article{Torvalds2000,
author = {Torvalds, Linus},
file = {:F\:/D2/Keenlab-mosec2016.pdf:pdf},
journal = {slides},
title = {keenlab attack root slides},
url = {https://lkml.org/lkml/2000/8/25/132},
year = {2000}
}
@article{Li2018,
abstract = {The operating system kernel is often the security foundation for the whole system. To prevent attacks, control-flow integrity (CFI) has been proposed to ensure that any control transfer during the program's execution never deviates from its control-flow graph (CFG). Existing CFI solutions either work in user space or are coarse-grained; thus they cannot be readily deployed in kernels or are vulnerable to state-of-The-Art attacks. In this paper, we present Fine-CFI, a system that enforces fine-grained CFI for operating system kernels. Unlike previous systems, Fine-CFI constructs the kernel's fine-grained CFG with a retrofitted context-sensitive and field-sensitive pointer analysis, then enforces CFI with this CFG. At the same time, Fine-CFI provides comprehensive protection to the control data in the kernel's interrupt context. Combining the above two kinds of protection, we can thus defeat those formidable ret2usr and kernel code-reuse attacks. We have developed a compiler-based prototype and implemented this technique in Linux 3.14 kernel. Our evaluation indicates that Fine-CFI prevents all the gadgets found by an open-source gadget-finding tool from being misused, as well as all the attacks from the RIPE benchmark and malicious attempts to modify control data in the interrupt context; and it also reduces the number of indirect control-flow targets by 99.998%, thus largely raising the bar for attackers. Our evaluation also shows that the performance overhead introduced by Fine-CFI is less than 10% on average.},
author = {Li, Jinku and Tong, Xiaomeng and Zhang, Fengwei and Ma, Jianfeng},
doi = {10.1109/TIFS.2018.2797932},
file = {:F\:/papers/Li et al. - 2018 - Fine-cfi Fine-grained control-flow integrity for operating system kernels.pdf:pdf},
issn = {15566013},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {Control-flow integrity,Fine-grained,Intrusion prevention,Kernel protection},
number = {6},
pages = {1535--1550},
publisher = {IEEE},
title = {{Fine-cfi: Fine-grained control-flow integrity for operating system kernels}},
volume = {13},
year = {2018}
}
@article{Bai2019,
abstract = {In Linux device drivers, use-after-free (UAF) bugs can cause system crashes and serious security problems. According to our study of Linux kernel commits, 42% of the driver commits fixing use-after-free bugs involve driver concurrency. We refer to these use-after-free bugs as concurrency use-after-free bugs. Due to the non-determinism of concurrent execution, concurrency use-after-free bugs are often more difficult to reproduce and detect than sequential use-after-free bugs. In this paper, we propose a practical static analysis approach named DCUAF, to effectively detect concurrency use-after-free bugs in Linux device drivers. DCUAF combines a local analysis analyzing the source code of each driver with a global analysis statistically analyzing the local results of all drivers, forming a local-global analysis, to extract the pairs of driver interface functions that may be concurrently executed. Then, with these pairs, DCUAF performs a summary-based lockset analysis to detect concurrency use-after-free bugs. We have evaluated DCUAF on the driver code of Linux 4.19, and found 640 real concurrency use-after-free bugs. We have randomly selected 130 of the real bugs and reported them to Linux kernel developers, and 95 have been confirmed.},
author = {Bai, Jia Ju and Lawall, Julia and Chen, Qiu Liang and Hu, Shi Min},
file = {:F\:/D2/atc19-bai.pdf:pdf},
isbn = {9781939133038},
journal = {Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019},
pages = {255--268},
title = {{Effective static analysis of concurrency use-after-free bugs in Linux device drivers}},
year = {2019}
}
@inproceedings{Cao2019,
abstract = {The use of uninitialized variables is a common issue. It could cause kernel information leak, which defeats the widely deployed security defense, i.e., kernel address space layout randomization (KASLR). Though a recent system called Bochspwn Reloaded reported multiple memory leaks in Windows kernels, how to effectively detect this issue is still largely behind. In this paper, we propose a new technique, i.e., differential replay, that could effectively detect the use of uninitialized variables. Specifically, it records and replays a program's execution in multiple instances. One instance is with the vanilla memory, the other one changes (or poisons) values of variables allocated from the stack and the heap. Then it compares program states to find references to uninitialized variables. The idea is that if a variable is properly initialized, it will overwrite the poisoned value and program states in two running instances should be the same. After detecting the differences, our system leverages the symbolic taint analysis to further identify the location where the variable was allocated. This helps us to identify the root cause and facilitate the development of real exploits. We have implemented a prototype called TimePlayer. After applying it to both Windows 7 and Windows 10 kernels (x86/x64), it successfully identified 34 new issues and another 85 ones that had been patched (some of them were publicly unknown.) Among 34 new issues, 17 of them have been confirmed as zero-day vulnerabilities by Microsoft.},
author = {Cao, Mengchen and Qu, Hunter and Hou, Xiantong and Zhou, Yajin and Wang, Fuwei and Wang, Tao and Bai, Xiaolong},
booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
doi = {10.1145/3319535.3345654},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2019 - Different is good Detecting the use of uninitialized variables through differential replay.pdf:pdf},
isbn = {9781450367479},
issn = {15437221},
pages = {1883--1897},
title = {{Different is good: Detecting the use of uninitialized variables through differential replay}},
year = {2019}
}
@article{Azab2011,
abstract = {SICE is a novel framework to provide hardware-level isolation and protection for sensitive workloads running on ×86 platforms in compute clouds. Unlike existing isolation techniques, SICE does not rely on any software component in the host environment (i.e., an OS or a hypervisor). Instead, the security of the isolated environments is guaranteed by a trusted computing base that only includes the hardware, the BIOS, and the System Management Mode (SMM). SICE provides fast context switching to and from an isolated environment, allowing isolated workloads to time-share the physical platform with untrusted workloads. Moreover, SICE supports a large range (up to 4GB) of isolated memory. Finally, the most unique feature of SICE is the use of multi-core processors to allow the isolated environments to run concurrently and yet securely beside the untrusted host. We have implemented a SICE prototype using an AMD x86 hardware platform. Our experiments show that SICE performs fast context switching (67 $\mu$s) to and from the isolated environment and that it imposes a reasonable overhead (3% on all but one benchmark) on the operation of an isolated Linux virtual machine. Our prototype demonstrates that, subject to a careful security review of the BIOS software and the SMM hardware implementation, current hardware architecture already provides abstractions that can support building strong isolation mechanisms using a very small SMM software foundation of about 300 lines of code. {\textcopyright} 2011 ACM.},
author = {Azab, Ahmed M. and Ning, Peng and Zhang, Xiaolan},
doi = {10.1145/2046707.2046752},
file = {:F\:/D2/2046707.2046752.pdf:pdf},
isbn = {9781450310758},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Isolation,Trusted computing,Virtualization security},
pages = {375--388},
title = {{SICE: A hardware-level strongly isolated computing environment for x86 multi-core platforms}},
year = {2011}
}
@article{Dautenhahn2015,
abstract = {Monolithic operating system designs undermine the security of computing systems by allowing single exploits anywhere in the kernel to enjoy full supervisor privilege. The nested kernel operating system architecture addresses this problem by "nesting" a small isolated kernel within a traditional monolithic kernel. The "nested kernel" interposes on all updates to virtual memory translations to assert protections on physical memory, thus significantly reducing the trusted computing base for memory access control enforcement. We incorporated the nested kernel architecture into FreeBSD on x86-64 hardware while allowing the entire operating system, including untrusted components, to operate at the highest hardware privilege level by write-protecting MMU translations and de-privileging the untrusted part of the kernel. Our implementation inherently enforces kernel code integrity while still allowing dynamically loaded kernel modules, thus defending against code injection attacks. We also demonstrate that the nested kernel architecture allows kernel developers to isolate memory in ways not possible in monolithic kernels by introducing write-mediation and write-logging services to protect critical system data structures. Performance of the nested kernel prototype shows modest overheads: < 1% average for Apache and 2.7% for kernel compile. Overall, our results and experience show that the nested kernel design can be retrofitted to existing monolithic kernels, providing important security benefits.},
author = {Dautenhahn, Nathan and Kasampalis, Theodoros and Dietz, Will and Criswell, John and Adve, Vikram},
doi = {10.1145/2694344.2694386},
file = {:F\:/D2/2694344.2694386.pdf:pdf},
isbn = {9781450328357},
issn = {15232867},
journal = {ACM SIGPLAN Notices},
keywords = {Intra-kernel isolation,Malicious operating systems,Operating system architecture,Virtual memory},
number = {4},
pages = {191--206},
title = {{Nested kernel: An operating system architecture for intra-kernel privilege separation}},
volume = {50},
year = {2015}
}
@article{Kimmelman2005,
abstract = {The therapeutic misconception arises wherever human subjects misinterpret the primary purpose of a clinical trial as therapeutic. Such misconceptions are particularly prevalent in trials involving severely ill subjects or novel and well-publicized investigational agents. In order to identify possible sources of the therapeutic misconception in gene transfer trials, 286 phase 1 human gene transfer consent documents were analyzed for their description of purpose, alternatives, and their use of the term gene transfer. We report that 20% of trials fail to explain their purpose as safety and dosage, only 41% of oncology trials identify comfort care as an alternative to participation, and that the term gene therapy is used with twice the frequency of the term gene transfer. Trends and coherence in consent form language were analyzed as well. Our results indicate that consent forms used in gene transfer phase 1 trials often contain language that promotes, or does little to deter, therapeutic misconceptions. {\textcopyright} Mary Ann Liebert, Inc.},
author = {Kimmelman, Jonathan and Levenstadt, Aaron},
doi = {10.1089/hum.2005.16.502},
file = {:F\:/D2/elos.pdf:pdf},
issn = {10430342},
journal = {Human Gene Therapy},
number = {4},
pages = {502--508},
pmid = {15871681},
title = {{Elements of style: Consent form language and the therapeutic misconception in phase 1 gene transfer trials}},
volume = {16},
year = {2005}
}
@article{Gershuni2019,
abstract = {Extended Berkeley Packet Filter (eBPF) is a Linux subsystem that allows safely executing untrusted user-defined extensions inside the kernel. It relies on static analysis to protect the kernel against buggy and malicious extensions. As the eBPF ecosystem evolves to support more complex and diverse extensions, the limitations of its current verifier, including high rate of false positives, poor scalability, and lack of support for loops, have become a major barrier for developers. We design a static analyzer for eBPF within the framework of abstract interpretation. Our choice of abstraction is based on common patterns found in many eBPF programs. We observed that eBPF programs manipulate memory in a rather disciplined way which permits analyzing them successfully with a scalable mixture of very-precise abstraction of certain bounded regions with coarser abstractions of other parts of the memory. We use the Zone domain, a simple domain that tracks differences between pairs of registers and offsets, to achieve precise and scalable analysis. We demonstrate that this abstraction is as precise in practice as more costly abstract domains like Octagon and Polyhedra. Furthermore, our evaluation, based on hundreds of real-world eBPF programs, shows that the new tool generates no more false alarms than the existing Linux verifier, while it supports a wider class of programs (including programs with loops) and has better asymptotic complexity.},
author = {Gershuni, Elazar and Narodytska, Nina and Amit, Nadav and Navas, Jorge A. and Gurfinkel, Arie and Rinetzky, Noam and Ryzhyk, Leonid and Sagiv, Mooly},
doi = {10.1145/3314221.3314590},
file = {:F\:/papers/3314221.3314590.pdf:pdf},
isbn = {9781450367127},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
keywords = {Ebpf,Kernel extensions,Linux,Static analysis},
pages = {1069--1084},
title = {{Simple and precise static analysis of untrusted Linux kernel extensions}},
year = {2019}
}
@article{Rostedt2010,
author = {Rostedt, Steven},
file = {:F\:/papers/linuxcon_jp2010_rostedt.pdf:pdf},
title = {{Ftrace Linux Kernel Tracing Who am I ?}},
year = {2010}
}
@article{Xu2018a,
abstract = {Code virtualization is a highly sophisticated obfuscation technique adopted by malware authors to stay under the radar. However, the increasing complexity of code virtualization also becomes a “double-edged sword” for practical application. Due to its performance limitations and compatibility problems, code virtualization is seldom used on an entire program. Rather, it is mainly used only to safeguard the key parts of code such as security checks and encryption keys. Many techniques have been proposed to reverse engineer the virtualized code, but they share some common limitations. They assume the scope of virtualized code is known in advance and mainly focus on the classic structure of code emulator. Also, few work verifies the correctness of their deobfuscation results. In this paper, with fewer assumptions on the type and scope of code virtualization, we present a verifiable method to address the challenge of partially-virtualized binary code simplification. Our key insight is that code virtualization is a kind of process-level virtual machine (VM), and the context switch patterns when entering and exiting the VM can be used to detect the VM boundaries. Based on the scope of VM boundary, we simplify the virtualized code. We first ignore all the instructions in a given virtualized snippet that do not affect the final result of that snippet. To better revert the data obfuscation effect that encodes a variable through bitwise operations, we then run a new symbolic execution called multiple granularity symbolic execution to further simplify the trace snippet. The generated concise symbolic formulas facilitate the correctness testing of our simplification results. We have implemented our idea as an open source tool, VMHunt, and evaluated it with real-world applications and malware. The encouraging experimental results demonstrate that VMHunt is a significant improvement over the state of the art.},
author = {Xu, Dongpeng and Ming, Jiang and Fu, Yu and Wu, Dinghao},
doi = {10.1145/3243734.3243827},
file = {:F\:/papers/Xu et al. - 2018 - VMhunt A verifiable approach to partially-virtualized binary code simplification.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Binary Analysis,Code Virtualization,De-obfuscation,Multiple Granularity Symbolic Execution},
pages = {442--458},
title = {{VMhunt: A verifiable approach to partially-virtualized binary code simplification}},
year = {2018}
}
@article{Bennieston2009,
author = {Bennieston, Andrew J},
file = {:F\:/D2/scidoc.pdf:pdf},
journal = {Society},
pages = {1--12},
title = {{Writing Scientific Documents Using L E Starting a L}},
year = {2009}
}
@book{Silvestro,
abstract = {Due to the ongoing threats posed by heap vulnerabili-ties, we design a novel secure allocator-GUARDER-to defeat these vulnerabilities. GUARDER is different from existing secure allocators in the following aspects. Existing allocators either have low/zero randomization entropy, or cannot provide stable security guarantees, where their entropies vary by object size classes, execution phases, inputs, or applications. GUARDER ensures the desired randomization entropy, and provides an unprecedented level of security guarantee by combining all security features of existing allocators, with overhead that is comparable to performance-oriented allocators. Compared to the default Linux allocator, GUARDER's performance overhead is less than 3% on average. This overhead is similar to the previous state-of-the-art, Free-Guard, but comes with a much stronger security guarantee. GUARDER also provides an additional feature that allows users to customize security based on their performance budget, without changing code or even recompil-ing. The combination of high security and low overhead makes GUARDER a practical solution for the deployed environment.},
author = {Silvestro, Sam and Liu, Hongyu and Liu, Tianyi and Lin, Zhiqiang and Liu, Tongping},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silvestro et al. - Unknown - GUARDER A Tunable Secure Allocator.pdf:pdf},
isbn = {978-1-939133-04-5},
title = {{GUARDER: A Tunable Secure Allocator}},
url = {https://www.usenix.org/conference/usenixsecurity18/presentation/silvestro}
}
@article{Panwar2018,
abstract = {The virtual-to-physical address translation overhead, a major performance bottleneck for modern workloads, can be effectively alleviated with huge pages. However, since huge pages must be mapped contiguously, OSs have not been able to use them well because of the memory fragmentation problem despite hardware support for huge pages being available for nearly two decades. This paper presents a comprehensive study of the interaction of fragmentation with huge pages in the Linux kernel. We observe that when huge pages are used, problems such as high CPU utilization and latency spikes occur because of unnecessary work (e.g., useless page migration) performed by memory management related subsystems due to the poor handling of unmovable (i.e., kernel) pages. This behavior is even more harmful in virtualized systems where unnecessary work may be performed in both guest and host OSs. We present Illuminator, an efficient memory manager that provides various subsystems, such as the page allocator, the ability to track all unmovable pages. It allows subsystems to make informed decisions and eliminate unnecessary work which in turn leads to cost-effective huge page allocations. Illuminator reduces the cost of compaction (up to 99%), improves application performance (up to 2.3x) and reduces the maximum latency of MySQL database server (by 30x). Importantly, this work shows the effectiveness of a simple solution for long-standing huge page related problems.},
author = {Panwar, Ashish and Prasad, Aravinda and Gopinath, K.},
doi = {10.1145/3296957.3173203},
file = {:F\:/D2/3173162.3173203.pdf:pdf},
isbn = {9781450349116},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Address Translation,Huge Pages,Memory Compaction,Memory Fragmentation,address translation,huge pages,memory compaction,memory fragmentation},
number = {2},
pages = {679--692},
title = {{Making Huge Pages Actually Useful}},
volume = {53},
year = {2018}
}
@book{Huang,
abstract = {We present a comprehensive and quantitative study on the development of the Linux memory manager. The study examines 4587 committed patches over the last five years (2009-2015) since Linux version 2.6.32. Insights derived from this study concern the development process of the virtual memory system, including its patch distribution and patterns, and techniques for memory optimizations and semantics. Specifically, we find that the changes to memory manager are highly centralized around the key functionalities, such as memory alloca-tor, page fault handler and memory resource controller. The well-developed memory manager still suffers from increasing number of bugs unexpectedly. And the memory optimizations mainly focus on data structures, memory policies and fast path. To the best of our knowledge, this is the first such study on the virtual memory system.},
author = {Huang, Jian and Qureshi, Moinuddin K and Schwan, Karsten},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Qureshi, Schwan - Unknown - An Evolutionary Study of Linux Memory Management for Fun and Profit.pdf:pdf},
isbn = {978-1-931971-30-0},
pages = {465},
title = {{An Evolutionary Study of Linux Memory Management for Fun and Profit}},
url = {https://www.usenix.org/conference/atc16/technical-sessions/presentation/huang}
}
@article{Machiry2017,
abstract = {—In the past decade, we have come to rely on comput-ers for various safety and security-critical tasks, such as securing our homes, operating our vehicles, and controlling our finances. To facilitate these tasks, chip manufacturers have begun including trusted execution environments (TEEs) in their processors, which enable critical code (e.g., cryptographic functions) to run in an isolated hardware environment that is protected from the traditional operating system (OS) and its applications. While code in the untrusted environment (e.g., Android or Linux) is forbidden from accessing any memory or state within the TEE, the code running in the TEE, by design, has unrestricted access to the memory of the untrusted OS and its applications. However, due to the isolation between these two environments, the TEE has very limited visibility into the untrusted environment's security mechanisms (e.g., kernel vs. application memory). In this paper, we introduce BOOMERANG, a class of vulner-abilities that arises due to this semantic separation between the TEE and the untrusted environment. These vulnerabilities permit untrusted user-level applications to read and write any memory location in the untrusted environment, including security-sensitive kernel memory, by leveraging the TEE's privileged position to perform the operations on its behalf. BOOMERANG can be used to steal sensitive data from other applications, bypass security checks, or even gain full control of the untrusted OS. To quantify the extent of this vulnerability, we developed an automated framework for detecting BOOMERANG bugs within the TEEs of popular mobile phones. Using this framework, we were able to confirm the existence of BOOMERANG on four different TEE platforms, affecting hundreds of millions of devices on the market today. Moreover, we confirmed that, in at least two instances, BOOMERANG could be leveraged to completely compromise the untrusted OS (i.e., Android). While the implications of these vulnerabilities are severe, defenses can be quickly implemented by vendors, and we are currently in contact with the affected TEE vendors to deploy adequate fixes. To this end, we evaluated the two most promising defense proposals and their inherent trade-offs. This analysis led the proposal of a novel BOOMERANG defense, addressing the major shortcomings of the existing defenses with minimal performance overhead. Our findings have been reported to and verified by the corresponding vendors, who are currently in the process of creating security patches.},
author = {Machiry, Aravind and Gustafson, Eric and Spensky, Chad and Salls, Christopher and Stephens, Nick and Wang, Ruoyu and Bianchi, Antonio and Choe, Yung Ryn and Kruegel, Christopher and Vigna, Giovanni},
doi = {10.14722/ndss.2017.23227},
file = {:F\:/papers/ndss2017_07-3_Machiry_paper.pdf:pdf},
isbn = {1891562460},
number = {March},
title = {{BOOMERANG: Exploiting the Semantic Gap in Trusted Execution Environments}},
year = {2017}
}
@book{Nosco,
abstract = {There is a cognitive bias in the hacker community to select a piece of software and invest significant human resources into finding bugs in that software without any prior indication of success. We label this strategy depth-first search and propose an alternative: breadth-first search. In breadth-first search, humans perform minimal work to enable automated analysis on a range of targets before committing additional time and effort to research any particular one. We present a repeatable human study that leverages teams of varying skill while using automation to the greatest extent possible. Our goal is a process that is effective at finding bugs; has a clear plan for the growth, coaching, and efficient use of team members; and supports measurable , incremental progress. We derive an assembly-line process that improves on what was once intricate, manual work. Our work provides evidence that the breadth-first approach increases the effectiveness of teams.},
author = {Nosco, Timothy and Clark, Zechariah and Marrero, Davy and Nosco, Tim and Ziegler, Jared and Barbarello, Andrew and Petullo, W Michael},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nosco et al. - Unknown - The Industrial Age of Hacking(2).pdf:pdf},
isbn = {9781939133175},
keywords = {Andrew Barbarello, United States Navy,Todd Finkler, United States Air Force,United States Navy,W Michael Petullo, United States Army},
title = {{The Industrial Age of Hacking}},
url = {https://www.usenix.org/conference/usenixsecurity20/presentation/nosco}
}
@article{VanDerVeen2012,
abstract = {Memory error exploitations have been around for over 25 years and still rank among the top 3 most dangerous software errors. Why haven't we been able to stop them? Given the host of security measures on modern machines, are we less vulnerable than before, and can we expect to eradicate memory error problems in the near future? In this paper, we present a quarter century worth of memory errors: attacks, defenses, and statistics. A historical overview provides insights in past trends and developments, while an investigation of real-world vulnerabilities and exploits allows us to answer on the significance of memory errors in the foreseeable future. {\textcopyright} 2012 Springer-Verlag.},
author = {{Van Der Veen}, Victor and Dutt-Sharma, Nitish and Cavallaro, Lorenzo and Bos, Herbert},
doi = {10.1007/978-3-642-33338-5_5},
file = {:F\:/D2/Veen2012_Chapter_MemoryErrorsThePastThePresentA.pdf:pdf},
isbn = {9783642333378},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {86--106},
title = {{Memory errors: The past, the present, and the future}},
volume = {7462 LNCS},
year = {2012}
}
@techreport{Giuffrida,
abstract = {In recent years, the deployment of many application-level countermeasures against memory errors and the increasing number of vulnerabilities discovered in the kernel has fostered a renewed interest in kernel-level exploitation. Unfortunately, no comprehensive and well-established mechanism exists to protect the operating system from arbitrary attacks, due to the relatively new development of the area and the challenges involved. In this paper, we propose the first design for fine-grained address space randomization (ASR) inside the operating system (OS), providing an efficient and comprehensive countermeasure against classic and emerging attacks, such as return-oriented programming. To motivate our design, we investigate the differences with application-level ASR and find that some of the well-established assumptions in existing solutions are no longer valid inside the OS; above all, perhaps, that information leakage becomes a major concern in the new context. We show that our ASR strategy outperforms state-of-the-art solutions in terms of both performance and security without affecting the software distribution model. Finally, we present the first comprehensive live reran-domization strategy, which we found to be particularly important inside the OS. Experimental results demonstrate that our techniques yield low run-time performance overhead (less than 5% on average on both SPEC and syscall-intensive benchmarks) and limited run-time memory footprint increase (around 15% during the execution of our benchmarks). We believe our techniques can greatly enhance the level of OS security without compromising the performance and reliability of the OS.},
author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Giuffrida, Kuijsten, Tanenbaum - Unknown - Enhanced Operating System Security Through Efficient and Fine-grained Address Space Randomiza.pdf:pdf},
title = {{Enhanced Operating System Security Through Efficient and Fine-grained Address Space Randomization}}
}
@article{Motakis2014,
abstract = {VFIO (Virtual Function I/O) is a Linux kernel infrastructure that allows to leverage the capabilities of modern IOMMUs to drive a device directly from user space without any additional specialized kernel driver being involved. When used by QEMU/KVM, a device can be assigned to a guest VM, allowing to transparently handle all aspects of communication with the device, including DMA mapping, MMIO range mapping, and interrupts. To support a given hardware architecture and device, VFIO will need to be able to support the type of IOMMU that is in front of the device, and the discovery and configuration mechanisms of the bus that the device is connected to. However, often no auto configuration interface is exposed on ARM, as opposed to devices on a PCI bus, commonly used on x86. In order to support VFIO on ARM, in this work platform devices support is being implemented as a VFIO-PLATFORM driver. Additionally, VFIO is being extended to support common IOMMUs found on ARM systems, such as the ARM SMMU. In this paper, we highlight the challenges met while implementing the required components, and extensions to VFIO and KVM in order to fully support device assignment to Virtual Machines on modern ARM systems.},
author = {Motakis, Antonios and Rigo, Alvise and Raho, Daniel},
doi = {10.1109/EUC.2014.32},
file = {:F\:/D2/06962282.pdf:pdf},
isbn = {9780769552491},
journal = {Proceedings - 2014 International Conference on Embedded and Ubiquitous Computing, EUC 2014},
keywords = {arm,device assignment,device passthrough,iommu,kvm,qemu,vfio,virtualization},
pages = {170--177},
publisher = {IEEE},
title = {{Platform Device Assignment to KVM-on-ARM Virtual Machines via VFIO}},
year = {2014}
}
@article{Lozi,
abstract = {As a central part of resource management, the OS thread scheduler must maintain the following, simple, invariant: make sure that ready threads are scheduled on available cores. As simple as it may seem, we found that this invariant is often broken in Linux. Cores may stay idle for seconds while ready threads are waiting in runqueues. In our experiments, these performance bugs caused many-fold performance degradation for synchronization-heavy scientific applications, 13% higher latency for kernel make, and a 14-23% decrease in TPC-H throughput for a widely used commercial database. The main contribution of this work is the discovery and analysis of these bugs and providing the fixes. Conventional testing techniques and debugging tools are ineffective at confirming or understanding this kind of bugs, because their symptoms are often evasive. To drive our investigation , we built new tools that check for violation of the invariant online and visualize scheduling activity. They are simple, easily portable across kernel versions, and run with a negligible overhead. We believe that making these tools part of the kernel developers' tool belt can help keep this type of bug at bay.},
author = {Lozi, Jean-Pierre and {Lepers EPFL}, Baptiste and Funston, Justin and Gaud, Fabien and Qu{\'{e}}ma, Vivien and Fedorova, Alexandra},
doi = {10.1145/2901318.2901326},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lozi et al. - Unknown - The Linux Scheduler a Decade of Wasted Cores.pdf:pdf},
isbn = {9781450342407},
title = {{The Linux Scheduler: a Decade of Wasted Cores}},
url = {http://dx.doi.org/10.1145/2901318.2901326}
}
@article{Yee2010,
abstract = {Native Client is a sandbox for untrusted x86 native code. It aims to give browser-based applications the computational performance of native applications without compromising safety. Native Client uses software fault isolation and a secure runtime to direct system interaction and side effects through interfaces it controls. It further provides operating system portability for binary code while supporting performance-oriented features generally absent from Web application programming environments, such as thread support, instruction set extensions such as SSE, and use of compiler intrinsics and hand-coded assembler. We combine these properties in an open architecture thatencourages community review and third-party tools. {\textcopyright} 2010 ACM.},
author = {Yee, Bennet and Sehr, David and Dardyk, Gregory and Chen, J. Bradley and Muth, Robert and Ormandy, Tavis and Okasaka, Shiki and Narula, Neha and Fullagar, Nicholas},
doi = {10.1145/1629175.1629203},
file = {:F\:/papers/Yee et al. - 2010 - Native client A sandbox for portable, untrusted x86 native code.pdf:pdf},
isbn = {9780769536330},
issn = {00010782},
journal = {Communications of the ACM},
number = {1},
pages = {91--99},
publisher = {IEEE},
title = {{Native client: A sandbox for portable, untrusted x86 native code}},
volume = {53},
year = {2010}
}
@article{Song2019,
abstract = {The C and C++ programming languages are notoriously insecure yet remain indispensable. Developers therefore resort to a multi-pronged approach to find security issues before adversaries. These include manual, static, and dynamic program analysis. Dynamic bug finding tools - henceforth 'sanitizers' - can find bugs that elude other types of analysis because they observe the actual execution of a program, and can therefore directly observe incorrect program behavior as it happens. A vast number of sanitizers have been prototyped by academics and refined by practitioners. We provide a systematic overview of sanitizers with an emphasis on their role in finding security issues. Specifically, we taxonomize the available tools and the security vulnerabilities they cover, describe their performance and compatibility properties, and highlight various trade-offs.},
archivePrefix = {arXiv},
arxivId = {1806.04355},
author = {Song, Dokyung and Lettner, Julian and Rajasekaran, Prabhu and Na, Yeoul and Volckaert, Stijn and Larsen, Per and Franz, Michael},
doi = {10.1109/SP.2019.00010},
eprint = {1806.04355},
file = {:F\:/D2/08835294.pdf:pdf},
isbn = {9781538666609},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Computer-Bugs,Security,Software-Safety,System-Software},
pages = {1275--1295},
publisher = {IEEE},
title = {{SoK: Sanitizing for security}},
volume = {2019-May},
year = {2019}
}
@article{Chen2021,
author = {Chen, Kaixiang and Zhang, Chao and Yin, Tingting and Chen, Xingman and Zhao, Lei},
file = {:F\:/D2/sec21fall-chen-kaixiang.pdf:pdf},
journal = {30th {USENIX} Security Symposium ({USENIX} Security 21)},
number = {1},
title = {{VScape: Assessing and Escaping Virtual Call Protections}},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/chen-kaixiang},
year = {2021}
}
@article{Pomonis,
author = {Pomonis, Marios},
file = {:F\:/D2/3064176.3064216.pdf:pdf},
isbn = {9781450349383},
keywords = {code diversification,execute-only memory},
title = {{kR ^ X : Comprehensive Kernel Protection against Just-In-Time Code Reuse}}
}
@article{Spinellis2021,
abstract = {Unix has evolved for almost five decades, shaping modern operating systems, key software technologies, and development practices. Studying the evolution of this remarkable system from an architectural perspective can provide insights on how to manage the growth of large, complex, and long-lived software systems. Along main Unix releases leading to the FreeBSD lineage we examine core architectural design decisions, the number of features, and code complexity, based on the analysis of source code, reference documentation, and related publications. We report that the growth in size has been uniform, with some notable outliers, while cyclomatic complexity has been religiously safeguarded. A large number of Unix-defining design decisions were implemented right from the very early beginning, with most of them still playing a major role. Unix continues to evolve from an architectural perspective, but the rate of architectural innovation has slowed down over the system's lifetime. Architectural technical debt has accrued in the forms of functionality duplication and unused facilities, but in terms of cyclomatic complexity it is systematically being paid back through what appears to be a self-correcting process. Some unsung architectural forces that shaped Unix are the emphasis on conventions over rigid enforcement, the drive for portability, a sophisticated ecosystem of other operating systems and development organizations, and the emergence of a federated architecture, often through the adoption of third-party subsystems. These findings have led us to form an initial theory on the architecture evolution of large, complex operating system software.},
author = {Spinellis, Diomidis and Avgeriou, Paris},
doi = {10.1109/TSE.2019.2892149},
file = {:F\:/D2/Evolution_of_the_Unix_System_Architecture_An_Exploratory_Case_Study.pdf:pdf},
issn = {19393520},
journal = {IEEE Transactions on Software Engineering},
keywords = {Unix,architecture design decisions,operating systems,software architecture,software evolution},
number = {6},
pages = {1134--1163},
publisher = {IEEE},
title = {{Evolution of the Unix System Architecture: An Exploratory Case Study}},
volume = {47},
year = {2021}
}
@article{LeVasseur2004,
abstract = {We propose a method to reuse unmodified device drivers and to improve system dependability using virtual machines. We run the unmodified device driver, with its original operating system, in a virtual machine. This approach enables extensive reuse of existing and unmodified drivers, independent of the OS or device vendor, significantly reducing the barrier to building new OS endeavors. By allowing distinct device drivers to reside in separate virtual machines, this technique isolates faults caused by defective or malicious drivers, thus improving a system's dependability. We show that our technique requires minimal support infrastructure and provides strong fault isolation. Our prototype's network performance is within 3–8% of a native Linux system. Each additional virtual machine increases the CPU utilization by about 0.12%. We have successfully reused a wide variety of unmodified Linux network, disk, and PCI device drivers.},
author = {LeVasseur, Joshua and Uhlig, Volkmar and Stoess, Jan and G{\"{o}}tz, Stefan},
file = {:F\:/D2/levasseur.pdf:pdf},
journal = {OSDI 2004 - 6th Symposium on Operating Systems Design and Implementation},
pages = {17--30},
title = {{Unmodified device driver reuse and improved system dependability via virtual machines}},
year = {2004}
}
@article{Reserved2001,
abstract = {Virtual machines were developed by IBM in the 1960's to provide concurrent, interactive access to a mainframe computer. Each virtual machine is a replica of the un- derlying physical machine and users are given the illu- sion of running directly on the physical machine. Virtual machines also provide benefits like isolation and resource sharing, and the ability to run multiple flavors and con- ?? figurations of operating systems. VMware Workstation brings such mainframe-class virtual machine technology to PC-based desktop and workstation computers.},
author = {Reserved, All Rights},
doi = {10.1109/msp.2009.28},
file = {:F\:/D2/usenix_io_devices.pdf:pdf},
issn = {1540-7993},
journal = {IEEE Security & Privacy Magazine},
number = {2},
pages = {c4--c4},
title = {{Virtualizing I/O Devices on VMware Workstation's Hosted Virtual Machine Monitor Jeremy}},
volume = {7},
year = {2001}
}
@article{Koning2017,
abstract = {As modern 64-bit x86 processors no longer support the segmentation capabilities of their 32-bit predecessors, most research projects assume that strong in-process memory isolation is no longer an affordable option. Instead of strong, deterministic isolation, new defense systems therefore rely on the probabilistic pseudo-isolation provided by randomization to "hide" sensitive (or safe) regions. However, recent attacks have shown that such protection is insufficient; attackers can leak these safe regions in a variety of ways. In this paper, we revisit isolation for x86-64 and argue that hardware features enabling efficient deterministic isolation do exist. We first present a comprehensive study on commodity hardware features that can be repurposed to isolate safe regions in the same address space (e.g., Intel MPX and MPK).We then introduce MemSentry, a framework to harden modern defense systems with commodity hardware features instead of information hiding. Our results show that some hardware features are more effective than others in hardening such defenses in each scenario and that features originally conceived for other purposes (e.g., Intel MPX for bounds checking) are surprisingly efficient at isolating safe regions compared to their software equivalent (i.e., SFI).},
author = {Koning, Koen and Chen, Xi and Bos, Herbert and Giuffrida, Cristiano and Athanasopoulos, Elias},
doi = {10.1145/3064176.3064217},
file = {:F\:/D2/3064176.3064217.pdf:pdf},
isbn = {9781450349383},
journal = {Proceedings of the 12th European Conference on Computer Systems, EuroSys 2017},
keywords = {Hardware features,Information hiding,Isolation,Software fault isolation},
pages = {437--452},
title = {{No need to hide: Protecting safe regions on commodity hardware}},
year = {2017}
}
@article{Hu2018,
abstract = {The goal of control-flow integrity (CFI) is to stop control-hijacking attacks by ensuring that each indirect control-flow transfer (ICT) jumps to its legitimate target. However, existing implementations of CFI have fallen short of this goal because their approaches are inaccurate and as a result, the set of allowable targets for an ICT instruction is too large, making illegal jumps possible. In this paper, we propose the Unique Code Target (UCT) property for CFI. Namely, for each invocation of an ICT instruction, there should be one and only one valid target. We develop a prototype called CFI to enforce this new property. During compilation, CFI identifies the sensitive instructions that influence ICT and instruments the program to record necessary execution context. At runtime, CFI monitors the program execution in a different process, and performs points-to analysis by interpreting sensitive instructions using the recorded execution context in a memory safe manner. It checks runtime ICT targets against the analysis results to detect CFI violations. We apply CFI to SPEC benchmarks and 2 servers (nginx and vsftpd) to evaluate its efficacy of enforcing UCT and its overhead. We also test CFI against control-hijacking attacks, including 5 real-world exploits, 1 proof of concept COOP attack, and 2 synthesized attacks that bypass existing defenses. The results show that CFI strictly enforces the UCT property for protected programs, successfully detects all attacks, and introduces less than 10% performance overhead.},
author = {Hu, Hong and Qian, Chenxiong and Yagemann, Carter and Chung, Simon Pak Ho and Harris, William R. and Kim, Taesoo and Lee, Wenke},
doi = {10.1145/3243734.3243797},
file = {:F\:/papers/Hu et al. - 2018 - Enforcing unique code target property for control-flow integrity.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Control-flow integrity,Intel PT,Performance,Unique code target},
pages = {1470--1486},
title = {{Enforcing unique code target property for control-flow integrity}},
year = {2018}
}
@article{Banerjee2021,
abstract = {Hardware performance counters (HPCs) that measure low-level architectural and microarchitectural events provide dynamic con-textual information about the state of the system. However, HPC measurements are error-prone due to non determinism (e.g., un-dercounting due to event multiplexing, or OS interrupt-handling behaviors). In this paper, we present BayesPerf, a system for quantifying uncertainty in HPC measurements by using a domain-driven Bayesian model that captures microarchitectural relationships between HPCs to jointly infer their values as probability distributions. We provide the design and implementation of an accelerator that allows for low-latency and low-power inference of the BayesPerf model for x86 and ppc64 CPUs. BayesPerf reduces the average error in HPC measurements from 40.1% to 7.6% when events are being multiplexed. The value of BayesPerf in real-time decision-making is illustrated with a simple example of scheduling of PCIe transfers. CCS CONCEPTS • General and reference → Performance; Measurement; • Hardware → Error detection and error correction; Hardware accelerators; • Computing methodologies → Learning in probabilistic graphical models.},
author = {Banerjee, Subho S and Jha, Saurabh and Kalbarczyk, Zbigniew and Iyer, Ravishankar K},
doi = {10.1145/3445814.3446739},
isbn = {9781450383172},
keywords = {Accelerator,Error Correction,Error Detection,Performance Counter,Probabilistic Graphical Model,Sampling Errors},
publisher = {ACM},
title = {{BayesPerf: Minimizing Performance Monitoring Errors using Bayesian Statistics; BayesPerf: Minimizing Performance Monitoring Errors using Bayesian Statistics}},
url = {https://doi.org/10.1145/3445814.3446739},
year = {2021}
}
@article{Chen2019,
abstract = {To determine the exploitability for a kernel vulnerability, a security analyst usually has to manipulate slab and thus demonstrate the capability of obtaining the control over a program counter or performing privilege escalation. However, this is a lengthy process because (1) an analyst typically has no clue about what objects and system calls are useful for kernel exploitation and (2) he lacks the knowledge of manipulating a slab and obtaining the desired layout. In the past, researchers have proposed various techniques to facilitate exploit development. Unfortunately, none of them can be easily applied to address these challenges. On the one hand, this is because of the complexity of the Linux kernel. On the other hand, this is due to the dynamics and non-deterministic of slab variations. In this work, we tackle the challenges above from two perspectives. First, we use static and dynamic analysis techniques to explore the kernel objects, and the corresponding system calls useful for exploitation. Second, we model commonly-adopted exploitation methods and develop a technical approach to facilitate the slab layout adjustment. By extending LLVM as well as Syzkaller, we implement our techniques and name their combination after SLAKE. We evaluate SLAKE by using 27 real-world kernel vulnerabilities, demonstrating that it could not only diversify the ways to perform kernel exploitation but also sometimes escalate the exploitability of kernel vulnerabilities.},
author = {Chen, Yueqi and Xing, Xinyu},
doi = {10.1145/3319535.3363212},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Xing - 2019 - Slake Facilitating slab manipulation for exploiting vulnerabilities in the linux kernel.pdf:pdf},
isbn = {9781450367479},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {OS Security,Vulnerability Exploitation},
pages = {1707--1722},
title = {{Slake: Facilitating slab manipulation for exploiting vulnerabilities in the linux kernel}},
year = {2019}
}
@article{Intel2011,
abstract = {The Intel{\textregistered} 64 and IA-32 Architectures Software Developer's Manual, Volume 1, describes the basic architecture and programming environment of Intel 64 and IA-32 processors. The Intel{\textregistered} 64 and IA-32 Architectures Software Developer's Manual, Volumes 2A & 2B, describe the instruction set of the processor and the opcode struc- ture. These volumes apply to application programmers and to programmers who write operating systems or executives. The Intel{\textregistered} 64 and IA-32 Architectures Software Developer's Manual, Volumes 3A & 3B, describe the operating-system support environment of Intel 64 and IA-32 processors. These volumes target operating- system and BIOS designers. In addition, the Intel{\textregistered} 64 and IA-32 Architectures Software Developer's Manual, Volume 3B, addresses the programming environment for classes of software that host operating systems.},
author = {Intel},
doi = {10.1109/MAHC.2010.22},
file = {:C\:/Users/purpl/Desktop/325462-sdm-vol-1-2abcd-3abcd.pdf:pdf},
journal = {System},
keywords = {253665,IA-32 architecture,Intel 64, IA-32 architecture, 253665},
number = {253665},
title = {{Intel 64 and IA-32 Architectures Software Developer's Manual Combined Volumes}},
volume = {3},
year = {2011}
}
@article{Wang2015,
abstract = {The OS kernel is critical to the security of a computer system. Many systems have been proposed to improve its security. A fundamental weakness of those systems is that page tables, the data structures that control the memory protection, are not isolated from the vulnerable kernel, and thus subject to tampering. To address that, researchers have relied on virtualization for reliable kernel memory protection. Unfortunately, such memory protection requires to monitor every update to the guest's page tables. This fundamentally conflicts with the recent advances in the hardware virtualization support. In this paper, we propose SecPod, an extensible framework for virtualization-based security systems that can provide both strong isolation and the compatibility with modern hardware. SecPod has two key techniques: Paging delegation delegates and audits the kernel's paging operations to a secure space; execution trapping intercepts the (compromised) kernel's attempts to subvert SecPod by misusing privileged instructions. We have implemented a prototype of SecPod based on KVM. Our experiments show that SecPod is both effective and efficient.},
author = {Wang, Xiaoguang and Chen, Yue and Wang, Zhi and Qi, Yong and Zhou, Yajin},
file = {:F\:/D2/atc15-paper-wang-xiaoguang.pdf:pdf},
isbn = {9781931971225},
journal = {Proceedings of the 2015 USENIX Annual Technical Conference, USENIX ATC 2015},
pages = {347--360},
title = {{Secpod: A framework for virtualization-based security systems}},
year = {2015}
}
@article{Criswell2014b,
abstract = {Applications that process sensitive data can be carefully designed and validated to be difficult to attack, but they are usually run on monolithic, commodity operating systems, which may be less secure. An OS compromise gives the attacker complete access to all of an application's data, regardless of how well the application is built. We propose a new system, Virtual Ghost, that protects applications from a compromised or even hostile OS. Virtual Ghost is the first system to do so by combining compiler instrumentation and run-time checks on operating system code, which it uses to create ghost memory that the operating system cannot read or write. Virtual Ghost interposes a thin hardware abstraction layer between the kernel and the hardware that provides a set of operations that the kernel must use to manipulate hardware, and provides a few trusted services for secure applications such as ghost memory management, encryption and signing services, and key management. Unlike previous solutions, Virtual Ghost does not use a higher privilege level than the kernel. Virtual Ghost performs well compared to previous approaches; it outperforms InkTag on five out of seven of the LMBench microbenchmarks with improvements between 1.3x and 14.3x. For network downloads, Virtual Ghost experiences a 45% reduction in bandwidth at most for small files and nearly no reduction in bandwidth for large files and web traffic. An application we modified to use ghost memory shows a maximum additional overhead of 5% due to the Virtual Ghost protections. We also demonstrate Virtual Ghost's efficacy by showing how it defeats sophisticated rootkit attacks. Copyright is held by the owner/author(s).},
author = {Criswell, John and Dautenhahn, Nathan and Adve, Vikram},
doi = {10.1145/2541940.2541986},
file = {:F\:/D2/2654822.2541986.pdf:pdf},
isbn = {9781450323055},
issn = {0163-5964},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {Control-flow integrity,Inlined reference monitors,Malicious operating systems,Software fault isolation,Software security},
pages = {81--96},
title = {{Virtual Ghost: Protecting applications from hostile operating systems}},
year = {2014}
}
@article{Swift2003,
abstract = {Despite decades of research in extensible operating system technology, extensions such as device drivers remain a significant cause of system failures. In Windows XP, for example, drivers account for 85% of recently reported failures. This paper describes Nooks, a reliability subsystem that seeks to greatly enhance OS reliability by isolating the OS from driver failures. The Nooks approach is practical: rather than guaranteeing complete fault tolerance through a new (and incompatible) OS or driver architecture, our goal is to prevent the vast majority of driver-caused crashes with little or no change to existing driver and system code. To achieve this, Nooks isolates drivers within lightweight protection domains inside the kernel address space, where hardware and software prevent them from corrupting the kernel. Nooks also tracks a driver's use of kernel resources to hasten automatic clean-up during recovery.To prove the viability of our approach, we implemented Nooks in the Linux operating system and used it to fault-isolate several device drivers. Our results show that Nooks offers a substantial increase in the reliability of operating systems, catching and quickly recovering from many faults that would otherwise crash the system. In a series of 2000 fault-injection tests, Nooks recovered automatically from 99% of the faults that caused Linux to crash.While Nooks was designed for drivers, our techniques generalize to other kernel extensions, as well. We demonstrate this by isolating a kernel-mode file system and an in-kernel Internet service. Overall, because Nooks supports existing C-language extensions, runs on a commodity operating system and hardware, and enables automated recovery, it represents a substantial step beyond the specialized architectures and type-safe languages required by previous efforts directed at safe extensibility.},
author = {Swift, Michael M. and Bershad, Brian N. and Levy, Henry M.},
doi = {10.1145/945445.945466},
file = {:F\:/D2/nooks-sosp.pdf:pdf},
isbn = {1581137575},
keywords = {device drivers,i,o,protection,recovery,virtual memory},
pages = {207},
title = {{Improving the reliability of commodity operating systems}},
year = {2003}
}
@article{Narayanan2019,
abstract = {Modern operating systems are monolithic. Today, however, lack of isolation is one of the main factors undermining security of the kernel. Inherent complexity of the kernel code and rapid development pace combined with the use of unsafe, low-level programming language results in a steady stream of errors. Even after decades of efforts to make commodity kernels more secure, i.e., development of numerous static and dynamic approaches aimed to prevent exploitation of most common errors, several hundreds of serious kernel vulnerabilities are reported every year. Unfortunately, in a monolithic kernel a single exploitable vulnerability potentially provides an attacker with access to the entire kernel. Modern kernels need isolation as a practical means of confining the effects of exploits to individual kernel subsystems. Historically, introducing isolation in the kernel is hard. First, commodity hardware interfaces provide no support for efficient, fine-grained isolation. Second, the complexity of a modern kernel prevents a naive decomposition effort. Our work on Lightweight Execution Domains (LXDs) takes a step towards enabling isolation in a full-featured operating system kernel. LXDs allow one to take an existing kernel subsystem and run it inside an isolated domain with minimal or no modifications and with a minimal overhead. We evaluate our approach by developing isolated versions of several performance-critical device drivers in the Linux kernel.},
author = {Narayanan, Vikram and Balasubramanian, Abhiram and Jacobsen, Charlie and Spall, Sarah and Bauer, Scott and Quigley, Michael and Hussain, Aftab and Younis, Abdullah and Shen, Junjie and Bhattacharyya, Moinak},
file = {:F\:/D2/atc19-narayanan.pdf:pdf},
isbn = {9781939133038},
journal = {Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019},
pages = {269--284},
title = {{LXDS: Towards isolation of kernel subsystems}},
year = {2019}
}
@techreport{Garfinkel,
abstract = {Today's architectures for intrusion detection force the IDS designer to make a difficult choice. If the IDS resides on the host, it has an excellent view of what is happening in that host's software, but is highly susceptible to attack. On the other hand, if the IDS resides in the network , it is more resistant to attack, but has a poor view of what is happening inside the host, making it more susceptible to evasion. In this paper we present an architecture that retains the visibility of a host-based IDS, but pulls the IDS outside of the host for greater attack resistance. We achieve this through the use of a virtual machine monitor. Using this approach allows us to isolate the IDS from the monitored host but still retain excellent visibility into the host's state. The VMM also offers us the unique ability to completely mediate interactions between the host software and the underlying hardware. We present a detailed study of our architecture, including Livewire, a prototype implementation. We demonstrate Livewire by implementing a suite of simple intrusion detection policies and using them to detect real attacks.},
author = {Garfinkel, Tal and Rosenblum, Mendel},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garfinkel, Rosenblum - Unknown - A Virtual Machine Introspection Based Architecture for Intrusion Detection.pdf:pdf},
title = {{A Virtual Machine Introspection Based Architecture for Intrusion Detection}}
}
@book{Ghavamnia,
abstract = {Attack surface reduction through the removal of unnecessary application features and code is a promising technique for improving security without incurring any additional overhead. Recent software debloating techniques consider an applica-tion's entire lifetime when extracting its code requirements, and reduce the attack surface accordingly. In this paper, we present temporal specialization, a novel approach for limiting the set of system calls available to a process depending on its phase of execution. Our approach is tailored to server applications, which exhibit distinct ini-tialization and serving phases with different system call requirements. We present novel static analysis techniques for improving the precision of extracting the application's call graph for each execution phase, which is then used to pinpoint the system calls used in each phase. We show that requirements change throughout the lifetime of servers, and many dangerous system calls (such as execve) can be disabled after the completion of the initialization phase. We have implemented a prototype of temporal specialization on top of the LLVM compiler, and evaluated its effectiveness with six popular server applications. Our results show that it disables 51% more security-critical system calls compared to existing library specialization approaches, while offering the additional benefit of neutralizing 13 more Linux kernel vulnerabilities that could lead to privilege escalation.},
author = {Ghavamnia, Seyedhamed and Palit, Tapti and Mishra, Shachee and Polychronakis, Michalis},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghavamnia et al. - Unknown - Temporal System Call Specialization for Attack Surface Reduction(2).pdf:pdf},
isbn = {9781939133175},
title = {{Temporal System Call Specialization for Attack Surface Reduction}},
url = {www.usenix.org/conference/usenixsecurity20/presentation/ghavamnia}
}
@article{Lu2017,
abstract = {A common type of memory error in the Linux kernel is using uninitialized variables (uninitialized use). Unini-tialized uses not only cause undefined behaviors but also impose a severe security risk if an attacker takes control of the uninitialized variables. However, reliably exploiting uninitialized uses on the kernel stack has been considered infeasible until now since the code executed prior to triggering the vulnerability must leave an attacker-controlled pattern on the stack. Therefore, uninitialized uses are largely overlooked and regarded as undefined behaviors, rather than security vulnerabilities. In particular, full memory-safety techniques (e.g., SoftBound+CETS) exclude uninitialized use as a prevention target, and widely used systems such as OpenSSL even use uninitialized memory as a randomness source. In this paper, we propose a fully automated targeted stack-spraying approach for the Linux kernel that reliably facilitates the exploitation of uninitialized uses. Our targeted stack-spraying includes two techniques: (1) a deterministic stack spraying technique that suitably combines tailored symbolic execution and guided fuzzing to identify kernel inputs that user-mode programs can use to deterministically guide kernel code paths and thereby leave attacker-controlled data on the kernel stack, and (2) an exhaustive memory spraying technique that uses memory occu-pation and pollution to reliably control a large region of the kernel stack. We show that our targeted stack-spraying approach allows attackers to reliably control more than 91% of the Linux kernel stack, which, in combination with uninitialized-use vulnerabilities, suffices for a privilege escalation attack. As a countermeasure, we propose a compiler-based mechanism that initializes potentially unsafe pointer-type fields with almost no performance overhead. Our results show that uninitialized use is a severe attack vector that can be readily exploited with targeted stack-spraying, so future memory-safety techniques should consider it a prevention target, and systems should not use uninitialized memory as a randomness source.},
author = {Lu, Kangjie and Walter, Marie-Therese and Pfaff, David and Nuernberger, Stefan and Lee, Wenke and Backes, Michael},
doi = {10.14722/ndss.2017.23387},
file = {:F\:/D2/ndss2017_09-2_Lu_paper.pdf:pdf},
isbn = {1891562460},
number = {March},
title = {{Unleashing Use-Before-Initialization Vulnerabilities in the Linux Kernel Using Targeted Stack Spraying}},
year = {2017}
}
@article{Burow2019,
abstract = {Control-Flow Hijacking attacks are the dominant attack vector against C/C++ programs. Control-Flow Integrity (CFI) solutions mitigate these attacks on the forward edge, i.e., indirect calls through function pointers and virtual calls. Protecting the backward edge is left to stack canaries, which are easily bypassed through information leaks. Shadow Stacks are a fully precise mechanism for protecting backwards edges, and should be deployed with CFI mitigations. We present a comprehensive analysis of all possible shadow stack mechanisms along three axes: performance, compatibil- ity, and security. For performance comparisons we use SPEC CPU2006, while security and compatibility are qualitatively analyzed. Based on our study, we renew calls for a shadow stack design that leverages a dedicated register, resulting in low performance overhead, and minimal memory overhead, but sacrifices compatibility. We present case studies of our implementation of such a design, Shadesmar, on Phoronix and Apache to demonstrate the feasibility of dedicating a general purpose register to a security monitor on modern architectures, and Shadesmar's deployability. Our comprehensive analysis, including detailed case studies for our novel design, allows compiler designers and practitioners to select the correct shadow stack design for different usage scenarios. Shadow stacks belong to the class of defense mechanisms that require metadata about the program's state to enforce their defense policies. Protecting this metadata for deployed mitigations requires in-process isolation of a segment of the virtual address space. Prior work on defenses in this class has relied on information hiding to protect metadata. We show that stronger guarantees are possible by repurposing two new Intel x86 extensions for memory protection (MPX), and page table control (MPK). Building on our isolation efforts with MPX and MPK, we present the design requirements for a dedicated hardware mechanism to support intra-process memory isolation, and discuss how such a mechanism can empower the next wave of highly precise software security mitigations that rely on partially isolated information in a process.},
author = {Burow, Nathan and Zhang, Xinping and Payer, Mathias},
doi = {10.1109/SP.2019.00076},
file = {:F\:/D2/08835389.pdf:pdf},
isbn = {9781538666609},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
keywords = {Control-flow-hijacking,Control-flow-integrity,Language-based-security,Return-oriented-programming,Shadow-stacks},
pages = {985--999},
publisher = {IEEE},
title = {{SoK: Shining light on shadow stacks}},
volume = {2019-May},
year = {2019}
}
@article{Tian2019,
abstract = {Vulnerable kernel extensions are severe threats to the security of modern operating systems. Due to lack of protection mechanism in the kernel space, the kernel extension exploitation could take over the entire operating system's control. To enhance security and reliability of kernel extensions, many solutions mainly rely on adding the kernel isolation mechanisms to confine the execution behaviors of kernel extensions. However, previous methods suffer from limitations in terms of compatibility and performance cost. To address these issues, we present KEcruiser, a novel control flow protection mechanism for kernel extensions. The basic idea of our approach is to monitor the control flow of a kernel extension and then identify the abnormal execution behavior during run-time. Based on the recent hardware feature, our system can collect the kernel control flow information efficiently. By leveraging the virtualization technology, our security monitor is deployed outside of the target VM so that the kernel control flow can be checked securely. To ensure the monitoring correctness and concurrency, we make use of Lamport's ring buffer algorithm. Our system is compatible with the existing commodity operating system, and it can protect the running kernel extensions transparently. The experiments show that KEcruiser can effectively identify control flow violation occurred in kernel extensions with small performance cost.},
author = {Tian, Donghai and Ma, Rui and Jia, Xiaoqi and Hu, Changzhen},
doi = {10.1016/j.future.2019.05.008},
file = {:F\:/papers/1-s2.0-S0167739X18331273-main.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Control flow,Kernel extensions,Protection mechanism,Virtualization},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{KEcruiser: A novel control flow protection for kernel extensions}},
url = {https://doi.org/10.1016/j.future.2019.05.008},
volume = {100},
year = {2019}
}
@article{McCune2008a,
abstract = {We explore the extent to which newly available CPU-based security technology can reduce the Trusted Computing Base (TCB) for security-sensitive applications. We find that although this new technology represents a step in the right direction, significant performance issues remain. We offer several suggestions that leverage existing processor technology, retain security, and improve performance. Implementing these recommendations will finally allow application developers to focus exclusively on the security of their own code, enabling it to execute in isolation from the numerous vulnerabilities in the underlying layers of legacy code. Copyright {\textcopyright} 2008 ACM.},
author = {McCune, Jonathan M. and Parno, Bryan and Perrig, Adrian and Reiter, Michael K. and Seshadri, Arvind},
doi = {10.1145/1346281.1346285},
file = {:F\:/D2/1353535.1346285.pdf:pdf},
isbn = {9781595939586},
issn = {01635980},
journal = {Operating Systems Review (ACM)},
keywords = {Late launch,Secure execution,Trusted computing},
number = {2},
pages = {14--25},
title = {{How low can you go?: Recommendations for hardware-supported minimal TCB code execution}},
volume = {42},
year = {2008}
}
@article{Kemerlis2014,
abstract = {Return-to-user (ret2usr) attacks redirect corrupted kernel pointers to data residing in user space. In response, several kernel-hardening approaches have been proposed to enforce a more strict address space separation, by preventing arbitrary control flow transfers and dereferences from kernel to user space. Intel and ARM also recently introduced hardware support for this purpose in the form of the SMEP, SMAP, and PXN processor features. Unfortunately , although mechanisms like the above prevent the explicit sharing of the virtual address space among user processes and the kernel, conditions of implicit sharing still exist due to fundamental design choices that trade stronger isolation for performance. In this work, we demonstrate how implicit page frame sharing can be leveraged for the complete circumven-tion of software and hardware kernel isolation protec-tions. We introduce a new kernel exploitation technique, called return-to-direct-mapped memory (ret2dir), which bypasses all existing ret2usr defenses, namely SMEP, SMAP, PXN, KERNEXEC, UDEREF, and kGuard. We also discuss techniques for constructing reliable ret2dir exploits against x86, x86-64, AArch32, and AArch64 Linux targets. Finally, to defend against ret2dir attacks, we present the design and implementation of an exclusive page frame ownership scheme for the Linux kernel that prevents the implicit sharing of physical memory pages with minimal runtime overhead.},
author = {Kemerlis, Vasileios P and Polychronakis, Michalis and Keromytis, Angelos D},
file = {:F\:/papers/Kemerlis, Polychronakis, Keromytis - 2014 - Open access to the Proceedings of the 23rd USENIX Security Symposium is sponsored by USENIX.pdf:pdf},
isbn = {978-1-931971-15-7},
title = {{ret2dir: Rethinking Kernel Isolation}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/kemerlis},
year = {2014}
}
@article{Zhang2013,
abstract = {Control Flow Integrity (CFI) provides a strong protection against modern control-flow hijacking attacks. However, performance and compatibility issues limit its adoption. We propose a new practical and realistic protection method called CCFIR (Compact Control Flow Integrity and Randomization), which addresses the main barriers to CFI adoption. CCFIR collects all legal targets of indirect control-transfer instructions, puts them into a dedicated "Springboard section" in a random order, and then limits indirect transfers to flow only to them. Using the Springboard section for targets, CCFIR can validate a target more simply and faster than traditional CFI, and provide support for on-site target-randomization as well as better compatibility. Based on these approaches, CCFIR can stop control-flow hijacking attacks including ROP and return-into-libc. Results show that ROP gadgets are all eliminated. We observe that with the wide deployment of ASLR, Windows/x86 PE executables contain enough information in relocation tables which CCFIR can use to find all legal instructions and jump targets reliably, without source code or symbol information. We evaluate our prototype implementation on common web browsers and the SPEC CPU2000 suite: CCFIR protects large applications such as GCC and Firefox completely automatically, and has low performance overhead of about 3.6%/8.6% (average/max) using SPECint2000. Experiments on real-world exploits also show that CCFIR-hardened versions of IE6, Firefox 3.6 and other applications are protected effectively. {\textcopyright} 2013 IEEE.},
author = {Zhang, Chao and Wei, Tao and Chen, Zhaofeng and Duan, Lei and Szekeres, L{\'{a}}szl{\'{o}} and McCamant, Stephen and Song, Dawn and Zou, Wei},
doi = {10.1109/SP.2013.44},
file = {:F\:/papers/Zhang et al. - 2013 - Practical control flow integrity and randomization for binary executables.pdf:pdf},
isbn = {9780769549774},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {559--573},
title = {{Practical control flow integrity and randomization for binary executables}},
year = {2013}
}
@article{Cheng2019,
abstract = {Data-oriented attacks manipulate non-control data to alter a program's benign behavior without violating its control-flow integrity. It has been shown that such attacks can cause significant damage even in the presence of control-flow defense mechanisms. However, these threats have not been adequately addressed. In this systematization of knowledge (SoK) paper, we first map data-oriented exploits, including Data-Oriented Programming (DOP) and Block-Oriented Programming attacks, to their assumptions/requirements and attack capabilities. We also compare known defenses against these attacks, in terms of approach, detection capabilities, overhead, and compatibility. Then we discuss the possible frequency anomalies of data-oriented attacks, especially the frequency anomalies of DOP attacks with experimental proofs. It is generally believed that control flows may not be useful for data-oriented security. How-ever, the frequency anomalies show that data-oriented attacks (especially DOP attacks) may generate side-effects on control-flow behavior in multiple dimensions. In the end, we discuss challenges for building deployable data-oriented defenses and open research questions.},
archivePrefix = {arXiv},
arxivId = {1902.08359},
author = {Cheng, Long and Liljestrand, Hans and Ahmed, Md Salman and Nyman, Thomas and Jaeger, Trent and Asokan, N. and Yao, Danfeng Daphne},
doi = {10.1109/SecDev.2019.00022},
eprint = {1902.08359},
file = {:F\:/D2/Exploitation_Techniques_and_Defenses_for_Data-Oriented_Attacks.pdf:pdf},
isbn = {9781538672891},
journal = {Proceedings - 2019 IEEE Secure Development, SecDev 2019},
keywords = {Data-oriented attacks,Defenses,Exploitation techniques},
pages = {114--128},
publisher = {IEEE},
title = {{Exploitation techniques and defenses for data-oriented attacks}},
year = {2019}
}
@book{Dolan-Gavitt2009,
abstract = {Kernel-mode rootkits hide objects such as processes and threads using a technique known as Direct Kernel Object Manipulation (DKOM). Many forensic analysis tools attempt to detect these hidden objects by scanning kernel memory with handmade signatures; however, such signatures are brittle and rely on non-essential features of these data structures, making them easy to evade. In this paper, we present an automated mechanism for generating signatures for kernel data structures and show that these signatures are robust: attempts to evade the signature by modifying the structure contents will cause the OS to consider the object invalid. Using dynamic analysis, we profile the target data structure to determine commonly used fields, and we then fuzz those fields to determine which are essential to the correct operation of the OS. These fields form the basis of a signature for the data structure. In our experiments , our new signature matched the accuracy of existing scanners for traditional malware and found processes hidden with our prototype rootkit that all current signatures missed. Our techniques significantly increase the difficulty of hiding objects from signature scanning.},
author = {Dolan-Gavitt, Brendan and Srivastava, Abhinav and Traynor, Patrick and Giffin, Jonathon},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dolan-Gavitt et al. - 2009 - Robust Signatures for Kernel Data Structures.pdf:pdf},
isbn = {9781605583525},
keywords = {D46 [Operating Systems]: Security and Protection G,Security Keywords Data structures,memory analysis,security},
title = {{Robust Signatures for Kernel Data Structures}},
year = {2009}
}
@article{Ren2019,
abstract = {This paper presents an analysis of how Linux's performance has evolved over the past seven years. Unlike recent works that focus on OS performance in terms of scalability or service of a particular workload, this study goes back to basics: the latency of core kernel operations (e.g., system calls, context switching, etc.). To our surprise, the study shows that the performance of many core operations has worsened or fluctuated significantly over the years. For example, the select system call is 100% slower than it was just two years ago. An in-depth analysis shows that over the past seven years, core kernel subsystems have been forced to accommodate an increasing number of security enhancements and new features. These additions steadily add overhead to core kernel operations but also frequently introduce extreme slowdowns of more than 100%. In addition, simple misconfigurations have also severely impacted kernel performance. Overall, we find most of the slowdowns can be attributed to 11 changes. Some forms of slowdown are avoidable with more proactive engineering. We show that it is possible to patch two security enhancements (from the 11 changes) to eliminate most of their overheads. In fact, several features have been introduced to the kernel unoptimized or insufficiently tested and then improved or disabled long after their release. Our findings also highlight both the feasibility and importance for Linux users to actively configure their systems to achieve an optimal balance between performance, functionality, and security: we discover that 8 out of the 11 changes can be avoided by reconfiguring the kernel, and the other 3 can be disabled through simple patches. By disabling the 11 changes with the goal of optimizing performance, we speed up Redis, Apache, and Nginx benchmark workloads by as much as 56%, 33%, and 34%, respectively.},
author = {Ren, Xiang and Rodrigues, Kirk and Chen, Luyuan and Vega, Camilo and Stumm, Michael and Yuan, Ding},
doi = {10.1145/3341301.3359640},
file = {:F\:/D2/3341301.3359640.pdf:pdf},
isbn = {9781450368735},
journal = {SOSP 2019 - Proceedings of the 27th ACM Symposium on Operating Systems Principles},
keywords = {Linux,Operating systems,Performance evolution},
pages = {554--569},
title = {{An analysis of performance evolution of Linux's core operations}},
volume = {20},
year = {2019}
}
@article{Soares2010,
author = {Soares, Livio},
file = {:F\:/D2/Soares.pdf:pdf},
journal = {Proceedings of the 9th USENIX conference on Operating systems design and implementation},
title = {{FlexSC: Flexible system call scheduling with exception-less system calls}},
url = {http://dl.acm.org/citation.cfm?id=1924946},
year = {2010}
}
@book{Hofmann,
abstract = {Kernel rootkits that modify operating system state to avoid detection are a dangerous threat to system security. This paper presents OSck, a system that discovers kernel rootkits by detecting malicious modifications to operating system data. OSck integrates and extends existing techniques for detecting rootkits, and verifies safety properties for large portions of the kernel heap with minimal overhead. We deduce type information for verification by analyzing unmodified kernel source code and in-memory kernel data structures. High-performance integrity checks that execute concurrently with a running operating system create data races, and we demonstrate a deterministic solution for ensuring kernel memory is in a consistent state. We introduce two new classes of kernel rootkits that are undetectable by current systems, motivating the need for the OSck API that allows kernel developers to conveniently specify arbitrary integrity properties.},
author = {Hofmann, Owen S and Dunn, Alan M and Kim, Sangman and Roy, Indrajit and Witchel, Emmett},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hofmann et al. - Unknown - Ensuring Operating System Kernel Integrity with OSck.pdf:pdf},
isbn = {9781450302661},
keywords = {Verification Keywords Rootkit detection},
title = {{Ensuring Operating System Kernel Integrity with OSck}}
}
@article{Li2011,
abstract = {Protecting kernel control data (e.g., function pointers and return addresses) has been a serious issue plaguing rootkit defenders. In particular, rootkit authors only need to compromise one piece of control data to launch their attacks, while defenders need to protect thousands of such values widely scattered across kernel memory space. Worse, some of this data (e.g., return addresses) is volatile and can be dynamically generated at run time. Existing solutions, however, offer either incomplete protection or excessive performance overhead. To overcome these limitations, we present indexed hooks, a scheme that greatly facilitates kernel control-flow enforcement by thoroughly transforming and restricting kernel control data to take only legal jump targets (allowed by the kernel's control-flow graph). By doing so, we can severely limit the attackers' possibility of exploiting them as an infection vector to launch rootkit attacks. To validate our approach, we have developed a compiler-based prototype that implements this technique in the FreeBSD 8.0 kernel, transforming 49025 control transfer instructions ($\sim$ 7.25% of the code base) to use indexed hooks instead of direct pointers. Our evaluation results indicate that our approach is generic, effective, and can be implemented on commodity hardware with a low performance overhead ($<$5% based on benchmarks). {\textcopyright} 2006 IEEE.},
author = {Li, Jinku and Wang, Zhi and Bletsch, Tyler and Srinivasan, Deepa and Grace, Michael and Jiang, Xuxian},
doi = {10.1109/TIFS.2011.2159712},
file = {:F\:/D2/05887414.pdf:pdf},
issn = {15566013},
journal = {IEEE Transactions on Information Forensics and Security},
number = {4},
pages = {1404--1417},
publisher = {IEEE},
title = {{Comprehensive and efficient protection of kernel control data}},
volume = {6},
year = {2011}
}
@article{Prakash2013,
abstract = {Semantic values in kernel data structures are critical to many security applications, such as virtual machine introspection, malware analysis, and memory forensics. However, malware, or more specifically a kernel rootkit, can often directly tamper with the raw kernel data structures, known as DKOM (Direct Kernel Object Manipulation) attacks, thereby significantly thwarting security analysis. In addition to manipulating pointer fields to hide certain kernel objects, DKOM attacks may also mutate semantic values, which are data values with important semantic meanings. Prior research efforts have been made to defeat pointer manipulation attacks and thus identify hidden kernel objects. However, the space and severity of Semantic Value Manipulation (SVM) attacks have not received sufficient understanding. In this paper, we take a first step to systematically assess this attack space. To this end, we devise a new fuzz testing technique, namely-duplicate-value directed semantic field fuzzing, and implement a prototype called MOSS. Using MOSS, we evaluate two widely used operating systems: Windows XP and Ubuntu 10.04. Our experimental results show that the space of SVM attacks is vast for both OSes. Our proof-of-concept kernel rootkit further demonstrates that it can successfully evade all the security tools tested in our experiments, including recently proposed robust signature schemes. Moreover, our duplicate value analysis implies the challenges in defeating SVM attacks, such as an intuitive cross checking approach on duplicate values can only provide marginal detection improvement. Our study motivates revisiting of existing security solutions and calls for more effective defense against kernel threats. {\textcopyright} 2013 IEEE.},
author = {Prakash, Aravind and Venkataramani, Eknath and Yin, Heng and Lin, Zhiqiang},
doi = {10.1109/DSN.2013.6575344},
file = {:F\:/D2/06575344.pdf:pdf},
isbn = {9781467364713},
journal = {Proceedings of the International Conference on Dependable Systems and Networks},
publisher = {IEEE},
title = {{Manipulating semantic values in kernel data structures: Attack assessments and implications}},
year = {2013}
}
@article{Markuze,
abstract = {Malicious I/O devices might compromise the OS using DMAs. The OS therefore utilizes the IOMMU to map and unmap every target buffer right before and after its DMA is processed, thereby restricting DMAs to their designated locations. This usage model, however, is not truly secure for two reasons: (1) it provides protection at page granularity only, whereas DMA buffers can reside on the same page as other data; and (2) it delays DMA buffer unmaps due to performance considerations, creating a vulnerability window in which devices can access in-use memory. We propose that OSes utilize the IOMMU differently, in a manner that eliminates these two flaws. Our new usage model restricts device access to a set of shadow DMA buffers that are never unmapped, and it copies DMAed data to/from these buffers, thus providing sub-page protection while eliminating the aforementioned vulnerability window. Our key insight is that the cost of interacting with, and synchronizing access to the slow IOMMU hardware-required for zero-copy protection against devices-make copying preferable to zero-copying. We implement our model in Linux and evaluate it with standard networking benchmarks utilizing a 40 Gb/s NIC. We demonstrate that despite being more secure than the safest preexisting usage model, our approach provides up to 5× higher throughput. Additionally, whereas it is inherently less scalable than an IOMMU-less (unprotected) system, our approach incurs only 0%-25% performance degradation in comparison.},
author = {Markuze, Alex and Morrison, Adam and Tsafrir, Dan},
doi = {10.1145/2872362.2872379},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Markuze, Morrison, Tsafrir - Unknown - True IOMMU Protection from DMA Attacks When Copy is Faster than Zero Copy.pdf:pdf},
isbn = {9781450340915},
keywords = {DMA attacks,Security and Protection Keywords IOMMU},
title = {{True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy}},
url = {http://dx.doi.org/10.1145/2872362.2872379}
}
@article{Zeldovich2011,
abstract = {The practice of Minimally Invasive Surgery is becoming more and more widespread and is being adopted as an alternative to the classical procedure. This technique presents some limitations for surgeons. In particular, the lack of depth in perception and the difficulty in estimating the distance of the specific structures in laparoscopic surgery can impose limits to delicate dissection or suturing. The presence of new systems for the pre-operative planning can be very useful to the surgeon. In this paper we present an advanced interface for the pre-operative planning of the surgical procedure and the choice of the abdominal access points in pediatric laparoscopy; using the Augmented Reality technology, these points are overlapped on the real patient's body. Two case studies have been considered for the building of 3D models of the patient's organs from the CT images. The developed application allows the surgeon to gather information about the patient and his pathology, visualizing and interacting with the 3D models of the organs built from the patient's medical images, measuring the dimensions of the organs and deciding the best points to insert the trocars in the patient's body. {\textcopyright} 2011 Springer-Verlag.},
author = {Zeldovich, Silas Boyd-Wickizer and Nickolai},
doi = {10.1007/978-3-642-21898-9_46},
file = {:F\:/papers/Boyd-Wickizer.pdf:pdf},
isbn = {9783642218972},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Augmented Reality,image processing,surgical pre-operative planning,user interface},
number = {PART 4},
pages = {562--571},
title = {{Tolerating Malicious Device Drivers in Linux}},
volume = {6785 LNCS},
year = {2011}
}
@article{Kemerlis2012,
abstract = {Return-to-user (ret2usr) attacks exploit the operating system kernel, enabling local users to hijack privileged execution paths and execute arbitrary code with elevated privileges. Current defenses have proven to be inadequate, as they have been repeatedly circumvented, incur considerable overhead, or rely on extended hypervisors and special hardware features. We present kGuard, a compiler plugin that augments the kernel with compact inline guards, which prevent ret2usr with low performance and space overhead. kGuard can be used with any operating system that features a weak separation between kernel and user space, requires no modifications to the OS, and is applicable to both 32- and 64-bit architectures. Our evaluation demonstrates that Linux kernels compiled with kGuard become impervious to a variety of control-flow hijacking exploits. kGuard exhibits lower overhead than previous work, imposing on average an overhead of 11.4% on system call and I/O latency on x86 OSs, and 10.3% on x86-64. The size of a kGuard-protected kernel grows between 3.5% and 5.6%, due to the inserted checks, while the impact on real-life applications is minimal (≤1%).},
author = {Kemerlis, Vasileios P. and Portokalidis, Georgios and Keromytis, Angelos D.},
file = {:F\:/D2/sec12-final143.pdf:pdf},
journal = {Proceedings of the 21st USENIX Security Symposium},
pages = {459--474},
title = {{KGuard: Lightweight kernel protection against return-to-user attacks}},
year = {2012}
}
@book{Song,
abstract = {Kernel-mode drivers are challenging to analyze for vulner-abilities, yet play a critical role in maintaining the security of OS kernels. Their wide attack surface, exposed via both the system call interface and the peripheral interface, is often found to be the most direct attack vector to compromise an OS kernel. Researchers therefore have proposed many fuzzing techniques to find vulnerabilities in kernel drivers. However, the performance of kernel fuzzers is still lacking, for reasons such as prolonged execution of kernel code, interference between test inputs, and kernel crashes. This paper proposes lightweight virtual machine check-pointing as a new primitive that enables high-throughput kernel driver fuzzing. Our key insight is that kernel driver fuzzers frequently execute similar test cases in a row, and that their performance can be improved by dynamically creating multiple checkpoints while executing test cases and skipping parts of test cases using the created checkpoints. We built a system, dubbed Agamotto, around the virtual machine check-pointing primitive and evaluated it by fuzzing the peripheral attack surface of USB and PCI drivers in Linux. The results are convincing. Agamotto improved the performance of the state-of-the-art kernel fuzzer, Syzkaller, by 66.6% on average in fuzzing 8 USB drivers, and an AFL-based PCI fuzzer by 21.6% in fuzzing 4 PCI drivers, without modifying their underlying input generation algorithm.},
author = {Song, Dokyung and Kim, Jonghwan and Kang, Brent Byunghoon and Franz, Michael and Hetzelt, Felicitas and Brent, Kaist and Kang, Byunghoon and Seifert, Jean-Pierre},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - Unknown - Agamotto Accelerating Kernel Driver Fuzzing with Lightweight Virtual Machine Checkpoints.pdf:pdf},
isbn = {9781939133175},
title = {{ Agamotto: Accelerating Kernel Driver Fuzzing with Lightweight Virtual Machine Checkpoints }},
url = {https://github.com/securesystemslab/agamotto}
}
@article{Abubakar2021,
abstract = {With growing hardware complexity and ever-evolving user requirements , the kernel is increasingly bloated which increases its attack surface. Despite its large size, for specific applications and workloads, only a small subset of the kernel code is actually required. Kernel specialization approaches exploit this observation to either harden the kernel or restrict access to its code (debloating) on a per-application basis. However, existing approaches suffer from coarse specialization granularity and lack strict enforcement which limits their effectiveness. This paper presents SHARD, a practical framework to enforce fine-grain kernel specialization. SHARD specializes at both the application and system call levels to significantly restrict the kernel code exposed to attackers. Furthermore, SHARD introduces context-aware hardening to dynamically enable code hardening during suspicious execution contexts. SHARD implements an instance of a context-aware hardening scheme using control-flow integrity (CFI), which provides near-native performance for non-hardened executions and strong security guarantees. Our analysis of the kernel attack surface reduction with SHARD as well as concrete attacks shows that SHARD exposes 181× less kernel code than the native kernel, an order of magnitude better than existing work, and prevents 90% of the evaluated attacks. Our evaluation shows that the average performance overhead of SHARD on real-world applications is moderate-10% to 36% on NG-INX, 3% to 10% on Redis, and 0% to 2.7% on the SPEC CPU 2006 benchmarks.},
author = {Abubakar, Muhammad and Ahmad, Adil and Fonseca, Pedro and Xu, Dongyan},
file = {:F\:/D2/sec21summer_abubakar.pdf:pdf},
journal = {USENIX Security},
title = {{SHARD: Fine-Grained Kernel Specialization with Context-Aware Hardening}},
year = {2021}
}
@article{Machiry2017a,
abstract = {While kernel drivers have long been know to poses huge security risks, due to their privileged access and lower code quality, bug-finding tools for drivers are still greatly lacking both in quantity and effectiveness. This is because the pointer-heavy code in these drivers present some of the hardest challenges to static analysis, and their tight coupling with the hardware make dynamic analysis infeasible in most cases. In this work, we present DR. CHECKER, a soundy (i.e., mostly sound) bug-finding tool for Linux kernel drivers that is based on well-known program analysis techniques. We are able to overcome many of the inherent limitations of static analysis by scoping our analysis to only the most bug-prone parts of the kernel (i.e., the drivers), and by only sacrificing soundness in very few cases to ensure that our technique is both scalable and precise. DR. CHECKER is a fully-automated static analysis tool capable of performing general bug finding using both pointer and taint analyses that are flow-sensitive, context-sensitive, and field-sensitive on kernel drivers. To demonstrate the scala-bility and efficacy of DR. CHECKER, we analyzed the drivers of nine production Linux kernels (3.1 million LOC), where it correctly identified 158 critical zero-day bugs with an overall precision of 78%.},
author = {Machiry, Aravind and Spensky, Chad and Corina, Jake and Stephens, Nick and Kruegel, Christopher and Vigna, Giovanni and Barbara, Santa},
file = {:F\:/papers/sec17-machiry.pdf:pdf},
isbn = {978-1-931971-40-9},
title = {{DR. CHECKER: A Soundy Analysis for Linux Kernel Drivers}},
url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/machiry},
year = {2017}
}
@article{Amit2017,
author = {Amit, Nadav and Wei, Michael and Tu, Cheng Chun},
doi = {10.1145/3102980.3102987},
file = {:F\:/papers/amit17hypercallbacks.pdf:pdf},
isbn = {9781450350686},
journal = {Proceedings of the Workshop on Hot Topics in Operating Systems - HOTOS},
pages = {37--41},
title = {{Hypercallbacks: Decoupling Policy Decisions and Execution}},
volume = {Part F1293},
year = {2017}
}
@article{Seo2017,
abstract = {—Traditional execution environments deploy Address Space Layout Randomization (ASLR) to defend against memory corruption attacks. However, Intel Software Guard Extension (SGX), a new trusted execution environment designed to serve security-critical applications on the cloud, lacks such an effective, well-studied feature. In fact, we find that applying ASLR to SGX programs raises non-trivial issues beyond simple engineering for a number of reasons: 1) SGX is designed to defeat a stronger adversary than the traditional model, which requires the address space layout to be hidden from the kernel; 2) the limited memory uses in SGX programs present a new challenge in providing a sufficient degree of entropy; 3) remote attestation conflicts with the dynamic relocation required for ASLR; and 4) the SGX specification relies on known and fixed addresses for key data structures that cannot be randomized. This paper presents SGX-Shield, a new ASLR scheme de-signed for SGX environments. SGX-Shield is built on a secure in-enclave loader to secretly bootstrap the memory space layout with a finer-grained randomization. To be compatible with SGX hardware (e.g., remote attestation, fixed addresses), SGX-Shield is designed with a software-based data execution protection mechanism through an LLVM-based compiler. We implement SGX-Shield and thoroughly evaluate it on real SGX hardware. It shows a high degree of randomness in memory layouts and stops memory corruption attacks with a high probability. SGX-Shield shows 7.61% performance overhead in running common micro-benchmarks and 2.25% overhead in running a more realistic workload of an HTTPS server.},
author = {Seo, Jaebaek and Lee, Byoungyoung and Kim, Seongmin and Shih, Ming-Wei and Shin, Insik and Han, Dongsu and Kim, Taesoo},
doi = {10.14722/ndss.2017.23037},
file = {:F\:/papers/Seo et al. - 2017 - SGX-Shield Enabling Address Space Layout Randomization for SGX Programs.pdf:pdf},
number = {March},
title = {{SGX-Shield: Enabling Address Space Layout Randomization for SGX Programs}},
year = {2017}
}
@article{Zhao2020,
abstract = {Intel Software Guard eXtensions (SGX), a hardware-based Trusted Execution Environment (TEE), has become a promising solution to stopping critical threats such as insider attacks and remote exploits. SGX has recently drawn extensive research in two directions-using it to protect the confidentiality and integrity of sensitive data, and protecting itself from attacks. Both the applications and defense mechanisms of SGX have a fundamental need-flexible memory protection that updates memory-page permissions dynamically and enforces the least-privilege principle. Unfortunately, SGX does not provide such a memory-protection mechanism due to the lack of hardware support and the untrustedness of operating systems. This paper proposes MPTEE, a memory-protection mechanism that provides flexible and efficient enforcement of memory-page permissions in SGX. The enforcement relies on our elastic cross-region bound check technique which uses only three bound registers but provides six memory permissions. To defend MPTEE against potential attacks, we further develop an efficient mechanism that exploits the in-place bound-check technique to ensure the integrity of the memory protection. With MPTEE, developers can enhance the protection for data and code in SGX enclaves and enforce the least-privilege principle such as Execute-no-Read memory readily. We have implemented MPTEE and extensively evaluated its effectiveness, utility, and performance. The results show that MPTEE incurs a performance overhead of only 2%-8%, and is effective in ensuring memory protection and in defending against potential attacks.},
author = {Zhao, Wenjia and Lu, Kangjie and Qi, Yong and Qi, Saiyu},
doi = {10.1145/3342195.3387536},
file = {:C\:/Users/purpl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - MPTEE Bringing Flexible and Efficient Memory Protection to Intel SGX.pdf:pdf},
isbn = {9781450368827},
journal = {EuroSys '20},
pages = {1--15},
title = {{MPTEE: Bringing Flexible and Efficient Memory Protection to Intel SGX}},
url = {https://www-users.cs.umn.edu/$\sim$kjlu/papers/mptee.pdf},
year = {2020}
}
@article{Lee2018,
abstract = {Modern applications often involve processing of sensitive information. However, the lack of privilege separation within the user space leaves sensitive application secret such as cryptographic keys just as unprotected as a "hello world" string. Cutting-edge hardware-supported security features are being introduced. However, the features are often vendor-specific or lack compatibility with older generations of the processors. The situation leaves developers with no portable solution to incorporate protection for the sensitive application component. We propose LOTRx86, a fundamental and portable approach for user-space privilege separation. Our approach creates a more privileged user execution layer called PrivUser by harnessing the underused intermediate privilege levels on the x86 architecture. The PrivUser memory space, a set of pages within process address space that are inaccessible to user mode, is a safe place for application secrets and routines that access them. We implement the LOTRx86 ABI that exports the privcall interface to users to invoke secret handling routines in PrivUser. This way, sensitive application operations that involve the secrets are performed in a strictly controlled manner. The memory access control in our architecture is privilege-based, accessing the protected application secret only requires a change in the privilege, eliminating the need for costly remote procedure calls or change in address space. We evaluated our platform by developing a proof-of-concept LOTRx86-enabled web server that employs our architecture to securely access its private key during an SSL connection. We conducted a set of experiments including a performance measurement on the PoC on both Intel and AMD PCs, and confirmed that LOTRx86 incurs only a limited performance overhead.},
archivePrefix = {arXiv},
arxivId = {1805.11912},
author = {Lee, Hojoon and Song, Chihyun and Kang, Brent Byunghoon},
doi = {10.1145/3243734.3243748},
eprint = {1805.11912},
file = {:F\:/papers/Lee, Song, Kang - 2018 - Lord of the x86 rings A portable user mode privilege separation architecture on x86.pdf:pdf},
isbn = {9781450356930},
issn = {15437221},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
keywords = {Memory protection,Operating system,Privilege separation},
pages = {1441--1454},
title = {{Lord of the x86 rings: A portable user mode privilege separation architecture on x86}},
year = {2018}
}
@article{Renzelmann2012,
abstract = {Device-driver development and testing is a complex and error-prone undertaking. For example, testing error-handling code requires simulating faulty inputs from the device. A single driver may support dozens of devices, and a developer may not have access to any of them. Consequently, many Linux driver patches include the comment “compile tested only.” SymDrive is a system for testing Linux and FreeBSD drivers without their devices present. The system uses symbolic execution to remove the need for hardware, and extends past tools with three new features. First, SymDrive uses static-analysis and source-to-source transformation to greatly reduce the effort of testing a new driver. Second, SymDrive checkers are ordinary C code and execute in the kernel, where they have full access to kernel and driver state. Finally, SymDrive provides an execution-tracing tool to identify how a patch changes I/O to the device and to compare device-driver implementations. In applying SymDrive to 21 Linux drivers and 5 FreeBSD drivers, we found 39 bugs.},
author = {Renzelmann, Matthew J. and Kadav, Asim and Swift, Michael M.},
file = {:F\:/papers/osdi12-final-4.pdf:pdf},
isbn = {978-931971-96-6},
journal = {Osdi'12},
pages = {279--292},
title = {{SymDrive : Testing Drivers without Devices}},
year = {2012}
}
@article{McCune2010,
abstract = {An important security challenge is to protect the execution of security-sensitive code on legacy systems from malware that may infect the OS, applications, or system devices. Prior work experienced a tradeoff between the level of security achieved and efficiency. In this work, we leverage the features of modern processors from AMD and Intel to overcome the tradeoff to simultaneously achieve a high level of security and high performance. We present TrustVisor, a special-purpose hypervisor that provides code integrity as well as data integrity and secrecy for selected portions of an application. TrustVisor achieves a high level of security, first because it can protect sensitive code at a very fine granularity, and second because it has a very small code base (only around 6K lines of code) that makes verification feasible. TrustVisor can also attest the existence of isolated execution to an external entity. We have implemented TrustVisor to protect security-sensitive code blocks while imposing less than 7% overhead on the legacy OS and its applications in the common case. {\textcopyright} 2010 IEEE.},
author = {McCune, Jonathan M. and Li, Yanlin and Qu, Ning and Zhou, Zongwei and Datta, Anupam and Gligor, Virgil and Perrig, Adrian},
doi = {10.1109/SP.2010.17},
file = {:F\:/D2/05504713.pdf:pdf},
isbn = {9780769540351},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {143--158},
publisher = {IEEE},
title = {{Trust visor: Efficient TCB reduction and attestation}},
year = {2010}
}
@article{Zhai2014,
abstract = {Systems code is often written in low-level languages like C/C++, which offer many benefits but also dele-gate memory management to programmers. This invites memory safety bugs that attackers can exploit to divert control flow and compromise the system. Deployed de-fense mechanisms (e.g., ASLR, DEP) are incomplete, and stronger defense mechanisms (e.g., CFI) often have high overhead and limited guarantees [19, 15, 9]. We introduce code-pointer integrity (CPI), a new de-sign point that guarantees the integrity of all code point-ers in a program (e.g., function pointers, saved return ad-dresses) and thereby prevents all control-flow hijack at-tacks, including return-oriented programming. We also introduce code-pointer separation (CPS), a relaxation of CPI with better performance properties. CPI and CPS offer substantially better security-to-overhead ratios than the state of the art, they are practical (we protect a complete FreeBSD system and over 100 packages like apache and postgresql), effective (prevent all attacks in the RIPE benchmark), and efficient: on SPEC CPU2006, CPS averages 1.2% overhead for C and 1.9% for C/C++, while CPI's overhead is 2.9% for C and 8.4% for C/C++. A prototype implementation of CPI and CPS can be obtained from http://levee.epfl.ch.},
author = {Zhai, Ennan and Chen, Ruichuan and Labs, Bell and Wolinsky, David Isaac and Ford, Bryan},
file = {:F\:/D2/osdi14-paper-kuznetsov.pdf:pdf},
isbn = {9781931971164},
journal = {Usenix Osdi},
title = {{Code-Pointer Integrity}},
year = {2014}
}
@article{Lamport2014,
abstract = {Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.},
author = {Lamport, Leslie and Reed, Benjamin C. and Junqueira, Flavio P. and Ongaro, Diego and Ousterhout, John and Olson, Michael a and Bostic, Keith and Seltzer, Margo and Dwork, Cynthia and Lynch, Nancy and Stockmeyer, Larry and Shore, Jim and Schneider, Fred B and Lamport, Leslie and Castro, Miguel and Liskov, Barbara H and H.Zou and F.Jahanian and Lamport, Leslie and Malkhi, Dahlia and Zhou, Lidong and Zhang, X and Zagorodnov, D. and Hiltunen, M and Marzullo, Keith and Schlichting, R.D. and Budhiraja, Navin and Marzullo, Keith and Schneider, Fred B and Toueg, Sam and Al-Omari, R. and Somani, Arun K. and Manimaran, G. and Junqueira, Flavio P. and Reed, Benjamin C. and Serafini, Marco and Budhiraja, Navin and Guerraoui, Rachid and Schiper, Andr{\'{e}} and Pease, M. and Shostak, R. and Lamport, Leslie and Malkhi, Dahlia and Zhou, Lidong and July, Lamport and Liskov, Barbara H and Cowling, James},
doi = {10.1145/1529974.1529978},
file = {:F\:/papers/Lamport et al. - 2014 - In Search of an Understandable Consensus Algorithm.pdf:pdf},
isbn = {978-1-931971-10-2},
issn = {07342071},
journal = {Atc '14},
keywords = {22,29,3,39,4,5,6,81,Asynchronous consensus,Atomic broadcast,C24 [Computer-Communications Networks],Categories and Subject Descriptors,D45 [Operating Systems],Design,Distributed Systems—Network operating systems,Distributed algorithms,Fault tolerance,Fault-tolerance,Government General Terms,J1 [Administrative Data Processing],Multiprocessors,Primary backup,Real-time systems,Reliability,Reliability Additional Key Words and Phrases,Reliability—Fault-tolerance,Schedulability,Scheduling,State machines,agreement,and ehrases,and phrases,authentication,client-server,consistency,cr categories,distributed executive,fault,fault avoidance,synchronization,three-phase commit,tolerance,voting},
number = {2},
pages = {305--320},
pmid = {380302},
title = {{In Search of an Understandable Consensus Algorithm}},
url = {http://doi.acm.org/10.1145/322186.322188%5Cnhttp://dl.acm.org/ft_gateway.cfm?id=322188&type=pdf%5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5958223%5Cnhttp://portal.acm.org/citation.cfm?doid=1582716.1582783%5Cnhttp://www.itu.dk/stud/s},
volume = {22},
year = {2014}
}
@article{Wang2021,
abstract = {A large number of memory corruption vulnerabilities, e.g., heap overflow and use after free (UAF), could only be exploited in specific heap layouts via techniques like heap feng shui. To pave the way for automated exploit generation (AEG), automated heap layout manipulation is demanded. In this paper, we present a novel solution MAZE to manipulate proof-of-concept (POC) samples' heap layouts. It first identifies heap layout primitives (i.e., input fragments or code snippets) available for users to manipulate the heap. Then, it applies a novel Dig & Fill algorithm, which models the problem as a Linear Diophantine Equation and solves it de-terministically, to infer a primitive operation sequence that is able to generate target heap layout. We implemented a prototype of MAZE based on the analysis engine S2E, and evaluated it on the PHP, Python and Perl interpreters and a set of CTF (capture the flag) programs, as well as a large micro-benchmark. Results showed that MAZE could generate expected heap layouts for over 90% of them.},
author = {Wang, Yan and Lab, WeiRan and Zhang, Chao and Etc},
file = {:F\:/D2/sec21fall-wang-yan.pdf:pdf},
journal = {30th {USENIX} Security Symposium ({USENIX} Security 21)},
title = {{{MAZE}: Towards Automated Heap Feng Shui}},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/wang-yan},
year = {2021}
}
@book{Stolfo2013,
author = {Stolfo, Salvatore J and Eds, Charles V Wright and Bay, Rodney and Lucia, St and Hutchison, David},
file = {:F\:/papers/2013_Book_ResearchInAttacksIntrusionsAnd.pdf:pdf},
isbn = {9783642412837},
number = {October},
title = {{RAID 2013 Intrusions , and Defenses}},
year = {2013}
}
@article{Criswell2014a,
abstract = {Applications that process sensitive data can be carefully designed and validated to be difficult to attack, but they are usually run on monolithic, commodity operating systems, which may be less secure. An OS compromise gives the attacker complete access to all of an application's data, regardless of how well the application is built. We propose a new system, Virtual Ghost, that protects applications from a compromised or even hostile OS. Virtual Ghost is the first system to do so by combining compiler instrumentation and run-time checks on operating system code, which it uses to create ghost memory that the operating system cannot read or write. Virtual Ghost interposes a thin hardware abstraction layer between the kernel and the hardware that provides a set of operations that the kernel must use to manipulate hardware, and provides a few trusted services for secure applications such as ghost memory management, encryption and signing services, and key management. Unlike previous solutions, Virtual Ghost does not use a higher privilege level than the kernel. Virtual Ghost performs well compared to previous approaches; it outperforms InkTag on five out of seven of the LMBench microbenchmarks with improvements between 1.3x and 14.3x. For network downloads, Virtual Ghost experiences a 45% reduction in bandwidth at most for small files and nearly no reduction in bandwidth for large files and web traffic. An application we modified to use ghost memory shows a maximum additional overhead of 5% due to the Virtual Ghost protections. We also demonstrate Virtual Ghost's efficacy by showing how it defeats sophisticated rootkit attacks. Copyright is held by the owner/author(s).},
author = {Criswell, John and Dautenhahn, Nathan and Adve, Vikram},
doi = {10.1145/2541940.2541986},
file = {:F\:/papers/Criswell, Dautenhahn, Adve - 2014 - Virtual Ghost Protecting applications from hostile operating systems.pdf:pdf},
isbn = {9781450323055},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {Control-flow integrity,Inlined reference monitors,Malicious operating systems,Software fault isolation,Software security},
pages = {81--96},
title = {{Virtual Ghost: Protecting applications from hostile operating systems}},
year = {2014}
}
@article{Gerofi2016,
abstract = {Extreme degree of parallelism in high-end computing requires low operating system noise so that large scale, bulk-synchronous parallel applications can be run efficiently. Noiseless execution has been historically achieved by deploying lightweight kernels (LWK), which, on the other hand, can provide only a restricted set of the POSIX API in exchange for scalability. However, the increasing prevalence of more complex application constructs, such as in-situ analysis and workflow composition, dictates the need for the rich programming APIs of POSIX/Linux. In order to comply with these seemingly contradictory requirements, hybrid kernels, where Linux and a lightweight kernel (LWK) are run side-by-side on compute nodes, have been recently recognized as a promising approach. Although multiple research projects are now pursuing this direction, the questions of how node resources are shared between the two types of kernels, how exactly the two kernels interact with each other and to what extent they are integrated, remain subjects of ongoing debate. In this paper, we describe IHK/McKernel, a hybrid software stack that seamlessly blends an LWK with Linux by selectively offloading system services from the lightweight kernel to Linux. Specifically, we are focusing on transparent reuse of Linux device drivers and detail the design of our framework that enables the LWK to naturally leverage the Linux driver codebase without sacrificing scalability or the POSIX API. Through rigorous evaluation on a medium size cluster we demonstrate how McKernel provides consistent, isolated performance for simulations even in face of competing, in-situ workloads.},
author = {Gerofi, Balazs and Takagi, Masamichi and Hori, Atsushi and Nakamura, Gou and Shirasawa, Tomoki and Ishikawa, Yutaka},
doi = {10.1109/IPDPS.2016.80},
file = {:F\:/papers/07516101.pdf:pdf},
isbn = {9781509021406},
journal = {Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016},
keywords = {Hybrid kernels,Lightweight kernels,Operating systems,Scalability,System call offloading},
pages = {1041--1050},
publisher = {IEEE},
title = {{On the Scalability, Performance Isolation and Device Driver Transparency of the IHK/McKernel Hybrid Lightweight Kernel}},
year = {2016}
}
